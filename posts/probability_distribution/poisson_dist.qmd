---
title: "ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒ"
author: "Ryo Nakagami"
date: "2024-09-25"
date-modified: last-modified
number_sections: false
code-fold: true
comments:
    utterances:
         repo: RyoNakagami/statistics-for-regression-monkey
         label: discussion
jupyter: python3
---

## ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã®æ€§è³ª

ç¨€ãªç¾è±¡ã®å¤§é‡è¦³æ¸¬ï¼ˆäºŒé …åˆ†å¸ƒã«ç½®ãæ›ãˆã‚‹ãªã‚‰ã° $n$ ãŒãŠãŠããï¼Œ$p$ ãŒååˆ†å°ã•ã„ï¼‰ã«ãŠã„ã¦ç™ºç”Ÿã™ã‚‹å€‹æ•°ã®åˆ†å¸ƒã‚’è¡¨ã™ã®ã«ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒãŒ
ç”¨ã„ã‚‰ã‚Œã¾ã™ï¼ä¾‹ã¨ã—ã¦ï¼Œ

- ã‚ã‚‹éƒ½å¸‚ã®ï¼‘æ—¥ã«èµ·ã“ã‚‹äº¤é€šäº‹æ•…ã®ä»¶æ•°ã®åˆ†å¸ƒ
- ã‚ã‚‹éƒ½å¸‚ã§ï¼‘å¹´é–“ã«è‚ºãŒã‚“ã«ã‚ˆã‚Šãªããªã‚‹äººæ•°ã®åˆ†å¸ƒ

<div class="blog-custom-border">
<strong>Def: ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒ(Poisson distribution)</strong> <br>

ç¢ºç‡å¤‰æ•° $X$ ãŒãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ $\lambda > 0$ ã®ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã«å¾“ã†ã¨ãï¼Œæ¨™æœ¬ç©ºé–“ã¯ $\mathcal{X} = \{0, 1, \cdots, n\}$ï¼Œç¢ºç‡é–¢æ•° $f_X(x)$ ã¯

$$
f_X(x) = \bigg\{\begin{array}{c} \frac{\lambda^x}{x!}\exp(-\lambda) & x \in \mathcal{X}\\0 & \text{otherwise}\end{array}
$$

ã“ã®ã¨ãï¼Œ$X\sim \operatorname{Po}(\lambda)$ ã¨è¡¨ã™ï¼

</div>

ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã® $\lambda > 0$ ã¯**å¼·åº¦**ã‚‚ã—ãã¯**ç”Ÿèµ·ç‡**ã¨å‘¼ã°ã‚Œã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã§ã™ï¼

<strong > &#9654;&nbsp; ç¢ºç‡é–¢æ•°ã®å’Œ</strong>

$$
\begin{align*}
\sum_{x=0}^\infty f_X(x)
    &= \sum_{x=0}^\infty\frac{\lambda^x}{x!}\exp(-\lambda)\\
    &= \exp(-\lambda)\sum_{x=0}^\infty\frac{\lambda^x}{x!}\\
    &= \exp(-\lambda)\left[1 + \frac{\lambda}{1!} + \frac{\lambda^2}{2!} + \cdots\right]\\
    &= \exp(-\lambda)\exp(\lambda) \quad\because\text{ãƒã‚¯ãƒ­ãƒ¼ãƒªãƒ³å±•é–‹ã‚ˆã‚Š}\\
    &= 1
\end{align*}
$$

<strong > &#9654;&nbsp; æœŸå¾…å€¤ã®å°å‡º</strong>

ç¢ºç‡å¤‰æ•° $X\sim\operatorname{Po}(\lambda)$ ã«ã¤ã„ã¦ï¼Œ

$$
\begin{align*}
\mathbb E[X]
    &= \sum_{x=0}^\infty x \frac{\lambda^x}{x!}\exp(-\lambda)\\
    &= \lambda\exp(-\lambda)\sum_{x=1}^\infty\frac{\lambda^{x-1}}{(x-1)!}\\
    &= \lambda\exp(-\lambda)\sum_{k=0}^\infty\frac{\lambda^k}{k!}\\
    &= \lambda\exp(-\lambda)\exp(\lambda)\\
    &= \lambda
\end{align*}
$$

<strong > &#9654;&nbsp; åˆ†æ•£ã®å°å‡º</strong>

$$
\begin{align*}
\mathbb E[X(X-1)]
    &= \sum_{x=0}^\infty x(x-1) \frac{\lambda^x}{x!}\exp(-\lambda)\\
    &= \lambda^2\exp(-\lambda)\sum_{x=2}^\infty\frac{\lambda^{x-2}}{(x-2)!}\\
    &= \lambda^2
\end{align*}
$$

å¾“ã£ã¦ï¼Œ

$$
\begin{align*}
\operatorname{Var}(X)
    &= \mathbb E[X(X- 1)] + \mathbb E[X](1 - \mathbb E[X])\\
    &= \lambda^2 + \lambda(1 - \lambda)\\
    &= \lambda
\end{align*}
$$

<strong > &#9654;&nbsp; ç¢ºç‡æ¯é–¢æ•°ã®è¨ˆç®—</strong>

ç¢ºç‡å¤‰æ•° $X\sim\operatorname{Po}(\lambda)$ ã¨ã—ãŸã¨ãï¼Œ ç¢ºç‡æ¯é–¢æ•° $G_X(s)$ ã¯

$$
\begin{align*}
G_X(s)
    &= \sum_{x=0}^\infty s^x\frac{\lambda^x}{x!}\exp(-\lambda)\\
    &= \exp(-\lambda)\sum_{x=0}^\infty \frac{(s\lambda)^x}{x!}\\
    &= \exp(-\lambda)\exp(s\lambda)\\
    &= \exp((s-1)\lambda)
\end{align*}
$$

æœŸå¾…å€¤ã¯

$$
\begin{align*}
\mathbb E[X]
    &= G_X^\prime(1)\\
    &= \lambda \exp((1-1)\lambda)\\
    &= \lambda
\end{align*}
$$

åˆ†æ•£ã¯ $\operatorname{Var}(X) = \mathbb E[X(X-1)] + \mathbb E[X](1 - \mathbb E[X])$ ãªã®ã§

$$
\begin{align*}
\mathbb E[X(X-1)]
    &= G_X^{\prime\prime}(1)\\
    &= \lambda \lambda\exp((1-1)\lambda)\\
    &= \lambda^2
\end{align*}
$$

å¾“ã£ã¦ï¼Œ

$$
\begin{align*}
\operatorname{Var}(X)
    &= \lambda^2 + \lambda(1-\lambda)\\
    &= \lambda
\end{align*}
$$

<strong > &#9654;&nbsp; ç©ç‡æ¯é–¢æ•°ã®è¨ˆç®—</strong>

ç¢ºç‡å¤‰æ•° $X\sim\operatorname{Po}(\lambda)$ ã¨ã—ãŸã¨ãï¼Œ ç©ç‡æ¯é–¢æ•° $M_X(t)$ ã¯

$$
\begin{align*}
M_X(t)
    &= \mathbb E[\exp(tX)]\\
    &= \sum_{x=0}\exp(-\lambda)\exp(tX)\frac{\lambda^x}{x!}\\
    &= \exp(-\lambda)\sum_{x=0}\frac{(\exp(t)\lambda)^x}{x!}\\
    &= \exp(-\lambda)\exp(e^t\lambda)\\[5pt]
    &= \exp[\lambda(e^t - 1)]
\end{align*}
$$x



::: {#exm- .custom_problem }
**: 19-20ã‚·ãƒ¼ã‚ºãƒ³ã®Man Utdã®ã‚´ãƒ¼ãƒ«æ•°ã¨ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒ**
<br>

[Man Utd English Premier League 2019/20 fixture and results](https://fixturedownload.com/results/epl-2019/man-utd)ã¨ã„ã†ã‚µã‚¤ãƒˆã§ã¯ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°ã®å„ã‚·ãƒ¼ã‚ºãƒ³åŠã³å„ãƒãƒ¼ãƒ ã®è©¦åˆçµæœãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã™. ä¸Šè¨˜ã‚µã‚¤ãƒˆã®URLã®æ§‹é€ ã¯

```html
https://fixturedownload.com/results/epl-<ã‚·ãƒ¼ã‚ºãƒ³>/<teamå>
```

19-20ã‚·ãƒ¼ã‚ºãƒ³ã®Man Utdã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ãŸã„å ´åˆã¯æ¬¡ã®ã‚ˆã†ã«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’è¨­å®šã—ã¾ã™ï¼

|parameter|value|æ„å‘³|
|---|---|---|
|teamå| `man-utd`|Man Utd, ã™ã¹ã¦å°æ–‡å­—ã€ã‚¹ãƒšãƒ¼ã‚¹ã¯ãƒã‚¤ãƒ•ãƒ³ã¨ãªã‚‹|
|ã‚·ãƒ¼ã‚ºãƒ³| `2019` |2019-2020ã‚·ãƒ¼ã‚ºãƒ³|

æŠ½å‡ºçµæœã¯ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™

```{python}
import pandas as pd
target_team = 'man-utd'
TARGET_TEAMNAME = target_team.replace('-', ' ').title()
URL_PATH = 'https://fixturedownload.com/results/epl-2019/'+target_team

df = pd.read_html(URL_PATH, flavor="bs4")[0]
df.head()
```

ã“ã“ã‹ã‚‰Man Utdã®ã‚²ãƒ¼ãƒ ã”ã¨ã®ã‚´ãƒ¼ãƒ«æ•°é…åˆ—ã‚’æŠ½å‡ºã—ï¼Œãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒæ¯”è¼ƒã—ã¦ã¿ã¾ã™ï¼

```{python}
import numpy as np
from plotly import express as px
import plotly.graph_objects as go
from scipy.stats import poisson


def extract_goal(data, target_team):
    score_list = data["Result"].str.split(r"\s-\s", expand=True)
    score_list.columns = ["home_score", "away_score"]
    score_list = score_list.astype({"home_score": "int64", "away_score": "int64"})

    data = pd.concat([data, score_list], axis=1)
    return np.where(
        df["Home Team"] == target_team, data["home_score"], data["away_score"]
    )


goal_array = extract_goal(df.copy(), target_team=TARGET_TEAMNAME)

## å¯è¦–åŒ–
x, y = np.unique(goal_array, return_counts=True)

fig = go.Figure()
fig.add_trace(
    go.Bar(
        x=x,
        y=y / sum(y),  # Normalizing the frequency
        name="Goals per games", 
        width=0.3
    )
)

fig.add_trace(
    go.Scatter(
        x=x,
        y=poisson(np.mean(goal_array)).pmf(x),
        mode="lines+markers",
        name="Poisson",
        line=dict(color="gray", dash="dot"),
    )
)

fig.update_layout(
    title="19-20ã‚·ãƒ¼ã‚ºãƒ³ Man Utd Goal Distribution",
    xaxis_title="Goals",  # X-axis label
    yaxis_title="Frequency",  # Y-axis label
    legend_title="Legend",  # Legend title
    showlegend=True,  # Ensure legend is displayed
)

fig.show()    
```

- Fittingã¯ãã‚“ãªã«æ‚ªããªã„ãŒï¼ŒscoreãŒã‚¼ãƒ­ã®ã¨ã“ã‚ãŒç†è«–é »åº¦ã‚ˆã‚Šå®Ÿç¾å€¤ã®ã»ã†ãŒé »åº¦ãŒå¤šã„å‚¾å‘ãŒã‚ã‹ã‚Šã¾ã™
- 0ãŒéå‰°ã«å«ã¾ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã¯ã‚¼ãƒ­éå‰°ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒ(Zero-inflated Poisson Model, ZIP)ã‚’ç”¨ã„ã¦å¯¾å‡¦ã™ã‚‹ã“ã¨ãŒè€ƒãˆã‚‰ã‚Œã¾ã™


:::





<div class="blog-custom-border">
::: {#thm- .custom_problem }
**: ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã®å†ç”Ÿæ€§**
<br>

äº’ã„ã«ç‹¬ç«‹ãªç¢ºç‡å¤‰æ•° $X\sim\operatorname{Po}(\lambda_x), Y\sim\operatorname{Po}(\lambda_y)$ ã«ã¤ã„ã¦,
$X + Y$ ã‚‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ $\lambda_x + \lambda_y$ ã®ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã«å¾“ã†ï¼ã¤ã¾ã‚Šï¼Œ

$$
X + Y \sim \operatorname{Po}(\lambda_x + \lambda_y)
$$

:::

</div>

::: {.callout-note collapse="false" icon=false}
## Proof: PGFã‚’ç”¨ã„ãŸè¨¼æ˜

$$
\begin{align*}
G_{X+Y}(s)
    &= G_{X}(s)G_{Y}(s)\\
    &= \exp(-\lambda_x)\exp(s\lambda_x)\exp(-\lambda_y)\exp(s\lambda_y)\\
    &= \exp(-(\lambda_x+\lambda_y))\exp(s(\lambda_x+\lambda_y))
\end{align*}
$$

ã“ã‚Œã¯ï¼Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ $\lambda_x + \lambda_y$ ã®ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã®PGFã«ä¸€è‡´ã—ã¦ã„ã¾ã™ï¼

:::

::: {.callout-note collapse="false" icon=false}
## Proof: MGFã‚’ç”¨ã„ãŸè¨¼æ˜

$$
\begin{align*}
M_{X+Y}(t)
    &= M_{X}(t)M_{X}(t)\\
    &= \exp[\lambda_x(e^t - 1)]\exp[\lambda_y(e^t - 1)]\\
    &= \exp[\lambda_x(e^t - 1) + \lambda_y(e^t - 1)]\\
    &= \exp[(\lambda_x + \lambda_y)(e^t - 1)]
\end{align*}
$$

ã“ã‚Œã¯ï¼Œãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ $\lambda_x + \lambda_y$ ã®ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã®MGFã«ä¸€è‡´ã—ã¦ã„ã¾ã™ï¼


:::

## Estimation
### Ommited vriable and overdispersion

<div class="blog-custom-border">
<strong>Def: overdispersion</strong> <br>

è¦³å¯Ÿãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ï¼ŒæœŸå¾…ã•ã‚Œã‚‹åˆ†æ•£ã‚ˆã‚Šã‚‚å¤§ãã„åˆ†æ•£(variation)ãŒç¢ºèªã•ã‚Œã‚‹çŠ¶ãŒã‚ã‚‹ã¨ãï¼Œoverdispersionã§ã‚ã‚‹ã¨ã„ã†ï¼

</div>

ãƒãƒ¯ã‚½ãƒ³åˆ†å¸ƒã«ãŠã„ã¦ï¼Œä¸Šã§ç¢ºèªã—ãŸã‚ˆã†ã«åˆ†æ•£ã¨å¹³å‡ã¯ä¸€è‡´ã™ã‚‹ã¯ãšã§ã™ãŒï¼Œommitted variable biasã‚’åŸå› ã¨ã—ã¦
overdispersionãŒç™ºç”Ÿã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒå¤šãã‚ã‚Šã¾ã™ï¼

$$
\begin{align*}
y &\sim \operatorname{Po}(\lambda)\\
\log(\lambda) &= \beta_0 + \beta_1 x_1 + \beta_2 x_2
\end{align*}
$$

ã¨ã„ã†ç¢ºç‡å¤‰æ•°ã‚’è€ƒãˆã¾ã™ï¼ã“ã®ã¨ãæ¬¡ã®ã‚ˆã†ãªæ¡ä»¶ã‚’æƒ³å®šã—ã¾ã™ï¼š

- è¦³å¯Ÿãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦, $x_2$ ã¯è¦³å¯Ÿä¸èƒ½(=missing variable)
- $x_1 \perp x_2$

ã“ã®ã¨ãï¼Œ$y$ ã«ã¤ã„ã¦ $x_1$ ã‚’æ¡ä»¶ã¥ã‘ãŸã¨ãã®æœŸå¾…å€¤ã‚’è¨ˆç®—ã™ã‚‹ã¨

$$
\begin{align*}
\mathbb E[y\vert x_1]
    &= \mathbb E[\mathbb E[y\vert x_1, x_2]\vert x_1]\\
    &= \mathbb E[\exp(\beta_0 + \beta_1 x_1 + \beta_2 x_2)\vert x_1]\\
    &= \exp(\beta_0 + \beta_1 x_1)\mathbb E[\exp(\beta_2 x_2)\vert x_1]\\
    &= \exp(\beta_0 + \beta_1 x_1)\mathbb E[\exp(\beta_2 x_2)] \because\text{ç‹¬ç«‹æ€§}\\
    &= \exp(\tilde\beta_0+ \beta_1 x_1)
\end{align*}
$$

ã¨ï¼Œåˆ‡ç‰‡ã«ã¯å½±éŸ¿ã‚’ä¸ãˆã¾ã™ãŒï¼Œ$\beta_1$ ã«ã¤ã„ã¦ã¯unbiasedã«æ¨å®šã§ãã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼ä¸€æ–¹ï¼Œæ¡ä»¶ä»˜ãåˆ†æ•£ã‚’è¦‹ã¦ã¿ã‚‹ã¨

$$
\begin{align*}
\operatorname{Var}(y\vert x_1)
    =& \mathbb E[\operatorname{Var}(y\vert x_1, x_2)\vert x_1] + \operatorname{Var}(\mathbb E[y\vert x_1, x_2]\vert x_1)\\[3pt]
    =& \mathbb E[\exp(\beta_0 + \beta_1 x_1 + \beta_2 x_2)\vert x_1] \\
     &+ \operatorname{Var}(\exp(\beta_0 + \beta_1 x_1 + \beta_2 x_2)\vert x_1)\\
    =& \exp(\tilde\beta_0+ \beta_1 x_1) \\
     & + [\exp(\beta_0 + \beta_1x_1)]^2\operatorname{Var}(\exp(\beta_2 x_2))\\
    >& \exp(\tilde\beta_0+ \beta_1 x_1) = \mathbb E[y\vert x_1]
\end{align*}
$$

ä»¥ä¸Šã‚ˆã‚Šï¼ŒOVBã®ã¨ãï¼ŒovberdispersionãŒç™ºç”Ÿã—ã¦ã—ã¾ã†ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼


<div class="blog-custom-border">
<strong >ğŸ“˜ REMARKS</strong> <br>

ãƒãƒ¯ã‚½ãƒ³å›å¸°ã«ãŠã„ã¦over-dispersionãŒç™ºç”Ÿã—ãŸå ´åˆã¯ä»¥ä¸‹ã®ã‚±ãƒ¼ã‚¹ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ï¼š

- é‡è¦ãªç‰¹å¾´é‡ãŒæ¬ è½å¤‰æ•°(ommited variable)ã«ãªã£ã¦ã—ã¾ã£ã¦ã„ã‚‹
- èª¬æ˜å¤‰æ•°ï¼Œè¢«èª¬æ˜å¤‰æ•°(response variable)ã«ã¤ã„ã¦measurement errorãŒç™ºç”Ÿã—ã¦ã—ã¾ã£ã¦ã„ã‚‹
- $\log(\lambda)$ ã¨ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ« $\mathbf x$ ã®ãƒ¢ãƒ‡ãƒ«ç‰¹å®šã«èª¤ã‚ŠãŒã‚ã‚‹
- Outlierã®å­˜åœ¨
- response variableãŒè¤‡æ•°ã®ç¢ºç‡åˆ†å¸ƒã®æ··åˆ(mixture)ã«åŸºã¥ã„ã¦ã„ã‚‹å ´åˆ

</div>
