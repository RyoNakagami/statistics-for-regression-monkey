[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for Regression Monkeys",
    "section": "",
    "text": "Welcome\nã“ã®Quarto Bookã¯ä»¥ä¸‹ã®ã‚·ãƒªãƒ¼ã‚ºã¨é€£å‹•ã—ã¦é‹ç”¨ã•ã‚Œã¦ã„ã¾ã™:",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Statistics for Regression Monkeys",
    "section": "References",
    "text": "References\n\n\næŸ³å·å ¯ (2018), På€¤:\nãã®æ­£ã—ã„ç†è§£ã¨é©ç”¨, è¿‘ä»£ç§‘å­¦ç¤¾.\n\n\næ°¸ç”°é– (2003), ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã®æ±ºã‚æ–¹,\næœå€‰æ›¸åº—.\n\n\nç«¹æ‘å½°é€š (2020), ç¾ä»£æ•°ç†çµ±è¨ˆå­¦,\nå­¦è¡“å›³æ›¸å‡ºç‰ˆç¤¾.\n\n\nè—¤æ¾¤æ´‹å¾³ (2017), ãƒ­ãƒã‚¹ãƒˆçµ±è¨ˆ\n: å¤–ã‚Œå€¤ã¸ã®å¯¾å‡¦ã®ä»•æ–¹ï¼ˆISMã‚·ãƒªãƒ¼ã‚º : é€²åŒ–ã™ã‚‹çµ±è¨ˆæ•°ç† /\nçµ±è¨ˆæ•°ç†ç ”ç©¶æ‰€ç·¨, 6, è¿‘ä»£ç§‘å­¦ç¤¾.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html",
    "href": "posts/statistics101/averages.html",
    "title": "1Â  ä»£è¡¨å€¤",
    "section": "",
    "text": "å¹³å‡\nâ–¶Â  æ¨™æœ¬å¹³å‡\nãƒ‡ãƒ¼ã‚¿ \\(X = \\{x_1, \\cdots, x_n\\}\\) ãŒä¸ãˆã‚‰ã‚Œã¨ãï¼Œæ¨™æœ¬å¹³å‡ï¼ˆsample meanï¼‰ \\(\\overline{x}\\) ã¯æ¬¡ã«ãªã‚Šã¾ã™ï¼š\n\\[\n\\overline{x} = \\frac{x_1 + \\cdots + x_n}{n}\n\\]\næ¨™æœ¬å¹³å‡ã¯åˆ†å¸ƒã®ä»£è¡¨å€¤ã¨ã—ã¦æœ€ã‚‚ä½¿ç”¨ã•ã‚Œã‚‹ã‚‚ã®ã ãŒï¼Œå¤–ã‚Œå€¤ã«å¯¾ã—ã¦å¼±ã„æ€§è³ªãŒã‚ã‚‹ï¼\nimport numpy as np\n\nX_0 = np.array([5.6, 5.7, 5.4, 5.5, 5.8, 5.2, 5.3, 5.6, 5.4, 55.5])\nX_1 = np.array([5.6, 5.7, 5.4, 5.5, 5.8, 5.2, 5.3, 5.6, 5.4])\n\nprint(\n    \"\"\"X_0: sample mean = {}, median = {}\\nX_1: sample mean = {}, median = {}\n      \"\"\".format(\n        np.mean(X_0), np.median(X_0), np.mean(X_1), np.median(X_1)\n    )\n)\n\nX_0: sample mean = 10.5, median = 5.55\nX_1: sample mean = 5.5, median = 5.5\nä¸Šè¨˜ã®ä¾‹ã®ã‚ˆã†ã«ï¼Œmedianã¯å¤–ã‚Œå€¤ã®æ··å…¥ãŒã‚ã£ã¦ã‚‚ãã®å½±éŸ¿ã¯è»½å¾®ã§ã™ãŒï¼Œæ¨™æœ¬å¹³å‡ã¯å¤§ããå¤‰ã‚ã£ã¦ãŠã‚Šå¤–ã‚Œå€¤ã«å¯¾ã—ã¦å¼±ã„ã“ã¨ãŒã‚ã‹ã‚‹ï¼\nâ–¶Â  åˆˆã‚Šè¾¼ã¿å¹³å‡\nå¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å¼±ã‚ã¦æ¨™æœ¬å¹³å‡ã‚’æ¨å®šã™ã‚‹æ–¹æ³•ã¨ã—ã¦ï¼Œåˆˆã‚Šè¾¼ã¿å¹³å‡(trimmed mean)ãŒã‚ã‚Šã¾ã™ï¼ ä¸Šå´ \\(100\\alpha \\%\\) ã¨ä¸‹å´ \\(100\\alpha \\%\\) ã‚’ä½¿ã‚ãªã„ã§æ¨å®šã™ã‚‹æ–¹æ³•ã§ï¼Œ\\(x_{[i]}\\) ã‚’é †åºçµ±è¨ˆå€¤ã¨ã—ã¦\n\\[\n\\hat\\mu_\\alpha = \\frac{1}{n-2m} \\sum_{i=m+1}^{n-m}x_{[i]}, \\  \\ m = \\lfloor n\\alpha \\rfloor\n\\]\nã§æ¨å®šã™ã‚‹æ–¹æ³•ã‚’åˆˆã‚Šè¾¼ã¿å¹³å‡ã¨ã„ã†ï¼åˆ©ç”¨ã«ã‚ãŸã£ã¦ï¼Œå¤–ã‚Œåœ°ã®å‰²åˆã‚’äº‹å‰ã«æƒ³å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ãŒï¼Œ å°‘ã€…é©å½“ã«æ¨å®šã—ã¦ã‚‚å¦¥å½“ãªæ¨å®šã«ãªã‚Šã‚„ã™ã„ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ï¼\n\\(\\alpha = 0.1\\) ã¨ã—ã¦Pythonã§è¨ˆç®—ã—ã¦ã¿ã‚‹ã¨ä»¥ä¸‹ï¼Œ\nfrom scipy import stats\nself_trimmed_mean = np.mean([5.7, 5.4, 5.5, 5.8, 5.4, 5.3, 5.6, 5.6])\ntrimmed_mean = stats.trim_mean(X_0, 0.1)\nprint(self_trimmed_mean, trimmed_mean)\n\n5.5375 5.5375\nTrimmed meanã¯ARE(Asymptotic relative efficiency, æ¼¸è¿‘ç›¸å¯¾åŠ¹ç‡)ã¨ã„ã†è¦³ç‚¹ã‹ã‚‰ã‚‚å¤§æŠµã®è£¾ã®é‡ã•ã«å¯¾ã—ã¦ï¼ˆé‡ã™ãã‚‹ã®ã¯å³ã—ã„ã§ã™ãŒï¼ï¼ï¼ï¼‰é«˜ã„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒã‚ã‚‹ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ï¼\nâ–¶Â  å¹¾ä½•å¹³å‡\n\\(x_i &gt; 0\\) ã¨ãªã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ï¼Œå¹¾ä½•å¹³å‡ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã¾ã™ï¼š\n\\[\n\\overline{x}_G = \\bigg(\\prod_{i=1}^n x_i \\bigg)^{\\frac{1}{n}}\n\\]\n2000å¹´ã‹ã‚‰2005å¹´ã¾ã§ã®Xã“ãã®ã§ã®ç‰©ä¾¡ä¸Šæ˜‡ç‡ãŒ2%, 5%, 2%, 5%, 10%ã¨ã‚ã‚‹ã¨ãï¼Œå¹´å¹³å‡ä¸Šæ˜‡ç‡ã¯ç®—è¡“å¹³å‡ã§ã¯ãªãå¹¾ä½•å¹³å‡ã§è¨ˆç®—ã™ã¹ãã§\n\\[\n(1.02 \\times 1.05 \\times 1.02 \\times 1.05 \\times 1.1)^{1/5} \\approx 1.0476\n\\]\nã™ãªã‚ã¡å¹´å¹³å‡ç´„4.8%ã®å¢—åŠ ã¨å ±å‘Šã™ã¹ãã¨ãªã‚Šã¾ã™ï¼ãªãŠï¼Œç›¸åŠ ç›¸ä¹—å¹³å‡ã‚ˆã‚Šï¼Œå¹¾ä½•å¹³å‡ã¯ç®—è¡“å¹³å‡ã‚ˆã‚Šå°ã•ã„å€¤ã«ãªã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼ã‚‚ã—å¤§ãã„å€¤ã‚’å‡ºã—ã¦ã—ã¾ã£ã¦ã„ãŸã‚‰è¨ˆç®—ãƒŸã‚¹ã‚’ç–‘ã†ã¹ãã§ã™ï¼\nå¹¾ä½•å¹³å‡ã«ã¤ã„ã¦å¯¾æ•°ã‚’ã¨ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ç®—è¡“å¹³å‡ã§è¡¨ã™ã“ã¨ãŒã§ãã¾ã™\n\\[\n\\log(\\overline{x}_G) = \\frac{1}{n}\\sum \\log(x_i)\n\\]\nã“ã“ã‹ã‚‰ï¼Œå¹¾ä½•å¹³å‡ã‚’è¨ˆç®—ã™ã‚‹ã¨ãã¯ä¸€æ—¦log transformationã‚’å®Ÿè¡Œã—ï¼Œç®—è¡“å¹³å‡ã‚’è¨ˆç®—ã—ï¼Œãã®å¾Œ \\(\\exp(\\cdot)\\) ã§å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™ã¨ã„ã†å½¢ã§ã‚ˆãè¨ˆç®—ã•ã‚Œã¾ã™ï¼\nã‚¯ãƒ©ã‚¹åˆ†é¡ã®è©•ä¾¡æŒ‡æ¨™ã¨ã®é–¢ä¿‚ã§ã¯ï¼Œsensitivity(æ„Ÿå¿œåº¦)ã¨specificity(ç‰¹ç•°åº¦)ã®å¹¾ä½•å¹³å‡ã‚’ç”¨ã„ãŸG-Mean(geometric mean)ã¨ã„ã†æŒ‡æ¨™ãŒã‚ã‚Šã¾ã™ï¼\n\\[\n\\begin{align*}\n\\operatorname{G-mean} &= \\sqrt{\\operatorname{sensitivity} \\times \\operatorname{specificity}}\\\\\n                      &= \\sqrt{\\operatorname{recall} \\times \\operatorname{True Negative Rate}}\n\\end{align*}\n\\]\nâ–¶Â  èª¿å’Œå¹³å‡\n\\(x_i &gt; 0\\) ã¨ãªã‚‹ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ï¼Œèª¿å’Œå¹³å‡(harmonic mean)ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã¾ã™ï¼š\n\\[\n\\frac{1}{\\overline{x}_H} = \\frac{1}{n}\\sum\\frac{1}{x_i}\n\\]\nã¨ã‚ã‚‹è»ŠãŒè·é›¢ \\(\\alpha\\) ã®åŒºé–“Aã§ã¯25km/h, è·é›¢ \\(\\beta\\) ã®åŒºé–“Bã§ã¯15km/hã§èµ°ã£ã¦ã„ãŸã¨ã—ã¾ã™ï¼ã“ã®ã¨ãï¼Œã“ã®è»Šã®å¹³å‡æ™‚é€Ÿã¯\n\\[\n\\frac{1}{\\text{å¹³å‡æ™‚é€Ÿ}} = \\frac{\\alpha}{\\alpha + \\beta} \\frac{1}{25} + \\frac{\\beta}{\\alpha + \\beta} \\frac{1}{15}\n\\]\n\\(\\alpha = \\beta\\) ã®ã¨ãã¯\n\\[\n\\frac{1}{\\text{å¹³å‡æ™‚é€Ÿ}}  = \\frac{1}{2} \\bigg(\\frac{1}{25} + \\frac{1}{15}\\bigg)\n\\]\nå¹³å‡ã‚’è¨ˆç®—ã™ã‚‹ã«ã‚ãŸã£ã¦ï¼Œå€¤ãŒåŒã˜ã‚¹ã‚±ãƒ¼ãƒ«ã®å˜ä½ã§ã‚ã‚‹å¿…è¦ã§ã‚ã‚‹ãŸã‚ï¼Œä¸Šã®å¹³å‡æ™‚é€Ÿã®ä¾‹ã§ã¯èª¿å’Œå¹³å‡ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ãŒ å¥½ã¾ã—ã„ã¨ã•ã‚Œã¾ã™ï¼ãªãŠåŒºé–“Aã‚’xæ™‚é–“ã§25km/h, åŒºé–“Bã‚’yæ™‚é–“ã§15km/hã¨ã„ã†å ´åˆã¯ã‚¦ã‚§ã‚¤ãƒˆãŒæ™‚é–“å˜ä½ã§è¡¨ã•ã‚Œã¦ã„ã‚‹ã®ã§\n\\[\n\\text{å¹³å‡æ™‚é€Ÿ} = \\frac{x}{x + y} \\times 25 + \\frac{y}{x + y} \\times 15\n\\]\nãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡æŒ‡æ¨™ã®ï¼‘ã¤ã«precisionã¨recallã‚’ç”¨ã„ãŸF1-scoreãŒã‚ã‚Šã¾ã™ãŒï¼Œprecisionã¨recallã‚‚åˆ†å­ã¯ãã‚Œãã‚ŒTrue Positiveã§å…±é€šã—ã¦ã„ã¾ã™ãŒï¼Œåˆ†æ¯ãŒãã‚Œãã‚Œ \\(\\operatorname{TP} + \\operatorname{FP}, \\operatorname{TP} + \\operatorname{FN}\\) ã¨ç•°ãªã£ã¦ã„ã‚‹ã®ã§ï¼Œèª¿å’Œå¹³å‡ã‚’ç”¨ã„ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã—ã¾ã™ï¼š\n\\[\n\\begin{align*}\n\\operatorname{F1-score} &= \\frac{1}{\\frac{1}{2} \\left(\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}\\right)}\\\\\n&= \\frac{2}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}}\n\\end{align*}\n\\]\nãªãŠï¼Œã“ã‚Œã¯ã‚¦ã‚§ã‚¤ãƒˆãŒç­‰ã—ã„å ´åˆã‚’æ„å‘³ã—ã¦ãŠã‚Šï¼Œweighted harmonic meanã¸æ‹¡å¼µã™ã‚‹å ´åˆã¯ä»¥ä¸‹ã®ã‚ˆã†ã« \\(\\operatorname{F_\\beta-score}\\) ã‚’ç”¨ã„ã¦è¨ˆç®—ã—ã¾ã™\n\\[\n\\operatorname{F_\\beta-score} = \\frac{1 + \\beta^2}{\\frac{1}{\\text{precision}} + \\frac{\\beta^2}{\\text{recall}}}\n\\]\nã‚¦ã‚§ã‚¤ãƒˆãŒ \\(\\frac{1}{1 + \\beta^2}, \\frac{\\beta^2}{1 + \\beta^2}\\) ã®å½¢ã‚’å–ã£ã¦ã„ã‚‹ã®ã¯ä¸€è¦‹ä¸è‡ªç„¶ã«è¦‹ãˆã¾ã™ãŒï¼Œãã®è€ƒå¯Ÿã§é¢ç™½ã„ã®ãŒvan Rijs-bergenâ€™s E (effectiveness) functionã«åŸºã¥ã„ãŸèª¬æ˜ã§ã™ï¼",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>ä»£è¡¨å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#å¹³å‡",
    "href": "posts/statistics101/averages.html#å¹³å‡",
    "title": "1Â  ä»£è¡¨å€¤",
    "section": "",
    "text": "Theorem 1.1 \nå®šç¾©åŸŸãŒ \\(\\mathbb R_+\\) ã®ç¢ºç‡å¤‰æ•° \\(X\\) ã‚’è€ƒãˆã‚‹ï¼ˆã¤ã¾ã‚Š \\(X &gt; 0\\)ï¼‰. ã“ã®ã¨ã,\n\n\\(H_x\\): èª¿å’Œå¹³å‡\n\\(G_x\\): å¹¾ä½•å¹³å‡\n\\(\\overline{X}\\): æ¨™æœ¬å¹³å‡\n\nã¨ã—ã¦ä»¥ä¸‹ãŒå¸¸ã«æˆã‚Šç«‹ã¤\n\\[\nH_x \\leq G_x \\leq \\overline{X}\n\\]\n\n\n\n\n\n\n\n\nProof: Jensenâ€™s inequalityã‚’ç”¨ã„ãŸè¨¼æ˜\n\n\n\n\n\nJensenâ€™s inequalityã‚ˆã‚Š é–¢æ•° \\(g\\) ã‚’å‡¸é–¢æ•°(convex function)ã¨ã™ã‚‹ã¨\n\\[\n\\frac{1}{n}\\sum_{i=1}^ng(x_i)\\geq g(\\overline{x})\n\\]\nã¨ã„ã†ä¸ç­‰å¼ãŒæˆã‚Šç«‹ã¤.\n â–¶Â  \\(\\overline{X} \\geq G_x\\) ã®è¨¼æ˜\n\\(f(x) = -\\log(x)\\) ã¨ã™ã‚‹ã¨ \\(f\\) ã¯å˜èª¿æ¸›å°‘ã®å‡¸é–¢æ•°ã§ã‚ã‚‹ã®ã§\n\\[\n\\begin{align*}\n-\\log(\\overline{x}) &\\leq -\\frac{1}{n}\\sum_{i=1}^n\\log(x_i)\\\\\n                    &= -\\log(\\prod_{i=1}^n x_i^{1/n})\\\\\n                    &= -\\log(G_x)\n\\end{align*}\n\\]\nã¤ã¾ã‚Šï¼Œ\\(\\log(\\overline{x})\\geq \\log(G_x) \\Rightarrow \\overline{X} \\geq G_x\\)\n â–¶Â  \\(G_x \\geq H_x\\) ã®è¨¼æ˜\n\\(1/x_i = y_i\\) ã¨å¤‰æ›ã™ã‚‹ã¨\n\\[\n\\begin{align*}\nG_x &= \\left(\\prod \\frac{1}{y_i}\\right)^{1/n}\\\\\nH_x &= \\frac{1}{\\overline y}\n\\end{align*}\n\\]\nãã‚Œãã‚Œã«ã¤ã„ã¦ \\(f(x) = \\log(x)\\) ã¨ã™ã‚‹ã¨\n\\[\n\\begin{align*}\n\\log(G_x) &= \\frac{1}{n}\\sum_{i=1}^n(-\\log(y_i))\\\\\n\\log(H_x) &= -\\log(\\overline y)\n\\end{align*}\n\\]\n\\(-\\log(\\cdot)\\) ã¯å‡¸é–¢æ•°ã§ã‚ã‚‹ã®ã§\n\\(\\log(G_x) \\geq \\log(H_x) \\Rightarrow G_x \\geq H_x\\) ã‚’å¾—ã‚‹ï¼",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>ä»£è¡¨å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#ä¸­å¤®å€¤",
    "href": "posts/statistics101/averages.html#ä¸­å¤®å€¤",
    "title": "1Â  ä»£è¡¨å€¤",
    "section": "ä¸­å¤®å€¤",
    "text": "ä¸­å¤®å€¤\n\nDef: median \nãƒ‡ãƒ¼ã‚¿ \\(x_1, \\cdots, x_n\\) ã‚’å°ã•ã„é †ã«ä¸¦ã³æ›¿ãˆãŸé †åºçµ±è¨ˆé‡\n\\[\nx_{[1]} &lt; \\cdots &lt; x_{[n]}\n\\]\nã«ã¤ã„ã¦ï¼ŒçœŸã‚“ä¸­ã®å€¤ã‚’ä¸­å¤®å€¤ã¨ã„ã†ï¼ã¤ã¾ã‚Šï¼Œ\n\\[\n\\operatorname{Med}(X) = \\left\\{\\begin{array}{cl}\nx_{[k]} & \\text{where } n = 2k-1\\\\\n\\displaystyle \\frac{x_{[k]} + x_{[k+1]}}{2} & \\text{where } n = 2k\n\\end{array}\\right.\n\\]\n\n â–¶Â  Hodges-Lehmannæ¨å®šé‡\næ¨™æœ¬ã®ä¸­ã‹ã‚‰ãƒšã‚¢ã‚’é¸ã³ï¼Œãã®ãƒ˜ã‚¢ã®å¹³å‡ã®ä¸­å¤®å€¤ã‚’ç”¨ã„ã¦ä¸­å¤®å€¤ã‚’æ¨å®šã™ã‚‹ã®ãŒãƒ›ãƒƒã‚¸ã‚¹ãƒ¬ãƒ¼ãƒãƒ³æ¨å®šå€¤ã§ã™ï¼\n\\[\n\\hat\\mu_{HL} = \\operatorname{Med}\\bigg(\\bigg\\{\\frac{x_i + x_j}{2}\\bigg\\}_{1\\leq i \\leq j \\le n}\\bigg)\n\\]\ncomputationä¸Šå°‘ã—é‡ãŸã„ã§ã™ãŒè¨ˆç®—ä¾‹ã¨ã—ã¦ä»¥ä¸‹ï¼Œ\n\nimport itertools\n\ndef HL_mean(x: list[tuple]):\n    return np.median([np.mean(t) for t in itertools.combinations(x, 2)])\n\nX_0 = np.array([5.6, 5.7, 5.4, 5.5, 5.8, 5.2, 5.3, 5.6, 5.4, 55.5])\nprint(HL_mean(X_0))\n\n5.55\n\n\n\nTheorem: Asymptotic distribution of sample quantile-p \n\\(y_1, \\cdots, y_n\\) ã‚’ density function \\(f\\) åŠã³quantile function \\(Q^{(p)}\\) ã‚’æŒã¤åˆ†å¸ƒã‹ã‚‰ã®i.i.dã¨ã—ã¾ã™ï¼ã“ã®ã¨ã, sample quantile \\(\\hat Q^{(p)}\\) ã¯\n\\[\n\\sqrt{n}(\\hat Q^{(p)} - Q^{(p)}) \\rightarrow_d \\mathbb N\\left(0,\\frac{p(1-p)}{f(Q^{(p)})^2}\\right)\n\\]\n\nã“ã“ã§ã¯ï¼Œé€£ç¶šå¤‰æ•°åˆ†å¸ƒã‚’æƒ³å®šã—ã¦è§£èª¬ã—ã¾ã™ï¼é€£ç¶šãªdensity function \\(f_x\\) ã‚’æŒã¤é€£ç¶šç¢ºç‡åˆ†å¸ƒ \\(F\\) ã¨ã„ã†åˆ†å¸ƒã«ã¤ã„ã¦\n\\[\nX = \\{x_1, \\cdots, x_n\\}  \\overset{\\mathrm{iid}}{\\sim} F\n\\]\nã¨ç¢ºç‡å¤‰æ•°åˆ—ãŒä¸ãˆã‚‰ã‚ŒãŸã¨ã—ã¾ã™ï¼ã“ã®ç¢ºç‡å¤‰æ•°ã«å¯¾ã—ã¦\n\\[\nZ_i\\equiv 1\\{x_i \\leq x\\}\n\\]\nã¨ã„ã†å¤‰æ•°ã‚’è€ƒãˆã¾ã™ï¼ã“ã® \\(Z_i\\) ã¯ Bernoulliåˆ†å¸ƒã«å¾“ã†ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã®ã§ï¼Œ\\(F\\) ã®CDFã‚’ \\(F_X\\) ã¨ãŠãã¨\n\\[\n\\begin{align*}\n\\mathbb E(Z_i) &=  \\mathbb E\\left(I\\{X_i\\le x\\}\\right) = P(X_i\\le x)=F_X(x)\\\\\n\\operatorname{Var}(Z_i) &= F_X(x)[1-F_X(x)]\n\\end{align*}\n\\]\nã“ã“ã§ï¼Œ\\(Z_i\\) ã®sample meanã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ï¼\n\\[\nY_n(x) =  \\frac 1n\\sum_{i=1}^nZ_i\n\\]\nã“ã®ã‚ˆã†ã«å®šç¾©ã—ãŸ \\(Y_n(x)\\) ã¯ã„ã‚ã‚†ã‚‹çµŒé¨“åˆ†å¸ƒé–¢æ•° \\(F_n(x)\\) ã§ã‚ã‚‹ã¨ã¿ãªã›ã¾ã™ï¼ã¾ãŸï¼Œå®šç¾©ã‚ˆã‚Š\n\\[\n\\begin{align*}\n&E[F_n(x)] = F_X(x)\\\\\n&\\operatorname{Var}(F_n(x)) = (1/n)F_X(x)[1-F_X(x)]\\\\\n&\\sqrt n\\Big(F_n(x) - F_X(x)\\Big) \\rightarrow_d \\mathbb N\\left(0,F_X(x)[1-F_X(x)]\\right) \\because{\\text{CLT}}\n\\end{align*}\n\\]\nã“ã“ã§CDFã®é€†é–¢æ•° \\(F^{-1}_X\\) ã¨ã™ã‚‹(monotonicityã‚ˆã‚Šè‡ªæ˜)ã¨ delta methodã‚’ç”¨ã„ã‚‹ã¨\n\\[\n\\begin{align*}\n&\\frac {d}{dt}F^{-1}_X(t) = \\frac 1{f_x\\left(F^{-1}_X(t)\\right)}\\\\\n&\\sqrt n\\Big(F^{-1}_X(F_n(x)) - F^{-1}_X(F_X(x))\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {F_X(x)[1-F_X(x)]}{\\left[f_x\\left(F^{-1}_X(F_X(x))\\right)\\right]^2} \\right)\n\\end{align*}\n\\]\nã¤ã¾ã‚Šï¼Œ\n\\[\n\\sqrt n\\Big(F^{-1}_X(F_n(x)) - x\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {F_X(x)[1-F_X(x)]}{\\left[f_x(x)\\right]^2} \\right)\n\\]\nã“ã“ã§ \\(x = m\\)(population median)ã¨è¨­å®šã™ã‚‹ã¨\n\\[\n\\sqrt n\\Big(F^{-1}_X(F_n(m)) - m\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {1}{\\left[2f_x(m)\\right]^2} \\right)\n\\]\nã¾ãŸï¼Œ\n\\[\nF^{-1}_X(\\hat F_n(m)) = \\inf\\{x : F_X(x) \\geq \\hat F_n(m)\\} = \\inf\\{x : F_X(x) \\geq \\frac 1n \\sum_{i=1}^n I\\{X_i\\leq m\\}\\}\n\\]\nã‚ˆã‚Š, ä¸ç­‰å¼ã®RHSã¯ 1/2 ã«åæŸã™ã‚‹ã®ã§ \\(F^{-1}_X(\\hat F_n(m))\\) ã¯sample mean \\(\\hat m\\) ã«åæŸã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼å¾“ã£ã¦ï¼Œ\n\\[\n\\sqrt n\\Big(\\hat m - m\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {1}{\\left[2f_x(m)\\right]^2} \\right)\n\\]\n\n\nTheorem 1.2 æ¨™æœ¬å¹³å‡ã¨Medianã®è·é›¢ \nç‹¬ç«‹ã«åŒä¸€ã®åˆ†å¸ƒã«å¾“ã†ç¢ºç‡å¤‰æ•°åˆ— \\(\\{X_i\\}_{i=1}^n\\) ã‚’è€ƒãˆã‚‹ï¼ã“ã®æ¨™æœ¬å¹³å‡ã‚’ \\(\\overline{X}\\), ä¸ååˆ†æ•£ã‚’ \\(S^2\\), ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ \\(X_{\\operatorname{med}}\\) ã¨ã™ã‚‹ã¨\n\\[\n\\vert \\overline{X} - X_{\\operatorname{med}}\\vert &lt; S\n\\]\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(X_{\\operatorname{med}}\\) ã¯L1ãƒãƒ«ãƒ ã®å’Œã‚’æœ€å°ã«ã™ã‚‹ã‚ˆã†ãªå€¤ã§ã‚ã‚‹ã®ã§\n\\[\n\\begin{align*}\n\\vert \\overline{X} - X_{\\operatorname{med}}\\vert\n    &= \\bigg\\vert \\frac{1}{n}\\sum_{i=1}^n(X_i - X_{\\operatorname{med}})\\bigg\\vert\\\\\n    &\\leq \\frac{1}{n}\\sum_{i=1}^n\\bigg\\vert X_i - X_{\\operatorname{med}}\\bigg\\vert\\\\\n    &\\leq\\frac{1}{n}\\sum_{i=1}^n\\bigg\\vert X_i - \\overline{X}\\bigg\\vert\\\\\n    &\\leq\\sqrt{\\frac{1}{n}\\sum_{i=1}^n( X_i - \\overline{X})^2}\\\\\n    &=\\sqrt{\\frac{n-1}{n}}S\\\\\n    &\\leq S\n\\end{align*}\n\\]",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>ä»£è¡¨å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#åˆ†æ•£ã¨æ¨™æº–åå·®",
    "href": "posts/statistics101/averages.html#åˆ†æ•£ã¨æ¨™æº–åå·®",
    "title": "1Â  ä»£è¡¨å€¤",
    "section": "åˆ†æ•£ã¨æ¨™æº–åå·®",
    "text": "åˆ†æ•£ã¨æ¨™æº–åå·®\n\nDef: Variance \nmean \\(\\mu\\) ã‚’ã‚‚ã¤ç¢ºç‡å¤‰æ•° \\(X\\) ã®åˆ†æ•£ã¯\n\\[\n\\begin{align*}\n\\operatorname{Var}(X) &= \\mathbb E[(X - \\mu)^2]\\\\\n                      &= \\mathbb E[X^2] - \\mathbb E[X]^2\n\\end{align*}\n\\]\næ¨™æº–åå·®(standard deviation)ã¯åˆ†æ•£ã®square rootã§å®šç¾©ã•ã‚Œã‚‹ï¼\n\nä¸Šã®å®šç¾©ã‚ˆã‚Šæ¨™æº–åå·®ã«ã¤ã„ã¦ä»¥ä¸‹ã®ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼š\n\n\\(X\\) ã¨åŒã˜å˜ä½ã§è¡¨ã•ã‚Œã‚‹\n\\(X - \\mathbb E[X]\\) ã® L2ãƒãƒ«ãƒ ã¨è§£é‡ˆã§ãã‚‹\npopulation meanã‹ã‚‰ã©ã‚Œã ã‘åˆ†å¸ƒãŒãƒãƒ©ã¤ã„ã¦ã„ã‚‹ã‹(dispersion)ã‚’ç¤ºã™æŒ‡æ¨™ã®ä¸€ã¤\n\n\n\nTheorem 1.3 \nç¢ºç‡å¤‰æ•° \\(X\\sim D(\\mu, \\sigma^2)\\) ã¨ã™ã‚‹ï¼ã“ã®ã¨ã\n\\[\n\\begin{align*}\n\\mathbb E[\\vert X - \\mu\\vert] \\leq \\sigma\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\nProof: Jensenâ€™s Inequality\n\n\n\n\n\n\\(g(x) = \\sqrt{x}\\) ã¨ã„ã†é–¢æ•°ã¯concaveãªã®ã§ï¼ŒJensenâ€™s Inequalityã‚ˆã‚Š\n\\[\n\\begin{align*}\n\\mathbb E[\\vert X - \\mu \\vert]\n    &= \\mathbb E[\\sqrt{( X - \\mu)^2}]\\\\\n    &\\leq \\sqrt{\\mathbb E[( X - \\mu)^2]}\\\\\n    &= \\sigma\n\\end{align*}\n\\]\n\n\n\n\nå¤‰å‹•ä¿‚æ•°\nç¢ºç‡å¤‰æ•°ã®ãƒãƒ©ãƒ„ã‚­ã‚’è¡¨ã™æŒ‡æ¨™ã¨ã—ã¦ç¯„å›²(Range), å››åˆ†ä½ç¯„å›²ï¼ˆIQRï¼‰, åˆ†æ•£ãŒã‚ã‚Šã¾ã™ãŒï¼Œåˆ†å¸ƒã®ä¸­å¿ƒã®ä½ç½®ãŒè‘—ã—ãç•°ãªã‚‹ã‚ˆã†ãªå ´åˆ ã«ã¯ï¼Œã“ã‚Œã‚‰ã‚’ç”¨ã„ã¦åˆ†å¸ƒã®æ•£ã‚‰ã°ã‚Šå…·åˆã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ã¯é›£ã—ã„ã§ã™ï¼ã“ã®ã‚ˆã†ãªå ´åˆã«ï¼Œå¤‰å‹•ä¿‚æ•°(Coefficient of variation) ã¨ã„ã†å˜ä½ã®ãªã„çµ±è¨ˆé‡ã‚’ç”¨ã„ãŸã‚Šã—ã¾ã™ï¼\n\nDef: Coefficient of variation \næ¯”ä¾‹å°ºåº¦ã«ã‚‚ã¨ã¥ãæ¸¬å®šãŒè¡Œã‚ã‚Œï¼Œãã®æ¸¬å®šçµæœã‚’non-negative ç¢ºç‡å¤‰æ•° \\(X_i &gt;0\\) ã§è¡¨ã™ã¨ã™ã‚‹ï¼\\(\\{X_i\\}_{i=1}^n\\) ã®æ¨™æœ¬å¹³å‡ã‚’ \\(\\overline{X}\\), æ¨™æœ¬æ¨™æº–åå·®ã‚’ \\(S\\) ã¨ã—ãŸã¨ãï¼Œå¤‰å‹•ä¿‚æ•°ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã‚‹\n\\[\n\\operatorname{C_V} = \\frac{S}{\\overline{X}}\n\\]\n\nä¸Šè¨˜ã®å®šç¾©ã‚ˆã‚Šä»¥ä¸‹ã®ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™\n\nå¤‰å‹•ä¿‚æ•°ã¯ï¼Œå®Ÿéš›ã®ã‚¼ãƒ­ç‚¹ã‚’æŒã¤æ¸¬å®šå€¤ï¼ˆi.e., æ¯”ç‡å°ºåº¦ï¼‰ã«å¯¾ã—ã¦ã®ã¿ç”¨ã„ã‚‹ã“ã¨ãŒã§ãã¾ã™\nå¤‰å‹•ä¿‚æ•°ã®è¨ˆç®—å¯¾è±¡ã¨ãªã‚‹æ¸¬å®šã¯ï¼Œnon-negativeã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹\nã‚µã‚¤ã‚º \\(N\\) ã®finite sampleã«ãŠã‘ã‚‹ \\(\\operatorname{C_V}\\) ã®ãƒ¬ãƒ³ã‚¸ã¯ \\(\\operatorname{CV}\\in[0, \\sqrt{N-1}]\\) ã§ã‚ã‚‹\n\n\nExample 1.1 æ±äº¬ æ—¥å¹³å‡æ°—æ¸©ã®æœˆå¹³å‡å€¤ï¼ˆâ„ƒï¼‰ \nå›½åœŸäº¤é€šçœæ°—è±¡åºã‚ˆã‚Šä»¥ä¸‹ã®ã‚ˆã†ã«æ±äº¬éƒ½ã®æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ï¼\n\n\nCode\nimport polars as pl\nimport plotly.express as px\n\ndata = {\n    \"Year\": [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023],\n    \"Jan\": [5.8, 6.1, 5.8, 4.7, 5.6, 7.1, 5.4, 4.9, 5.7],\n    \"Feb\": [5.7, 7.2, 6.9, 5.4, 7.2, 8.3, 8.5, 5.2, 7.3],\n    \"Mar\": [10.3, 10.1, 8.5, 11.5, 10.6, 10.7, 12.8, 10.9, 12.9],\n    \"Apr\": [14.5, 15.4, 14.7, 17.0, 13.6, 12.8, 15.1, 15.3, 16.3],\n    \"May\": [21.1, 20.2, 20.0, 19.8, 20.0, 19.5, 19.6, 18.8, 19.0],\n    \"Jun\": [22.1, 22.4, 22.0, 22.4, 21.8, 23.2, 22.7, 23.0, 23.2],\n    \"Jul\": [26.2, 25.4, 27.3, 28.3, 24.1, 24.3, 25.9, 27.4, 28.7],\n    \"Aug\": [26.7, 27.1, 26.4, 28.1, 28.4, 29.1, 27.4, 27.5, 29.2],\n    \"Sep\": [22.6, 24.4, 22.8, 22.9, 25.1, 24.2, 22.3, 24.4, 26.7],\n    \"Oct\": [18.4, 18.7, 16.8, 19.1, 19.4, 17.5, 18.2, 17.2, 18.9],\n    \"Nov\": [13.9, 11.4, 11.9, 14.0, 13.1, 14.0, 13.7, 14.5, 14.4],\n    \"Dec\": [9.3, 8.9, 6.6, 8.3, 8.5, 7.7, 7.9, 7.5, 9.4],\n}\n\ndf = pl.DataFrame(data)\ndf_unpivoted = df.unpivot(index=\"Year\", variable_name=\"Month\", value_name=\"Celsius\")\npx.line(df_unpivoted, x=\"Month\", y=\"Celsius\", color=\"Year\", title=\"æ±äº¬éƒ½æœˆåˆ¥å¹³å‡æ°—æ¸©\")\n\n\n                                                \n\n\nã“ã“ã§ï¼Œä»¥ä¸‹ã®ã‚ˆã†ã«Fahrenheitã«å¤‰æ›ã—ã¦ã¿ã¾ã™ï¼\n\n\nCode\ndf_unpivoted = df_unpivoted.with_columns(\n    (pl.col(\"Celsius\") * 9 / 5 + 32).alias(\"Fahrenheit\")\n)\ndf_unpivoted.head()\n\n\n\nshape: (5, 4)\n\n\n\nYear\nMonth\nCelsius\nFahrenheit\n\n\ni64\nstr\nf64\nf64\n\n\n\n\n2015\n\"Jan\"\n5.8\n42.44\n\n\n2016\n\"Jan\"\n6.1\n42.98\n\n\n2017\n\"Jan\"\n5.8\n42.44\n\n\n2018\n\"Jan\"\n4.7\n40.46\n\n\n2019\n\"Jan\"\n5.6\n42.08\n\n\n\n\n\n\nã“ã“ã§ï¼ŒCelsius, Fahrenheitä¸¡æ–¹ã®ã‚«ãƒ©ãƒ ã«ã¤ã„ã¦å¤‰å‹•ä¿‚æ•°ã‚’è¨ˆç®—ã—ã¾ã™ï¼\n\n\nCode\ndef compute_cv(df, col: str) -&gt; float:\n    return df_unpivoted[col].std() / df_unpivoted[col].mean()\n\n\nprint(\n    \"\"\"Celsius CV: {:.2f}, Fahrenheit CV: {:.2f}\"\"\".format(\n        compute_cv(df_unpivoted, \"Celsius\"), compute_cv(df_unpivoted, \"Fahrenheit\")\n    ))\n\n\nCelsius CV: 0.45, Fahrenheit CV: 0.22\n\n\nã“ã®ã‚ˆã†ã«ï¼ŒCelsius, Fahrenheitã¨ã‚‚ã«åŒã˜æ¸©åº¦ã‚’å˜ä½ã®é•ã†æ–¹æ³•ã§è¡¨ã—ã¦ã„ã‚‹ã®ã«ã‚‚é–¢ã‚ã‚‰ãšå¤‰å‹•ä¿‚æ•°ã¯ç•°ãªã‚Šã¾ã™ï¼Celsius, Fahrenheitã¨ã‚‚ã«é–“éš”å°ºåº¦ã§ã‚ã‚‹ã“ã¨ï¼ŒåŠã³å¤‰æ•°å¤‰æ›ã®è¦³ç‚¹ã‹ã‚‰ã‚‚location/scale parameterã‚’ç•°ãªã‚‹å€¤ã§èª¿æ•´ã—ã¦ã„ã‚‹ã®ã§åŒã˜ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã£ã¦ã„ã‚‹ã«ã‚‚é–¢ã‚ã‚‰ãšCVãŒä¸€è‡´ã—ãªã„ã¨ã„ã†ç¾è±¡ãŒç™ºç”Ÿã—ã¦ã—ã¾ã„ã¾ã™ï¼\n\n â–¶Â  Bias Correction\nã‚µã‚¤ã‚º \\(N\\) ã®sampleãƒ™ãƒ¼ã‚¹ã§è¨ˆç®—ã•ã‚ŒãŸå¤‰å‹•ä¿‚æ•°ã¯populationå¤‰å‹•ä¿‚æ•° \\(\\gamma_V\\) ã¨æ¯”è¼ƒã—ã¦éå°æ¨å®šã•ã‚Œã¦ã„ã‚‹ã¨ã„ã†ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ï¼populationå¤‰å‹•ä¿‚æ•°ã®unbiased estimate \\(\\widehat{\\operatorname{C_V}}\\) ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã¾ã™\n\\[\n\\widehat{\\operatorname{C_V}} = \\left(1 + \\frac{1}{4N}\\right)\\operatorname{C_V}\n\\]",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>ä»£è¡¨å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#references",
    "href": "posts/statistics101/averages.html#references",
    "title": "1Â  ä»£è¡¨å€¤",
    "section": "References",
    "text": "References\n\nYutaka Sasaki, The truth of the F-measure, 2007",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>ä»£è¡¨å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/density_function.html",
    "href": "posts/statistics101/density_function.html",
    "title": "2Â  ç¢ºç‡å¯†åº¦é–¢æ•°",
    "section": "",
    "text": "é€£ç¶šç¢ºç‡å¤‰æ•°ã¨ç¢ºç‡å¯†åº¦é–¢æ•°\n\\(f\\) ã®non-negativityæ€§è³ªã¯ï¼Œç´¯ç©åˆ†å¸ƒé–¢æ•°ã¯non-decreasingã§ã‚ã‚‹ã“ã¨ï¼ŒåŠã³ \\(F^\\prime(x) = f(x)\\) ã§ã‚ã‚‹ã“ã¨ã‹ã‚‰åˆ†ã‹ã‚‹ï¼ ã¾ãŸç¢ºç‡å¤‰æ•° \\(X\\) ãŒç¢ºç‡å¯†åº¦é–¢æ•° \\(f(x)\\) ã‚’æŒã¤ã¨ãï¼Œã€Œ\\(X\\) ã¯ \\(f(x)\\) ã«å¾“ã†ã€ã¨ã‚ˆãè¨€ã‚ã‚Œã‚‹ï¼",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>ç¢ºç‡å¯†åº¦é–¢æ•°</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/density_function.html#é€£ç¶šç¢ºç‡å¤‰æ•°ã¨ç¢ºç‡å¯†åº¦é–¢æ•°",
    "href": "posts/statistics101/density_function.html#é€£ç¶šç¢ºç‡å¤‰æ•°ã¨ç¢ºç‡å¯†åº¦é–¢æ•°",
    "title": "2Â  ç¢ºç‡å¯†åº¦é–¢æ•°",
    "section": "",
    "text": "Def: çµ¶å¯¾é€£ç¶šå‹ã®ç¢ºç‡å¤‰æ•° \nç´¯ç©åˆ†å¸ƒé–¢æ•° \\(F\\) ã‚’ã‚‚ã¤ç¢ºç‡å¤‰æ•° \\(X\\) ãŒæ¬¡ã®æ¡ä»¶ã‚’æº€ãŸã™ç¢ºç‡å¯†åº¦é–¢æ•° \\(f\\) ã‚’æŒã¤ã¨ãï¼Œçµ¶å¯¾é€£ç¶š(absolutely continuous)ã¨ã„ã†ï¼š\n\\[\n\\begin{gather}\nf(x) \\geq 0 \\quad \\forall x\\\\\nF(b) - F(a) = \\int^b_a f(x)\\mathrm{d}x \\quad \\text{where } a\\leq b\n\\end{gather}\n\\]\n\n\n\n\nTheorem 2.1 å¤‰æ•°å¤‰æ›ã¨ç¢ºç‡å¯†åº¦é–¢æ•° \n\\(f\\) ã‚’ç¢ºç‡å¯†åº¦é–¢æ•°ï¼Œ\\(a &gt; 0\\) ã¨ã—ï¼Œ\n\\[\ng(x) = af(ax)\n\\]\nã¨é–¢æ•° \\(g\\) ã‚’å®šç¾©ã™ã‚‹ã¨\n\\[\n\\int^\\infty_{-\\infty} g(x)\\mathrm{d} x = 1\n\\]\nã¨ãªã‚‹\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(a &gt; 0, f\\geq 0\\) ã‚ˆã‚Š \\(g\\geq 0\\) ã¯è‡ªæ˜ï¼ã¾ãŸï¼Œ\\(ax = z\\) ã¨å¤‰æ•°å¤‰æ›ã™ã‚‹ã¨\n\\[\n\\begin{align*}\n\\int^\\infty_{-\\infty} g(x)\\mathrm{d} x &= \\int^\\infty_{-\\infty} af(ax)\\mathrm{d} x \\\\\n                                       &= \\int^\\infty_{-\\infty} af(z) \\frac{\\mathrm{d} x}{\\mathrm{d} z}\\mathrm{d} z\\\\\n                                       &= \\int^\\infty_{-\\infty} af(z) \\frac{1}{a}\\mathrm{d} z = 1\n\\end{align*}\n\\]",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>2</span>Â  <span class='chapter-title'>ç¢ºç‡å¯†åº¦é–¢æ•°</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html",
    "href": "posts/statistics101/expectation.html",
    "title": "3Â  æœŸå¾…å€¤",
    "section": "",
    "text": "æœŸå¾…å€¤ã®æ€§è³ª\nå®šç¾©ã‚ˆã‚Šç¢ºç‡å¯†åº¦é–¢æ•°ã§é‡ã¿ã¥ã‘ãŸå¹³å‡ãŒç¢ºç‡å¤‰æ•°ã®æœŸå¾…å€¤ã«ãªã‚‹ã¨è§£é‡ˆã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼meanã¯åˆ†å¸ƒã®ä½ç½®ã‚’è¡¨ã™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¨ã‚‚è§£é‡ˆã§ãã‚‹ã®ã§ location parameterï¼ˆä½ç½®æ¯æ•°ï¼‰ã¨å‘¼ã¶ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ï¼ä¸€æ–¹ï¼Œæ¨™æº–åå·® \\(\\sigma\\) ã¯scale parameterï¼ˆå°ºåº¦æ¯æ•°ï¼‰ã¨ã„ã„ã¾ã™ï¼",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>æœŸå¾…å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html#æœŸå¾…å€¤ã®æ€§è³ª",
    "href": "posts/statistics101/expectation.html#æœŸå¾…å€¤ã®æ€§è³ª",
    "title": "3Â  æœŸå¾…å€¤",
    "section": "",
    "text": "Def: é€£ç¶šç¢ºç‡å¤‰æ•°ã®æœŸå¾…å€¤ \n\\(f\\) ã‚’ç¢ºç‡å¤‰æ•° \\(X\\) ã®ç¢ºç‡å¯†åº¦é–¢æ•°ã¨ã™ã‚‹ï¼\\(\\int_{\\mathbb R} \\vert x\\vert f(x) \\mathrm{d}x &lt; \\infty\\) ã®ã¨ãï¼Œ\\(X\\) ã®æœŸå¾…å€¤ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹:\n\\[\n\\mathbb E[X] = \\int_{\\mathbb R} x f(x) \\mathrm{d}x\n\\]\nã¾ãŸï¼Œ\\(X\\) ã®é–¢æ•° \\(g(X)\\) ã®æœŸå¾…å€¤ã¯ \\(\\int_{\\mathbb R} \\vert g(x)\\vert f(x) \\mathrm{d}x &lt; \\infty\\) ãªã‚‰ã°\n\\[\n\\mathbb E[g(X)] = \\int_{\\mathbb R} g(x) f(x) \\mathrm{d}x\n\\]\n\n\n\nExample 3.1 æŒ‡æ•°åˆ†å¸ƒã®æœŸå¾…å€¤ \nrate parameter \\(\\lambda\\) ã®æŒ‡æ•°åˆ†å¸ƒã«å¾“ã†ç¢ºç‡å¤‰æ•° \\(X\\) ã‚’è€ƒãˆã¾ã™ï¼\n\\[\n\\begin{align*}\n\\mathbb E[X] &= \\int^\\infty_0 x \\lambda \\exp(-\\lambda x)\\mathrm{d}x\\\\\n             &= \\bigg[-x\\exp(-\\lambda x)\\bigg]^\\infty_0 + \\int^\\infty_0 \\exp(-\\lambda x)\\mathrm{d}x\\\\\n             &= \\int^\\infty_0 \\exp(-\\lambda x)\\mathrm{d}x\\\\\n             &= -\\frac{1}{\\lambda}\\bigg[\\exp(-\\lambda x)\\bigg]^\\infty_0\\\\\n             &= \\frac{1}{\\lambda}\n\\end{align*}\n\\]\næŒ‡æ•°åˆ†å¸ƒã¯é›»çƒã®å¯¿å‘½ãªã©ã«å¿œç”¨ã•ã‚Œã‚‹åˆ†å¸ƒã§ã™ãŒï¼Œrate parameter \\(\\lambda\\) ãŒå°ã•ã„ã»ã©æœŸå¾…å€¤ï¼ˆ= é›»çƒã®å¯¿å‘½ï¼‰ãŒå¤§ãããªã‚‹ã“ã¨ãŒåˆ†ã‹ã‚Šã¾ã™ï¼\n\n\nExample 3.2 æœŸå¾…å€¤ãŒå®šç¾©ã§ããªã„é›¢æ•£åˆ†å¸ƒ \nç¢ºç‡å¤‰æ•° \\(X\\) ã®supportã‚’åŠ ç®—é›†åˆ \\(\\{2, 2^2, 2^3, \\cdots\\}\\) ã¨ã™ã‚‹ï¼ç¢ºç‡é–¢æ•°ã‚’\n\\[\n\\Pr(X = 2^i) = \\frac{1}{2^i} \\quad (i = 1, 2, \\cdots)\n\\]\nã“ã®ã¨ãï¼Œ\n\\[\n\\sum_{i=1}^\\infty \\Pr(X=2^i) = \\sum_{i=1}^\\infty\\frac{1}{2^i} = 1\n\\]\nã¨ç¢ºç‡ã®å…¬ç†ã‚’æº€ãŸã—ã¦ã„ã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ï¼ä¸€æ–¹ï¼Œ\n\\[\n\\begin{align*}\n\\mathbb E[X]\n    &= \\sum_{i=1}^\\infty 2^i \\frac{1}{2^i}\\\\\n    &= \\sum_{i=1}^\\infty 1 = \\infty\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œç¢ºç‡å¤‰æ•° \\(X\\) ã®åˆ†å¸ƒã¯ï¼ŒæœŸå¾…å€¤ãŒå®šç¾©ã§ããªã„åˆ†å¸ƒã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼\n\n\nExample 3.3 æœŸå¾…å€¤ãŒå®šç¾©ã§ããªã„é€£ç¶šåˆ†å¸ƒ \nç¢ºç‡å¯†åº¦é–¢æ•° \\[\nf(x) = \\begin{cases}\n0 & x &lt; 1\\\\\n\\frac{1}{x^2} & x\\geq 1\n\\end{cases}\n\\]\nã¨ã„ã†ç¢ºç‡å¤‰æ•° \\(X\\) ã‚’è€ƒãˆã‚‹ï¼\n\\[\n\\begin{align*}\n\\int_1^\\infty f(x) \\mathrm{d}x\n    &= \\left[\\frac{1}{x}\\right]^1_\\infty = 1\n\\end{align*}\n\\]\nä¸€æ–¹ï¼Œ\n\\[\n\\begin{align*}\n\\mathbb E[X]\n    &= \\int_1^\\infty xf(x) \\mathrm{d}x\\\\\n    &= \\int_1^\\infty\\frac{1}{x}\\mathrm{d}x\\\\\n    &= \\left[\\log(x)\\right]_1^\\infty = \\infty\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œç¢ºç‡å¤‰æ•° \\(X\\) ã®åˆ†å¸ƒã¯ï¼ŒæœŸå¾…å€¤ãŒå®šç¾©ã§ããªã„åˆ†å¸ƒã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼\n\n\n\nTheorem 3.1 Tail probabilities \n\\([0, b]\\) ã®å®šç¾©åŸŸã‚’ã‚‚ã¤éè² ç¢ºç‡å¤‰æ•° \\(X\\) ã‚’è€ƒãˆã‚‹ï¼\\(F\\) ã‚’ç´¯ç©åˆ†å¸ƒé–¢æ•°ã¨ã™ã‚‹ã¨ã\n\\[\n\\mathbb E[X] = \\int_0^b (1 - F(x))\\mathrm{d}x\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\bigg[xF(x)\\bigg]^b_0 = \\int^b_0xf(x) \\mathrm{d}x + \\int^b_0F(x) \\mathrm{d}x\n\\]\nã‚’ç”¨ã„ã‚‹ã¨\n\\[\n\\begin{align*}\n\\mathbb E[X] &= b - \\int^b_0F(x) \\mathrm{d}x\\\\\n             &= \\int^b_0 1 \\mathrm{d}x - \\int^b_0F(x) \\mathrm{d}x\\\\\n             &= \\int_0^b (1 - F(x))\\mathrm{d}x\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.2 \n\\([0, \\infty)\\) ã®å®šç¾©åŸŸã‚’ã‚‚ã¤éè² ç¢ºç‡å¤‰æ•° \\(X\\) ã‚’è€ƒãˆã‚‹ï¼\\(\\mathbb E[\\vert X^{p+1} \\vert] &lt;\\infty\\) ãŒå®šç¾©å¯èƒ½åŠã³ï¼Œ \\(F\\) ã‚’ç´¯ç©åˆ†å¸ƒé–¢æ•°ã¨ã™ã‚‹ã¨ã\n\\[\n\\mathbb E[X^p] = \\int_0^\\infty px^{p-1} (1 - F(x))\\mathrm{d}x \\quad \\text{where } p &gt; 0\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\bigg[x^p(1 - F(x))\\bigg]^\\infty_0 = \\int^\\infty_0 p x^{p-1}(1 -F(x))\\mathrm{d}x - \\int^\\infty_0 x^{p}f(x)\\mathrm{d}x\n\\end{align*}\n\\]\n\\(\\text{RHS} = 0\\) ã§ã‚ã‚‹ã®ã§\n\\[\n\\mathbb E[X^p] = \\int_0^\\infty px^{p-1} (1 - F(x))\\mathrm{d}x\n\\]\n\n\n\n\nExample 3.4 \nåŒæ§˜ã®è€ƒãˆã§å®šç¾©åŸŸã‚’ \\(0,1,2,3,\\cdots\\) ã¨ã™ã‚‹é›¢æ•£ç¢ºç‡å¤‰æ•° \\(X\\) ã«ã¤ã„ã¦\n\\[\n\\mathbb E[X] = \\sum_{k=0}^\\infty \\Pr(X &gt; k)\n\\]\nãŒæˆç«‹ã—ã¾ã™ï¼\n\\[\n\\begin{align*}\n\\Pr(X &gt; k) &= \\Pr(X = k+1) + \\Pr(X = k+2) + \\cdots\\\\\n           &= \\sum_{l=k+1}^\\infty \\Pr(X=l)\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\begin{align*}\n\\sum_{k=0}^\\infty \\Pr(X &gt; k) &= \\sum_{k=0}^\\infty \\sum_{l=k+1}^\\infty \\Pr(X=l)\\\\\n                             &= \\sum_{l=1}^\\infty\\sum_{k=0}^{l-1}\\Pr(X=l) \\quad\\because \\Pr(X=l) &gt; 0 \\\\\n                             &= \\sum_{l=1}^\\infty l\\Pr(X=l)\\\\\n                             &= \\sum_{l=0}^\\infty l\\Pr(X=l)\\\\\n                             &= \\mathbb E[X]\n\\end{align*}\n\\] \\[\\tag*{\\(\\blacksquare\\)}\\]\n\n\nExample 3.5 \n\\(0,1,2,3,\\cdots\\) ã¨ã™ã‚‹é›¢æ•£ç¢ºç‡å¤‰æ•° \\(X\\) ã«ã¤ã„ã¦\n\\[\n\\mathbb E[X^2] = \\sum_{k=0}^\\infty \\Pr(X &gt; k)(2k+1)\n\\]\nã‚‚æˆç«‹ã™ã‚‹ï¼\n\\[\n\\begin{align*}\n\\sum_{k=0}^\\infty \\Pr(X &gt; k)(2k+1)\n    &= \\sum_{k=0}^\\infty \\sum_{l=k+1}^\\infty \\Pr(X=l)(2k+1)\\\\\n    &= \\sum_{l=1}^\\infty \\sum_{k=0}^{l-1}\\Pr(X=l)(2k+1)\\\\\n    &= \\sum_{l=1}^\\infty \\Pr(X=l)\\sum_{k=0}^{l-1}(2k+1)\\\\\n    &= \\sum_{l=1}^\\infty l^2\\Pr(X=l)\\\\\n    &= \\mathbb E[X^2]\n\\end{align*}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]\n\n\n\nTheorem 3.3 æœŸå¾…å€¤ã®ç·šå‹æ€§ \n\\(a, b\\) ã‚’å®Ÿæ•°ï¼Œç¢ºç‡å¤‰æ•° \\(X, Y\\) ã«ã¤ã„ã¦ä»¥ä¸‹ãŒæˆã‚Šç«‹ã¤\n\\[\n\\mathbb E[aX + bY] = a\\mathbb E[X] + b\\mathbb E[Y]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nç¢ºç‡å¤‰æ•° \\(X, Y\\) ãŒæœ‰é™åŠ ç®—ãªæ¨™æœ¬ç©ºé–“ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã«ã¦ä»¥ä¸‹ã‚’ç¤ºã™ï¼\n\n\\(\\mathbb E[X + Y] = \\mathbb E[X] + \\mathbb E[Y]\\)\n\\(\\mathbb E[cX] = c\\mathbb E[X]\\)\n\n â–¶Â  1. \\(\\mathbb E[X + Y] = \\mathbb E[X] + \\mathbb E[Y]\\)\nç¢ºç‡å¤‰æ•° \\(X\\) ã¯ \\(\\{x_1, \\cdots, x_m\\}\\), ç¢ºç‡å¤‰æ•° \\(Y\\) ã¯ \\(\\{y_1, \\cdots, y_n\\}\\) ã®å€¤ã‚’ãã‚Œãã‚Œå–ã‚Šã†ã‚‹ã¨ã™ã‚‹ï¼ ã“ã®ã¨ãï¼Œ\\(Z = X + Y\\) ã®æ¨™æœ¬ç©ºé–“ \\(\\{z_1, \\cdots, z_k\\}\\) ã«ã¤ã„ã¦ \\(k\\leq m + n\\) ãŒæˆã‚Šç«‹ã¤ï¼\n\\(A_l = \\{(i,j): x_i + y_j = z_l\\}\\) ã¨ã—ãŸã¨ãï¼Œ\n\\[\n\\begin{align*}\n\\mathbb E[X+Y]\n    &= \\sum_{l=1}^kz_l\\Pr(A_l)\\\\\n    &= \\sum_{l=1}^k\\sum_{(i,j)\\in Z_l}(x_i + y_j)\\Pr(x_i, y_j)\\\\\n    &= \\sum_{i=1}^m\\sum_{j=1}^n(x_i + y_j)\\Pr(x_i, y_j)\\\\\n    &= \\sum_{i=1}^m\\sum_{j=1}^nx_i\\Pr(x_i, y_j) + y_j\\Pr(x_i, y_j)\\\\\n    &= \\sum_{i=1}^m\\sum_{j=1}^n[x_i\\Pr(x_i, y_j) + y_j\\Pr(x_i, y_j)]\\\\\n    &= \\sum_{i=1}^mx_i\\sum_{j=1}^nPr(x_i, y_j) + \\sum_{j=1}^ny_j\\sum_{i=1}^m\\Pr(x_i, y_j)\\\\\n    &=\\sum_{i=1}^mx_i \\Pr(x_i) + \\sum_{j=1}^ny_j \\Pr(y_j)\\\\\n    &= \\mathbb E[X] + \\mathbb E[Y]\n\\end{align*}\n\\]\n â–¶Â  2. \\(\\mathbb E[cX] = c\\mathbb E[X]\\)\n\\[\n\\begin{align*}\n\\mathbb E[cX]\n    &= \\sum_{i=1}^m cx_i = \\Pr(cX = cx_i)\\\\\n    &= c\\sum_{i=1}^m x_i = \\Pr(X = x_i)\\\\\n    &= c\\mathbb E[X]\n\\end{align*}\n\\]\n\n\n\n\nExample 3.6 : å¤‰æ•°å¤‰æ›ã¨åˆ†æ•£ \nmean \\(\\mu\\) ã‚’ã‚‚ã¤ç¢ºç‡å¤‰æ•° \\(X\\) ã¨å®Ÿæ•° \\(a, b\\) ã«ã¤ã„ã¦\n\\[\n\\operatorname{Var}(aX + b) = a^2\\operatorname{Var}(X)\n\\]\nãŒæˆç«‹ã—ã¾ã™ï¼è¨¼æ˜ã¯ä»¥ä¸‹ï¼Œ\n\\[\n\\begin{align*}\n\\operatorname{Var}(aX + b)\n    &= \\mathbb E[(aX + b) - (a\\mu +b)^2]\\\\\n    &= \\mathbb E[a^2(X - \\mu)^2]\\\\\n    &= a^2 \\mathbb E[(X - \\mu)^2]\\\\\n    &= a^2\\operatorname{Var}(X)\n\\end{align*}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]\n\n\n\nTheorem 3.4 positive operator \nç¢ºç‡å¤‰æ•° \\(X, Y\\) ã«ã¤ã„ã¦ï¼Œ\\(X\\geq Y\\) ãŒæˆã‚Šç«‹ã¤ã¨ãï¼Œ\n\\[\n\\mathbb E[X] \\geq \\mathbb E[Y]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(X\\geq Y\\) ã‚ˆã‚Š \\(X - Y \\geq 0\\). æœŸå¾…å€¤ã¯positive operatorãªã®ã§\n\\[\n\\mathbb E[X - Y] \\geq 0\n\\]\nå¾“ã£ã¦ï¼ŒæœŸå¾…å€¤ã®ç·šå‹æ€§ã‚’ç”¨ã„ã‚‹ã¨\n\\[\n\\begin{align*}\n\\mathbb E[X - Y] &= \\mathbb E[X] - \\mathbb E[Y] \\geq 0\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.5 \nç¢ºç‡å¤‰æ•° \\(X\\) ã«ã¤ã„ã¦,\n\\[\n\\mathbb E[\\vert X \\vert] \\geq \\vert \\mathbb E[X] \\vert\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(\\vert X\\vert \\geq X\\) ã‚ˆã‚Š\n\\[\n\\mathbb E[\\vert X \\vert] \\geq \\mathbb E[X]\n\\]\nã¾ãŸ, \\(\\vert X\\vert + X \\geq 0\\) ã‚ˆã‚Šï¼Œ\\(\\mathbb E[\\vert X\\vert + X] \\geq 0\\)ï¼Œ ã¤ã¾ã‚Šï¼Œ\n\\[\n\\mathbb E[\\vert X \\vert] \\geq -\\mathbb E[X]\n\\]\nä»¥ä¸Šã‚ˆã‚Šï¼Œ\\(\\mathbb E[\\vert X \\vert] \\geq \\vert \\mathbb E[X] \\vert\\)\n\n\n\n\n\nTheorem 3.6 äº’ã„ã«ç‹¬ç«‹ãªç¢ºç‡å¤‰æ•°ã®ç©ã®æœŸå¾…å€¤ \n\\(\\mathbb E[\\vert X\\vert ]&lt;\\infty, \\mathbb E[\\vert Y\\vert ]&lt;\\infty\\) ã‚’æº€ãŸã™, ç¢ºç‡ç©ºé–“ \\((\\Omega, \\mathscr{F},P)\\) ä¸Šã§å®šç¾©ã•ã‚ŒãŸç¢ºç‡å¤‰æ•° \\(X, Y\\) ã‚’è€ƒãˆã‚‹ï¼ \\(X \\perp Y\\) ã§ã‚ã‚‹ã¨ãï¼Œæ¬¡ãŒæˆç«‹ã™ã‚‹\n\\[\n\\mathbb E[XY] = \\mathbb E[X]\\mathbb E[Y]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\mathbb E[XY] &= \\int\\int_\\Omega xy f(x, y)\\mathrm{d}x\\mathrm{d}y\\\\\n              &= \\int\\int_\\Omega xy f_X(x)f_Y(y)\\mathrm{d}x\\mathrm{d}y \\quad\\because{\\text{independence}}\\\\\n              &= \\left(\\int xf_X(x)\\mathrm{d}x\\right)\\left(\\int yf_Y(y)\\mathrm{d}y\\right)\\\\\n              &= \\mathbb E[X]\\mathbb E[Y]\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.7 Schwarz inquality \nç¢ºç‡å¤‰æ•° \\(X, Y\\) ã«ã¤ã„ã¦ã‚·ãƒ¥ãƒ¯ãƒ«ãƒ„ã®ä¸ç­‰å¼ãŒæˆç«‹ã™ã‚‹ã“ã¨ã‚’ç¤ºã›\n\\[\n\\left(\\mathbb E[XY]\\right)^2 \\leq \\mathbb E[X^2]\\mathbb E[Y^2]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nQuadratic functionã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã—ã¾ã™\n\\[\n\\begin{align*}\ng(t)\n    &= \\mathbb E[(tX - Y)^2]\\\\\n    &= t^2\\mathbb E[X^2] - 2t\\mathbb E[XY] + E[Y^2]\\\\\n    &\\geq 0\n\\end{align*}\n\\]\nã“ã®ã¨ãï¼Œ\\(g(t)\\) ã¯non-negativeãªã®ã§åˆ¤åˆ¥å¼ã«ã¤ã„ã¦ä»¥ä¸‹ãŒæˆç«‹ã™ã‚‹\n\\[\nD/4 = \\left(\\mathbb E[XY]\\right)^2 - \\mathbb E[X^2]\\mathbb E[Y^2]\\leq 0\n\\]\nå¾“ã£ã¦ï¼Œ\\(\\left(\\mathbb E[XY]\\right)^2 \\leq \\mathbb E[X^2]\\mathbb E[Y^2]\\)\n\n\n\n\n\nTheorem 3.8 : Triangle inequality \nç¢ºç‡å¤‰æ•° \\(X, Y\\) ã«ã¤ã„ã¦ï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªä¸‰è§’ä¸ç­‰å¼ãŒæˆç«‹ã™ã‚‹ã“ã¨ã‚’ç¤ºã›\n\\[\n\\sqrt{\\mathbb E[(X+Y)^2]} \\leq \\sqrt{\\mathbb E[X^2]} + \\sqrt{\\mathbb E[Y^2]}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nã‚·ãƒ¥ãƒ¯ãƒ«ãƒ„ã®ä¸ç­‰å¼ã‚’ç”¨ã„ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«ç¤ºã›ã‚‹\n\\[\n\\begin{align*}\n\\mathbb E[(X+Y)^2]\n    &= \\mathbb E[X^2] + 2\\mathbb E[XY] + \\mathbb E[Y^2]\\\\\n    &= \\mathbb E[X^2] + 2\\sqrt{(\\mathbb E[XY])^2} + \\mathbb E[Y^2]\\\\\n    &\\leq \\mathbb E[X^2] + 2\\sqrt{\\mathbb E[X^2]\\mathbb E[Y^2]} + \\mathbb E[Y^2]\\\\\n    &= (\\sqrt{\\mathbb E[X^2]} + \\sqrt{\\mathbb E[Y^2]})^2\n\\end{align*}\n\\]\nä¸¡è¾ºã«ã¤ã„ã¦ï¼Œsquare rootã‚’ã¨ã‚‹ã¨ï¼Œ\n\\[\n\\sqrt{\\mathbb E[(X+Y)^2]} \\leq \\sqrt{\\mathbb E[X^2]} + \\sqrt{\\mathbb E[Y^2]}\n\\]\n\n\n\n\næ¡ä»¶ä»˜ãæœŸå¾…å€¤\n\n\nTheorem 3.9 Law of Total Expectation \n\\[\n\\mathbb E[Y] = \\mathbb E[\\mathbb E[Y\\vert X]]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\mathbb E[\\mathbb E[Y\\vert X]]\n    &= \\int \\mathbb E[Y\\vert X=u]f_X(u)\\mathrm{d}u\\\\\n    &= \\int \\left[\\int t f_Y(t\\vert x=u)\\mathrm{d}t\\right]f_X(u)\\mathrm{d}u\\\\\n    &= \\int \\int t f_Y(t\\vert x=u)f_X(u)\\mathrm{d}u\\mathrm{d}t\\\\\n    &= \\int t\\left[\\int f_{X,Y}(u, t)\\mathrm{d}u\\right]\\mathrm{d}t\\\\\n    &= \\int t f_Y(t)\\mathrm{d}t\\\\\n    &= \\mathbb E[Y]\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.10 : CEF Decomposition Property \nç¢ºç‡å¤‰æ•° \\(X, Y\\) ã«ã¤ã„ã¦ï¼Œ\n\\[\nY = \\mathbb E[Y\\vert X] + \\epsilon\n\\]\nã¨ã—ãŸã¨ãï¼Œ\n\n\\(\\epsilon\\) ã¯ \\(X\\) ã«ã¤ã„ã¦ mean-independent, i.e., \\(\\mathbb E[\\epsilon\\vert X] = 0\\)\n\\(\\epsilon\\) ã¯ \\(X\\) ã®ä»»æ„ã®é–¢æ•°ã«å¯¾ã—ã¦ç„¡ç›¸é–¢, i.e., \\(\\operatorname{Cov}(h(X), \\epsilon) = 0\\)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n â–¶Â  (1)\n\\[\n\\begin{align*}\n\\mathbb E[\\epsilon\\vert X]\n    &= \\mathbb E[Y - \\mathbb E[Y\\vert X]\\vert X]\\\\\n    &= \\mathbb E[Y\\vert X] - \\mathbb E[Y\\vert X]\\\\\n    &= 0\n\\end{align*}\n\\]\n â–¶Â  (2)\n\\[\n\\begin{align*}\n\\mathbb E[h(X)\\epsilon] &= E[\\mathbb E[h(X)\\epsilon\\vert X]]\\\\\n                        &= E[h(X)\\mathbb E[\\epsilon\\vert X]]\\\\\n                        &= 0 \\quad \\because{\\text{mean independence}}\n\\end{align*}\n\\]\n\n\n\n\nğŸ“˜ REMARKS \nCEF Decomposition Propertyã¯ï¼Œç¢ºç‡å¤‰æ•° \\(Y\\) ã¯ç¢ºç‡å¤‰æ•° \\(X\\) ã§èª¬æ˜ã§ãã‚‹ãƒ‘ãƒ¼ãƒˆã¨ï¼Œ\\(X\\) ã®ä»»æ„ã®é–¢æ•°ã¨ç›´è¡Œï¼ˆorthogonalï¼‰ ãªèª¤å·®é …ã®ãƒ‘ãƒ¼ãƒˆã«åˆ†è§£ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ï¼",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>æœŸå¾…å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html#markov-and-chebyshev-inequalities",
    "href": "posts/statistics101/expectation.html#markov-and-chebyshev-inequalities",
    "title": "3Â  æœŸå¾…å€¤",
    "section": "Markov and Chebyshev Inequalities",
    "text": "Markov and Chebyshev Inequalities\nç¢ºç‡å¤‰æ•° \\(X\\) ã«ã¤ã„ã¦ï¼Œç¢ºç‡å¯†åº¦é–¢æ•°ã‚„åˆ†å¸ƒé–¢æ•°ãŒã‚ã‹ã£ã¦ã„ã‚‹çŠ¶æ³ã¯å°‘ãªã„ã§ã™ï¼ã¾ãŸï¼Œãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚ŒãŸã¨ã—ã¦ã‚‚ ãã‚Œã‚‰ã‚’è¨ˆç®—ã™ã‚‹ã“ã¨ã¯ã‹ã‚“ãŸã‚“ã§ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ãã®ä¸­ã§ï¼Œ\n\n\\(X\\) ãŒ mean \\(\\mu\\) ã‹ã‚‰ã©ã‚Œãã‚‰ã„é›¢ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã‹\n\\(\\Pr(\\vert X \\leq a\\vert )\\) ã®upper boundã¯ã©ã‚Œãã‚‰ã„ã‹ï¼Ÿ\n\nã¨ã„ã†çµ±è¨ˆçš„æ¨æ¸¬ã‚’ã—ãŸã„ã¨ãã«ä½¿ç”¨ã•ã‚Œã‚‹Markov and Chebyshev Inequalitiesã‚’è§£èª¬ã—ã¾ã™ï¼\n\nMarkovâ€™s Inequality\n\n\nTheorem 3.11 Markovâ€™s Inequality \nnon-negative ç¢ºç‡å¤‰æ•° \\(X \\geq 0\\)ï¼Œconstant \\(k &gt;0\\) ã«ã¤ã„ã¦ä»¥ä¸‹ãŒæˆç«‹ã™ã‚‹\n\\[\n\\Pr(X \\geq k) \\leq \\frac{\\mathbb E[X]}{k}\n\\]\nã¤ã¾ã‚Šï¼Œ\n\\[\n\\Pr(X \\geq k\\mathbb E[X]) \\leq \\frac{1}{k}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\mathbb E[X] &= \\int_0^\\infty xf(x)\\mathrm{d}x\\\\\n             &= \\int_0^k xf(x)\\mathrm{d}x + \\int_k^\\infty xf(x)\\mathrm{d}x\\\\\n             &\\leq \\int_k^\\infty xf(x)\\mathrm{d}x\\\\\n             &\\leq \\int_k^\\infty kf(x)\\mathrm{d}x\\\\\n             &= k \\Pr(X \\geq k)\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\nProof: å¤‰æ•°å¤‰æ›\n\n\n\n\n\n\\[\nY =\n\\begin{cases}\n    0 & \\text{if} X &lt; k\\\\[5pt]\n    k & \\text{if} X \\geq k\n\\end{cases}\n\\]\nã®ã‚ˆã†ã«å¤‰æ•°å¤‰æ›ã‚’ã™ã‚‹ã¨å¸¸ã« \\(Y \\leq X\\) ã§ã‚ã‚‹ã®ã§ \\(\\mathbb E[Y] \\leq \\mathbb E[X]\\).\n\\[\n\\begin{align*}\n&\\mathbb E[Y] = k\\Pr(X\\geq k)\\\\\n\\Rightarrow &\\Pr(X\\geq k)\\leq \\frac{\\mathbb E[X]}{k}\n\\end{align*}\n\\]\n\n\n\n\nğŸ“˜ REMARKS \n\nMarkovâ€™s inequalityã¯ ç¢ºç‡å¤‰æ•° \\(X\\) ãŒnon-negative, population mean \\(\\mu\\) ã®çŸ¥è­˜ã®ã¿ã§ä½¿ç”¨å¯èƒ½\nä¸€æ–¹ï¼Œboundå¹…ã¯å¤§ããï¼Œweakest inequalityã§ã‚ã‚‹\n\n\n\nExample 3.7 \nç‚¹æ•°ç¯„å›²ãŒ \\(\\Omega_x=[0, 110]\\) ã®è©¦é¨“ã‚’ã¤ã„ã¦ï¼Œãã®ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢ç¢ºç‡å¤‰æ•° \\(X\\) ã‚’è€ƒãˆã‚‹ï¼åˆ†å¸ƒã®æƒ…å ±ã¯ã‚ã‹ã‚‰ãªã„ãŒ population meanã¯ 25 ã§ã‚ã‚‹ã“ã¨ãŒçŸ¥ã‚‰ã‚Œã¦ã„ã‚‹ï¼ã“ã®ã¨ãï¼Œ\\(\\Pr(X \\geq 100)\\) ã®upper boundã¯Markovâ€™s inequalityã‚’ç”¨ã„ã¦ ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã§ãã¾ã™ï¼\n\\(X\\) ãŒnon-negativeãªã®ã§\n\\[\n\\begin{align*}\n\\Pr(X\\geq 100) &\\leq \\frac{25}{100}\\\\\n               &= \\frac{1}{4}\n\\end{align*}\n\\]\n\n\nExample 3.8 : weak inequality \n\\(X_i \\overset{\\mathrm{iid}}{\\sim} \\operatorname{Bernoulli}(0.2)\\) ã‚’20å›ç¹°ã‚Šè¿”ã™è©¦è¡Œã‚’è€ƒãˆã‚‹ï¼ã“ã®è©¦è¡Œã®çµæœã®ã‚¢ã‚¦ãƒˆã‚«ãƒ ã‚’ \\(Y\\) ã¨ã—ãŸã¨ãï¼Œ\n\\[\n\\Pr(Y \\geq 16) = \\sum_{k=16}^{20} {}_{20}C_{k} 0.2^k 0.8^{20-k} \\approx 1.38\\cdot 10^{-8}\n\\]\nä¸€æ–¹ï¼ŒMarkovâ€™s inequalityã‚’ç”¨ã„ã‚‹ã¨\n\\[\n\\begin{align*}\n\\Pr(Y \\geq 16) \\leq \\frac{4}{16} = \\frac{1}{4}\n\\end{align*}\n\\]\nã“ã®ã‚ˆã†ã«ï¼Œboundå¹…ã¯å¤§ãã„ã“ã¨ãŒåˆ†ã‹ã‚‹ï¼\n\n\n\nChebyshevâ€™s Inequality\n\n\nTheorem 3.12 Chebyshevâ€™s inequality \n\\(X \\sim D(\\mu, \\sigma^2)\\) ã¨ã™ã‚‹ï¼ãŸã ã—ï¼Œ\\(D\\) ã®å½¢çŠ¶ã¯ã‚ã‹ã‚‰ãªã„ï¼å®Ÿæ•° \\(\\alpha &gt;0\\) ã«ã¤ã„ã¦ï¼Œä»¥ä¸‹ãŒæˆç«‹ã™ã‚‹\n\\[\n\\Pr(\\vert X - \\mu \\vert \\geq \\alpha) \\leq \\frac{\\sigma^2}{\\alpha^2}\n\\]\nã¤ã¾ã‚Šï¼Œ\n\\[\n\\Pr(\\vert X - \\mu \\vert \\geq \\alpha \\sigma) \\leq \\frac{1}{\\alpha^2}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(I = \\{x: \\vert x -\\mu \\vert \\geq k\\}\\) ã¨ã™ã‚‹ï¼\n\\[\n\\begin{align*}\n\\sigma^2 &= \\int_{\\mathbb R} (x - \\mu)^2f(x)\\mathrm{d}x\\\\\n         &\\geq  \\int_{I} (x - \\mu)^2f(x)\\mathrm{d}x\\\\\n         &\\geq  \\int_{I} k^2f(x)\\mathrm{d}x\\\\\n         &= k^2 \\Pr(\\vert x - \\mu\\vert \\geq k)\n\\end{align*}\n\\]\nä»¥ä¸Šã‚ˆã‚Šï¼Œ\\(\\displaystyle\\Pr(\\vert X - \\mu \\vert \\geq k) \\leq \\frac{\\sigma^2}{k^2}\\) ã‚’å¾—ã‚‹ï¼\n\n\n\n\n\n\n\n\n\nProof: using Markovâ€™s inequality\n\n\n\n\n\n\\((x - \\mu)^2\\) ã‚’ç¢ºç‡å¤‰æ•°ã¨è€ƒãˆã‚‹ã¨ï¼Œnon-negativeç¢ºç‡å¤‰æ•°ã«ãªã‚‹ï¼Œã¤ã¾ã‚ŠMarkovâ€™s inequalityã‚’ç”¨ã„ã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§\n\\[\n\\begin{align*}\n\\Pr(\\vert x - \\mu\\vert \\geq k) &= \\Pr((x - \\mu)^2 \\geq k)\\\\\n                               &\\leq \\frac{\\mathbb E[(x - \\mu)^2]}{k^2} \\because{\\text{Markov's inequality}}\\\\\n                               &= \\frac{\\sigma^2}{k^2}\n\\end{align*}\n\\]\n\n\n\n\nExample 3.9 Markovâ€™s inequality vs Chebyshevâ€™s inequality \n\\(X \\sim \\operatorname{Binom}(n=20, p=0.2)\\) ã«ã¤ã„ã¦ï¼Œweak inequality ã§ç¢ºèªã—ãŸã‚ˆã†ã«ï¼ŒMarkovâ€™s inequalityã®ã‚ˆã‚Š\n\\[\n\\Pr(X \\geq 16) = \\Pr(X \\geq 4\\mathbb E[X]) \\leq \\frac{1}{4}\n\\]\nä¸€æ–¹ï¼ŒChebyshevâ€™s inequalityã‚’ç”¨ã„ã‚‹ã¨\n\\[\n\\begin{align*}\n\\Pr(X \\geq 16) &\\leq \\Pr(\\vert X - 4\\vert \\geq 12)\\\\\n               &\\leq \\frac{\\operatorname{Var}(X)}{12^2}\\\\\n               &\\leq \\frac{3.2}{12^2}\\\\\n               &= \\frac{1}{45}\n\\end{align*}\n\\]\n\n\nğŸ“˜ REMARKS \n\nChebyshevâ€™s inequalityã¯Markovâ€™s inqualityã¨ç•°ãªã‚Šï¼Œç¢ºç‡å¤‰æ•° \\(X\\) ãŒnon-negativeã§ã‚ã‚‹å¿…è¦ã¯ãªã„\nmeanã‹ã‚‰ã®è·é›¢ã«ã¤ã„ã¦ã®æƒ…å ±ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã‚‹\n\n\n\n\nWeak Law of Large Numbers\n\n\nTheorem 3.13 Weak Law of Large Numbers \nå¹³å‡ \\(\\mu\\), åˆ†æ•£ \\(\\sigma^2\\) ã®åˆ†å¸ƒã«ç‹¬ç«‹ã«å¾“ã†ç¢ºç‡å¤‰æ•° \\(X_1, \\cdots, X_n\\) ã‚’è€ƒãˆã‚‹ï¼æ¨™æœ¬å¹³å‡ã‚’ \\(\\overline{X_n} = \\frac{1}{n}\\sum_{i=1}^nX_i\\) ã¨ã™ã‚‹ï¼\nã“ã®ã¨ãï¼Œä»»æ„ã®å®Ÿæ•° \\(\\epsilon &gt;0\\) ã«å¯¾ã—ã¦ï¼Œ\n\\[\n\\lim_{n\\to\\infty}\\Pr(\\vert \\overline{X_n} - \\mu \\vert &gt; \\epsilon) = 0\n\\]\nã¤ã¾ã‚Šï¼Œæ¨™æœ¬å¹³å‡ã¯æ¯å¹³å‡ã«ç¢ºç‡åæŸã™ã‚‹ï¼\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nChebyshevâ€™s inequalityã‚’ç”¨ã„ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«ç¤ºã›ã‚‹\n\\[\n\\begin{align*}\n\\lim_{n\\to\\infty}\\Pr(\\vert \\overline{X_n} - \\mu \\vert &gt; \\epsilon)\n                &\\leq \\lim_{n\\to\\infty} \\frac{\\operatorname{Var}(\\overline{X_n})}{\\epsilon^2}\\\\\n                &= \\lim_{n\\to\\infty} \\frac{\\sigma^2}{n\\epsilon^2}\\\\\n                &=0\n\\end{align*}\n\\]",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>æœŸå¾…å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html#åˆ†æ•£",
    "href": "posts/statistics101/expectation.html#åˆ†æ•£",
    "title": "3Â  æœŸå¾…å€¤",
    "section": "åˆ†æ•£",
    "text": "åˆ†æ•£\n\n\nTheorem 3.14 : BienaymÃ© Equality \näº’ã„ã«ç‹¬ç«‹ãªç¢ºç‡å¤‰æ•° \\(X, Y\\) ã«ã¤ã„ã¦ä»¥ä¸‹ãŒæˆç«‹ã™ã‚‹\n\\[\n\\operatorname{Var}(X+Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\operatorname{Var}(X+Y)\n    &= \\mathbb E[((X+Y) - (\\mu_X+\\mu_Y))^2]\\\\\n    &= \\mathbb E[((X- \\mu_X)+(Y - \\mu_Y))^2]\\\\\n    &= \\mathbb E[(X- \\mu_X)^2] + 2\\mathbb E[(X- \\mu_X)(Y- \\mu_Y)] + \\mathbb E[(Y- \\mu_Y)^2]\\\\\n    &= \\mathbb E[(X- \\mu_X)^2] + 2\\mathbb E[(X- \\mu_X)]\\mathbb E[(Y- \\mu_Y)] + \\mathbb E[(Y- \\mu_Y)^2] \\quad \\because{\\text{ç‹¬ç«‹æ€§}}\\\\\n    &= \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\end{align*}\n\\]\n\n\n\nãªãŠï¼Œç¢ºç‡å¤‰æ•° \\(X, Y\\) ãŒç‹¬ç«‹ã§ã¯ãªã„å ´åˆã¯\n\\[\n\\operatorname{Var}(X + Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y) + 2\\operatorname{Cov}(X, Y)\n\\]\nãŒæˆç«‹ã—ã¾ã™ï¼\n\næ¡ä»¶ä»˜ãåˆ†æ•£\nç¢ºç‡å¤‰æ•° \\(X, Y\\) ã«ã¤ã„ã¦ã®æ¡ä»¶ä»˜ãåˆ†æ•£ã¯ä»¥ä¸‹ã®ã‚ˆã†ãªæ„å‘³ã‚’æŒã¤\n\n\\(\\operatorname{Var}(X\\vert Y=y)\\) ã¯ï¼Œ\\(Y = y\\) ã¨å›ºå®šã—ãŸã¨ãã® \\(X\\) ã®åˆ†æ•£\n\\(\\operatorname{Var}(X\\vert Y)\\) ã¯ï¼Œ\\(Y\\) ãŒãƒ©ãƒ³ãƒ€ãƒ ã«é¸ã°ã‚ŒãŸå€¤ã«å›ºå®šã•ã‚ŒãŸå ´åˆã® \\(X\\) ã®åˆ†æ•£\n\n\\(\\operatorname{Var}(X\\vert Y)\\) ã¯ \\(Y\\) ã®ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¹ã«ä¾å­˜ã—ãŸç¢ºç‡å¤‰æ•°ã§ã‚ã‚‹ä¸€æ–¹ï¼Œ \\(\\operatorname{Var}(X\\vert Y=y)\\) ã¯ \\(y\\) ã®é–¢æ•°ã¨ã„ã†é•ã„ãŒã‚ã‚‹\n\n\nTheorem 3.15 æ¡ä»¶ä»˜ãåˆ†æ•£ \n\\[\n\\operatorname{Var}(Y\\vert X) = \\mathbb E[(Y^2\\vert X)] - (\\mathbb E[(Y\\vert X)])^2 = \\mathbb E[(Y - \\mathbb E[Y\\vert X])^2\\vert X]\n\\]\n\n\n\n\n\nTheorem 3.16 Law of Total Variance \n\\[\n\\operatorname{Var}(Y) = \\operatorname{Var}(\\mathbb E[Y\\vert X]) + \\mathbb E_X[\\operatorname{Var}(Y\\vert X)]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(\\epsilon = Y - E\\mathbb E[Y\\vert X]\\) ã¨ã—ãŸã¨ãï¼Œ\\(\\epsilon\\) ã¨ \\(E\\mathbb E[Y\\vert X]\\) ã¯ç„¡ç›¸é–¢ãªã®ã§ï¼Œ\n\\[\n\\operatorname{Var}(Y) = \\operatorname{Var}(\\mathbb E[Y\\vert X]) + \\operatorname{Var}(\\epsilon)\n\\]\n\\(\\mathbb E[\\epsilon] = 0\\) ã‚ˆã‚Šï¼Œ\n\\[\n\\begin{align*}\n\\operatorname{Var}(\\epsilon)\n    &= \\mathbb E[\\epsilon^2] - (\\mathbb E[\\epsilon])^2\\\\\n    &= \\mathbb E[\\epsilon^2]\\\\\n    &= \\mathbb E_X(\\mathbb E[\\epsilon^2\\vert X])\\\\\n    &= \\mathbb E_X[\\operatorname{Var}(Y\\vert X)]\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\operatorname{Var}(Y) = \\operatorname{Var}(\\mathbb E[Y\\vert X]) + \\mathbb E_X[\\operatorname{Var}(Y\\vert X)]\n\\]\n\n\n\nLaw of Total Varianceã‚ˆã‚Š \\(Y\\) ã®åˆ†æ•£ã¯ï¼ŒCEFã®åˆ†æ•£ + èª¤å·®é …ã®åˆ†æ•£ã«åˆ†è§£ã§ãã‚‹ã“ã¨ã‚’ç¤ºã—ã¦ã„ã¾ã™ï¼ å®Ÿå‹™ã«ãŠã‘ã‚‹åˆ†æã«ãŠã„ã¦ï¼Œè³ƒé‡‘ã®ãƒãƒ©ãƒ„ã‚­ã‚’\n\nè³ƒé‡‘ã‚’èª¬æ˜ã™ã‚‹å„å€‹äººã®ç‰¹å¾´ã®ãƒãƒ©ãƒ„ã‚­\nç‰¹å¾´ã§èª¬æ˜ã™ã‚‹ã“ã¨ã®ã§ããªã„è³ƒé‡‘ã®ãƒãƒ©ãƒ„ã‚­(=èª¤å·®é …)ã®æœŸå¾…å€¤\n\nã«åˆ†è§£ã—ã¦è€ƒå¯Ÿã™ã‚‹éš›ã«Law of Total Varianceã‚’ä½¿ç”¨ã—ãŸã‚Šã—ã¾ã™ï¼",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>3</span>Â  <span class='chapter-title'>æœŸå¾…å€¤</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/order_statistic.html",
    "href": "posts/statistics101/order_statistic.html",
    "title": "4Â  é †åºçµ±è¨ˆé‡",
    "section": "",
    "text": "é †åºçµ±è¨ˆé‡\nâ–¶Â  \\(X_{(i)}\\) ã®ç´¯ç©å¯†åº¦é–¢æ•°ã¨ç¢ºç‡å¯†åº¦é–¢æ•°\n\\(F\\) ã‚’å¯†åº¦é–¢æ•° \\(f\\) ã‚’æŒã¤é€£ç¶šåˆ†å¸ƒã¨ã—ã¦ï¼Œ\\(X_{(i)} \\leq x\\) ã¨ãªã‚‹äº‹è±¡ã‚’è€ƒãˆã‚‹ï¼ã“ã®äº‹è±¡ã¯ \\(X_1, \\cdots, X_n\\) ã®ãªã‹ã§ \\(x\\) ä»¥ä¸‹ã¨ãªã‚‹ã‚‚ã®ã®å€‹æ•°ãŒ \\(i\\) å€‹ä»¥ä¸Šã§ã‚ã‚‹ã¨ã„ã†äº‹è±¡ã¨åŒåœ°ãªã®ã§\n\\[\nB_k = \\{X_1, \\cdots, X_n\\text{ã®ã†ã¡}k\\text{å€‹ãŒ}x\\text{ä»¥ä¸‹}\\}\n\\]\nã¨äº‹è±¡ \\(B_k\\) ã‚’è¨­å®šã™ã‚‹ã¨ï¼Œ\n\\[\n\\Pr(X_{(i)}\\leq x) = \\sum_{k=i}^n \\Pr(B_k)\n\\]\nãã‚Œãã‚Œã® \\(X_j\\) ã«ã¤ã„ã¦ï¼Œç‹¬ç«‹ã«æˆåŠŸç¢ºç‡ \\(p = F(x)\\) ã®ãƒ™ãƒ«ãƒŒãƒ¼ã‚¤è©¦è¡Œã¨è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§\n\\[\nF_{X_{(i)}}(X) = \\sum_{k=i}^n {}_nC_{k} p^k (1 - p)^{n-k}, \\ \\ p=F(x)\n\\]\nã¨ãªã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼ã¾ãŸï¼Œã“ã®å¼ã‚’ \\(x\\) ã§å¾®åˆ†ã™ã‚‹ã“ã¨ã§ \\(X_{(i)}\\) ã®ç¢ºç‡å¯†åº¦é–¢æ•°ãŒã‚ã‹ã‚‹ã®ã§, \\(p(k, m)\\) ã‚’ \\(\\operatorname{Binom}(m, p)\\) ã®ç¢ºç‡é–¢æ•°ã¨ã™ã‚‹ã¨\n\\[\n\\begin{align*}\n&\\frac{\\mathrm{d}}{\\mathrm{d}p} {}_nC_{k} p^k (1 - p)^{n-k}\\\\\n&= \\frac{n!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k} - \\frac{n!}{k!(n-k-1)!}p^{k-1}(1-p)^{n-k-1}\\\\\n&= n (p(k-1, n-1) - p(k. n-1))\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\\(p(n, n-1) =0\\) ã¨ã™ã‚‹ã¨ï¼Œ\n\\[\n\\begin{align*}\nf_{X_{(i)}}(x) &= nf(x)\\sum_{k=i}^n(p(k-1, n-1) - p(k. n-1))\\\\\n               &= nf(x) p(i-1, n-1)\\\\\n               &= \\frac{n!}{(i-1)!(n-i)!}f(x)F(x)^{i-1}(1 - F(x))^{n-i}\n\\end{align*}\n\\]\nâ–¶Â  æœ€å¤§å€¤ã®åˆ†å¸ƒé–¢æ•°\næœ€å¤§å€¤ã®åˆ†å¸ƒé–¢æ•° \\(\\Pr(X_{(n)} \\leq x)\\) ã¯\n\\[\n\\max_i X_i \\leq x \\Leftrightarrow X_i \\leq x, \\  \\ i = 1, \\cdots, n\n\\]\nãªã®ã§ï¼Œ\n\\[\n\\begin{align*}\n&\\Pr(\\max_i X_i \\leq x )= F(x)^n\\\\\n&f_{X_{(n)}}(x) = nf(x)F(x)^{n-1}\n\\end{align*}\n\\]\nâ–¶Â  æœ€å°å€¤ã®åˆ†å¸ƒé–¢æ•°\næœ€å°å€¤ã®åˆ†å¸ƒé–¢æ•° \\(\\Pr(X_{(1)} \\leq x) = \\Pr(\\min(X_i)\\leq x)\\) ã¯\n\\[\n\\min_i X_i &gt; x \\Leftrightarrow X_i &gt; x, \\  \\ i = 1, \\cdots, n\n\\]\nã‚ˆã‚Š\n\\[\n\\begin{align*}\n&\\Pr(\\min_i X_i \\leq x )= 1 - (1 - F(x))^n\\\\\n&f_{X_{(1)}}(x) = nf(x)(1 - F(x))^{n-1}\n\\end{align*}\n\\]\nCode\nimport numpy as np\nfrom scipy.stats import beta\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nN = 10\nITER = 10000\nI = 9\nNBINS = 100\na, b = 10, 1\nnp.random.seed(42)\n\n\ndef random_sampling_from_unif(index, size):\n    return sorted(np.random.uniform(0, 1, size))[index]\n\n\nx = np.array(list(map(lambda x: random_sampling_from_unif(I, N), range(ITER))))\nbeta_x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), NBINS)\n\n# plot\nnewnames = {\"0\": \"sample maximum\"}\nfig = px.histogram(x, histnorm=\"probability density\", nbins=NBINS, title=\"maximum value distribution of 10 rvs from Unif(0, 1)\")\nfig.for_each_trace(\n    lambda t: t.update(\n        name=newnames[t.name],\n        hovertemplate=t.hovertemplate.replace(t.name, newnames[t.name]),\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x=beta_x, y=beta.pdf(beta_x, a, b), mode=\"lines\", name=\"beta(10, 1) pdf\"\n    ),\n    row=1,\n    col=1,\n)\nfig.show()",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>é †åºçµ±è¨ˆé‡</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/order_statistic.html#é †åºçµ±è¨ˆé‡",
    "href": "posts/statistics101/order_statistic.html#é †åºçµ±è¨ˆé‡",
    "title": "4Â  é †åºçµ±è¨ˆé‡",
    "section": "",
    "text": "Def: é †åºçµ±è¨ˆé‡ \n\\(X_1, \\cdots, X_n \\overset{\\mathrm{iid}}{\\sim} F\\) ã¨ã™ã‚‹ã¨ãï¼Œã“ã‚Œkã‚‰ã®ç¢ºç‡å¤‰æ•°ã®å€¤ã‚’å°ã•ã„é †ã«ä¸¦ã³æ›¿ãˆãŸã‚‚ã®ã‚’\n\\[\nX_{(1)}\\leq\\cdots\\leq X_{(i)}\\leq\\cdots \\leq X_{(n)}\n\\]\nã¨è¡¨ã—ï¼Œé †åºçµ±è¨ˆé‡(order statistic)ã¨ã„ã†ï¼\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4.1 ä¸€æ§˜åˆ†å¸ƒã«å¾“ã†ç¢ºç‡å¤‰æ•°åˆ—ã®é †åºçµ±è¨ˆé‡ã¨ãƒ™ãƒ¼ã‚¿åˆ†å¸ƒ \n\\(X_1, \\cdots, X_n \\overset{\\mathrm{iid}}{\\sim} \\operatorname{Unif}(0, 1)\\) ã¨ã™ã‚‹ã¨ãï¼Œç¬¬ \\(i\\) é †åºçµ±è¨ˆé‡ã®ç¢ºç‡å¯†åº¦é–¢æ•°ã¨åˆ†å¸ƒé–¢æ•°ã¯ãã‚Œãã‚Œä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚‹\n\\[\n\\begin{align*}\nf_{X_{(i)}} &= \\frac{n!}{(i-1)!(n-i)!} x^{i-1}(1 - x)^{n-i}\\\\\n            &= \\frac{x^{i-1}(1 - x)^{n-i}}{\\operatorname{B}(i, n-i+1)}\\\\\nF_{X_{(i)}} &= \\sum_{k=i}^n \\frac{n!}{(n-k)!k!} x^k (1 - x)^{n-k}\\\\\n            &= \\frac{n!}{(i-1)!(n-i)!}\\int^x_0t^{i-1}(1 - t)^{n-i}\\mathrm{d}t\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\\(X_{(i)}\\) ã¯ãƒ™ãƒ¼ã‚¿åˆ†å¸ƒ \\(\\operatorname{Beta}(i, n-i+1)\\) ã«å¾“ã†ã“ã¨ãŒã‚ã‹ã‚‹ï¼ã“ã“ã‹ã‚‰ \\(\\operatorname{Beta}(1, 1)\\) ãŒ \\(\\operatorname{Unif}(0, 1)\\) ã«ç­‰ã—ããªã‚‹ã“ã¨ã‚‚ã‚ã‹ã‚‹ï¼",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>é †åºçµ±è¨ˆé‡</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/order_statistic.html#æœ€å¤§å€¤ã¨æœ€å°å€¤ã®åŒæ™‚å¯†åº¦é–¢æ•°",
    "href": "posts/statistics101/order_statistic.html#æœ€å¤§å€¤ã¨æœ€å°å€¤ã®åŒæ™‚å¯†åº¦é–¢æ•°",
    "title": "4Â  é †åºçµ±è¨ˆé‡",
    "section": "æœ€å¤§å€¤ã¨æœ€å°å€¤ã®åŒæ™‚å¯†åº¦é–¢æ•°",
    "text": "æœ€å¤§å€¤ã¨æœ€å°å€¤ã®åŒæ™‚å¯†åº¦é–¢æ•°\n\n\nTheorem 4.1 æœ€å¤§å€¤ã¨æœ€å°å€¤ã®åŒæ™‚å¯†åº¦é–¢æ•° \n\\(X_1, \\cdots, X_n \\overset{\\mathrm{iid}}{\\sim} F\\) ã¨ã™ã‚‹ã¨ãï¼Œ\\(x&lt;y\\) ã¨ã™ã‚‹ã¨\n\\[\n\\begin{align*}\nF_{X_{(1)},X_{(n)}}(x, y) &= \\Pr(X_{(1)} \\leq x,X_{(n)}\\leq y)\\\\\n                          &= [F(y)]^n - [F(y) - F(x)]^n\n\\end{align*}\n\\]\nåŒæ™‚ç¢ºç‡å¯†åº¦é–¢æ•°ã¯\n\\[\nf_{X_{(1)},X_{(n)}}(x, y) = n(n-1)[F(y) - F(x)]^{n-2}f(x)f(y)\n\\]\n\n\n\\(x &lt; y\\) ã®æ¡ä»¶ã®ã‚‚ã¨ã§ï¼Œ\n\\[\nF_{X_{(1)},X_{(n)}}(x, y) = \\Pr(X_{(1)} \\leq x,X_{(n)}\\leq y)\n\\]\nã«ã¤ã„ã¦ã¾ãšè€ƒãˆã‚‹ï¼ç¢ºç‡äº‹è±¡ã®æ’ä»–æ€§ã‚ˆã‚Š\n\\[\n\\Pr(X_{(n)} \\leq y) = \\Pr(X_{(1)}\\leq x, X_{(n)}\\leq y) + \\Pr(X_{(1)}&gt; x, X_{(n)}\\leq y)\n\\]\nã“ã“ã‹ã‚‰ï¼Œ\\(\\Pr(X_{(1)}\\leq x, X_{(n)}\\leq y) = \\Pr(X_{(n)} \\leq y) - \\Pr(X_{(1)}&gt; x, X_{(n)}\\leq y)\\) ã‚’å¾—ã‚‹ï¼\n\\[\n\\begin{align*}\n&\\Pr(X_{(1)}&gt; x, X_{(n)}\\leq y)\\\\\n&= \\Pr(x &lt; X_{(1)} \\leq y, \\cdots, x &lt; X_{(i)} \\leq y, \\cdots, x&lt; X_{(n)}\\leq y)\\\\\n&= [F(y) - F(x)]^n \\because{\\operatorname{i.i.d}}\n\\end{align*}\n\\]\n\\(\\Pr(X_{(n)}\\leq y) = [F(y)]^n\\) ã§ã‚ã‚‹ã®ã¯ä¸Šã§ç¢ºèªã—ãŸã®ã§ï¼Œå¾“ã£ã¦ï¼Œ\n\\[\n\\begin{align*}\nF_{X_{(1)},X_{(n)}}(x, y) &= \\Pr(X_{(1)} \\leq x,X_{(n)}\\leq y)\\\\\n                          &= [F(y)]^n - [F(y) - F(x)]^n\n\\end{align*}\n\\]\nåŒæ™‚ç¢ºç‡å¯†åº¦é–¢æ•°ã¯\n\\[\n\\begin{align*}\nf_{X_{(1)},X_{(n)}}(x, y) &= \\frac{\\mathrm{d}}{\\mathrm{d}x}\\frac{\\mathrm{d}}{\\mathrm{d}x}\\{[F(y)]^n - [F(y) - F(x)]^n\\}\\\\\n&= \\frac{\\mathrm{d}}{\\mathrm{d}x}\\{n[F_y]^{n-1}f(y) - n[F(y) - F(x)]^{n-1}f(y)\\}\\\\\n&= n(n-1)[F(y) - F(x)]^{n-2}f(y)f(x)\n\\end{align*}\n\\]\n â–¶Â  A heuristic approach for calculating the joint pdf\n\\(\\min X_i = x, \\max X_i =y\\), ã¨æ±ºã¾ã£ã¦ãŠã‚Š, ãã‚Œä»¥å¤–ã®å€¤ã¯ \\((x, y)\\) åŒºé–“ã«åã¾ã£ã¦ã„ã‚Œã°ä½•ã§ã‚‚è‰¯ã„ã®ã§ï¼Œ indexé€šã‚Šã«é †ç•ªãŒã‚ã‚‹ãªã‚‰ã°\n\\[\nf(x)[F(y) - F(x)]^{n-2}f(y)\n\\]\nã¾ãŸï¼Œã“ã®ä¸¦ã¹æ–¹ã¯ \\(n!\\) é€šã‚Šå­˜åœ¨ã™ã‚‹ãŒï¼Œ\\(X_{(1)}, X_{(n)}\\) ä»¥å¤–ã®ä¸¦ã³æ–¹ã«ã¯åŒºåˆ¥ã¯ã„ã‚‰ãªã„ã®ã§\n\\[\n\\frac{n!}{(n-2)!}f(x)[F(y) - F(x)]^{n-2}f(y) = n(n-1)f(x)[F(y) - F(x)]^{n-2}f(y)\n\\]\n\nğŸ“˜ REMARKS \nä¸¦ã³æ›¿ãˆã®è€ƒãˆã§åŒæ§˜ã« \\((X_{(1)}, \\cdots, X_{(n)})\\) ã®åŒæ™‚ç¢ºç‡å¯†åº¦é–¢æ•°ã¯\n\\[\nf_{X_{(1)}, \\cdots, X_{(n)}}(x_1, \\cdots, x_n) = n!f(x_1)f(x_2)\\cdots f(x_n)\n\\]\nã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚‹ï¼\n\\(X_{(i)}, X_{(j)}\\) ã®åŒæ™‚ç¢ºç‡å¯†åº¦é–¢æ•°ã¯\n\\[\nf_{X_{(i)}, X_{(j)}}(x, y)=\\frac{n!}{(i-1)!(j-i-1)!}(n-j)!f(x)f(y)F(x)^{i-1}[F(y)-F(x)]^{j-i-1}[1 - F(y)]^{n-j}\n\\]",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>é †åºçµ±è¨ˆé‡</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html",
    "href": "posts/probability_distribution/hypergeometric.html",
    "title": "5Â  è¶…å¹¾ä½•åˆ†å¸ƒ",
    "section": "",
    "text": "è¶…å¹¾ä½•åˆ†å¸ƒã®æ€§è³ª\nãƒ„ãƒœã« \\(K\\) å€‹ã®èµ¤ç‰ã¨ \\(N-K\\) å€‹ã®ç™½ç‰ï¼Œã¤ã¾ã‚Šåˆè¨ˆ \\(N\\) å€‹ã®ç‰ãŒå…¥ã£ã¦ã„ã‚‹ä¸­ã‹ã‚‰ï¼Œ\\(n\\) å€‹ã®ç‰ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã« éå¾©å…ƒ(without replacement)ã§æŠ½å‡ºã™ã‚‹ã¨ã™ã‚‹ï¼ã“ã®ã¨ãå–ã‚Šå‡ºã—ãŸèµ¤ç‰ã®å€‹æ•°ã‚’ \\(X\\) ã¨ã—ãŸã¨ãï¼Œã“ã® \\(X\\) ã¯è¶…å¹¾ä½•åˆ†å¸ƒ \\(\\operatorname{Hypergeometric}(N, K, n)\\) ã«å¾“ã„ã¾ã™ï¼\nâ–¶Â  ç¢ºç‡é–¢æ•°ã®åˆè¨ˆãŒ1ã«ãªã‚‹ã“ã¨ã®è¨¼æ˜\næ’ç­‰å¼\n\\[\n(1 + t)^N = (1 + t)^{K}(1 + t)^{N-K}\n\\]\nã‚’è€ƒãˆã‚‹ï¼RHSã‚’å±•é–‹ã—ï¼Œ\\(t^n\\) ã®ä¿‚æ•° \\(\\beta_n\\) ã‚’è¦‹ã¦ã¿ã‚‹ã¨\n\\[\n\\begin{align*}\n\\beta_n = \\sum_{\\max(n+K-N, 0)}^{\\min(K, n)} {}_KC_{x} \\times {}_{N-K}C_{n-x}\n\\end{align*}\n\\]\nä¸€æ–¹ï¼ŒLHSã§ã¿ã‚‹ã¨\n\\[\n\\beta_n = {}_NC_n\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\begin{gather*}\n\\sum_{\\max(n+K-N, 0)}^{\\min(K, n)} {}_KC_{x} \\times {}_{N-K}C_{n-x} = {}_NC_n\\\\\n\\Rightarrow \\sum_{\\max(n+K-N, 0)}^{\\min(K, n)}\\Pr(X=k) = 1\n\\end{gather*}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]",
    "crumbs": [
      "ç¢ºç‡åˆ†å¸ƒ",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>è¶…å¹¾ä½•åˆ†å¸ƒ</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html#è¶…å¹¾ä½•åˆ†å¸ƒã®æ€§è³ª",
    "href": "posts/probability_distribution/hypergeometric.html#è¶…å¹¾ä½•åˆ†å¸ƒã®æ€§è³ª",
    "title": "5Â  è¶…å¹¾ä½•åˆ†å¸ƒ",
    "section": "",
    "text": "Def: è¶…å¹¾ä½•åˆ†å¸ƒ \nParameters \\((N, K, n)\\) ã®è¶…å¹¾ä½•åˆ†å¸ƒã«å¾“ã†ç¢ºç‡å¤‰æ•° \\(X\\) ã«ã¤ã„ã¦ï¼Œãã®ç¢ºç‡é–¢æ•°ã¯\n\\[\n\\begin{gather*}\n\\Pr(X = x) = \\frac{{}_KC_x \\cdot {}_{N-K}C_{n-x}}{{}_NC_n}\\\\\n\\text{where} \\max\\{0, n+K-N\\} \\leq x \\leq \\min\\{n, K\\}\n\\end{gather*}\n\\]\nã¾ãŸ \\(\\max\\{0, n+K-N\\} \\leq x \\leq \\min\\{n, K\\}\\) ã®ç¯„å›²å¤–ã® \\(x\\) ã«ã¤ã„ã¦ã¯ \\(\\Pr(X = x) = 0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 5.1 æœŸå¾…å€¤ \nç¢ºç‡å¤‰æ•° \\(X \\sim \\operatorname{Hypergeometric}(N, K, n)\\) ã«ã¤ã„ã¦\n\\[\n\\mathbb E[X] = n\\frac{K}{N}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\left(\\begin{array}{c}n\\\\k\\end{array}\\right)= \\frac{n}{k} \\left(\\begin{array}{c}n-1\\\\ k-1\\end{array}\\right)\n\\]\nã¨ã„ã†é–¢ä¿‚å¼ã‚’ã‚‚ã¡ã„ã‚‹ã¨\n\\[\n\\begin{align*}\n\\mathbb E[X]\n    &= \\sum_x\\frac{x \\left(\\begin{array}{c}K\\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-K\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N\\\\ n\\end{array}\\right)}\\\\\n    &= \\frac{nK}{N}\\sum_x\\frac{ \\left(\\begin{array}{c}K-1\\\\ x-1\\end{array}\\right)\\left(\\begin{array}{c}N-K\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N-1\\\\ n-1\\end{array}\\right)}\\\\\n    &= \\frac{nK}{N}\\sum_x\\frac{ \\left(\\begin{array}{c}K-1\\\\ x-1\\end{array}\\right)\\left(\\begin{array}{c}N-1-(K-1)\\\\ n-1 - (x-1)\\end{array}\\right)}{\\left(\\begin{array}{c}N-1\\\\ n-1\\end{array}\\right)}\n\\end{align*}\n\\]\næœ€å¾Œã®å¼å¤‰å½¢ã¯ï¼Œãƒ„ãƒœã« \\(K-1\\) å€‹ã®èµ¤ç‰ã¨ \\(N-1 - (K-1)\\) å€‹ã®ç™½ç‰ï¼Œã¤ã¾ã‚Šåˆè¨ˆ \\(N-1\\) å€‹ã®ç‰ãŒå…¥ã£ã¦ã„ã‚‹ä¸­ã‹ã‚‰ \\(n-1\\) å€‹ã®ãƒœãƒ¼ãƒ«ã‚’é¸ã¶å ´åˆã®ç¢ºç‡é–¢æ•°ã¨åŒã˜ãªã®ã§\n\\[\n\\begin{align*}\n\\sum_x\\frac{ \\left(\\begin{array}{c}K-1\\\\ x-1\\end{array}\\right)\\left(\\begin{array}{c}N-1-(K-1)\\\\ n-1 - (x-1)\\end{array}\\right)}{\\left(\\begin{array}{c}N-1\\\\ n-1\\end{array}\\right)} = 1\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\\(\\displaystyle\\mathbb E[X] = \\frac{nK}{N}\\) ã‚’å¾—ã‚‹ï¼\n\n\n\n\n\nTheorem 5.2 åˆ†æ•£ \nç¢ºç‡å¤‰æ•° \\(X \\sim \\operatorname{Hypergeometric}(N, K, n)\\) ã«ã¤ã„ã¦\n\\[\n\\operatorname{Var}(X) = n\\frac{K}{N}\\frac{N-K}{N}\\frac{N-n}{(N-1)}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\operatorname{Var}(X) = \\mathbb E[X(X-1)] + E[X](1 - E[X])\n\\]\nãªã®ã§ï¼Œ\\(\\mathbb E[X(X-1)]\\) ãŒã‚ã‹ã‚Œã°è‰¯ã„ï¼\n\\[\n\\begin{align*}\n\\mathbb E[X(X-1)]\n    &= \\sum_{x}\\frac{x(x-1)\\left(\\begin{array}{c}K \\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-K \\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N \\\\ n\\end{array}\\right)}\\\\\n    &= \\frac{n(n-1)K(K-1)}{N(N-1)}\\sum_{x}\\frac{\\left(\\begin{array}{c}K-2 \\\\ x-2\\end{array}\\right)\\left(\\begin{array}{c}(N-2) - (K-2) \\\\ (n-2)-(x-2)\\end{array}\\right)}{\\left(\\begin{array}{c}N -2\\\\ n - 2\\end{array}\\right)}\\\\\n    &= \\frac{n(n-1)K(K-1)}{N(N-1)}\\sum_{l=x-2}\\frac{\\left(\\begin{array}{c}K-2 \\\\ l\\end{array}\\right)\\left(\\begin{array}{c}(N-2) - (K-2) \\\\ (n-2)-l\\end{array}\\right)}{\\left(\\begin{array}{c}N -2\\\\ n - 2\\end{array}\\right)}\\\\\n    &= \\frac{n(n-1)K(K-1)}{N(N-1)}\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\operatorname{Var}(X) = n\\frac{K}{N}\\frac{N-K}{N}\\frac{N-n}{N-1}\n\\]\n\n\n\n\nğŸ“˜ REMARKS \n\n\\(\\frac{N-n}{N-1}\\) ã¯æœ‰é™æ¯é›†å›£ä¿®æ­£ã¨å‘¼ã°ã‚Œã‚‹\n\n\n\nè¶…å¹¾ä½•åˆ†å¸ƒã®æ¥µé™ã¨äºŒé …åˆ†å¸ƒ\nç¢ºç‡å¤‰æ•° \\(X \\sim \\operatorname{Hypergeometric}(N, K, n)\\) ã«ã¤ã„ã¦, \\(\\frac{K}{N} = p \\text{ as } N, K \\to\\infty\\) ãŒæ¥µé™ã«ãŠã„ã¦ æˆç«‹ã™ã‚‹ã¨ã—ã¾ã™ï¼\n\\[\n\\begin{align*}\n&\\Pr(X = x)\\\\\n    &= \\frac{\\left(\\begin{array}{c}K\\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-K\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N\\\\n\\end{array}\\right)}\\\\\n    &= \\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)\\frac{K!}{(K-x)!}\\frac{(N-k)!}{(N-K-n+x)!}\\frac{(N-n)!}{N}\\\\\n    &= \\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)\\frac{K(K-1)\\cdots(K-x+1)}{N(N-1)\\cdots(N-x+1)}\\frac{(N-K)\\cdots(N-K-(n-x)+1)}{(N-x)\\cdots(N-x+1)}\n\\end{align*}\n\\]\nã“ã®ã¨ãï¼Œ\\(p = K/N\\) ã¨ã™ã‚‹ã¨ï¼Œæ¥µé™ã«ãŠã„ã¦\n\\[\n\\begin{gather*}\n\\frac{K(K-1)\\cdots(K-x+1)}{N(N-1)\\cdots(N-x+1)} \\approx p^x\\\\\n\\frac{(N-K)\\cdots(N-K-(n-x)+1)}{(N-x)\\cdots(N-x+1)}\\approx (1-p)^{n-x}\n\\end{gather*}\n\\]\nä»¥ä¸Šã‚ˆã‚Š\n\\[\n\\lim_{N,K\\to\\infty}\\Pr(X=x) = \\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)p^x(1-p)^{n-x}\n\\]\n\n\næœ‰é™æ¯é›†å›£ã‹ã‚‰ã®éå¾©å…ƒæŠ½å‡ºã¨æœ‰é™æ¯é›†å›£ä¿®æ­£\næœ‰é™æ¯é›†å›£ã‹ã‚‰ã®å¾©å…ƒæŠ½å‡ºã¯ï¼Œi.i.d.ç¢ºç‡å¤‰æ•°ãŒè¦³æ¸¬ã•ã‚Œã‚‹ãŒï¼Œéå¾©å…ƒæŠ½å‡ºã®å ´åˆã¯ i.i.d.ã¨ãªã‚Šã¾ã›ã‚“ï¼ å¤§ãã• \\(N\\) ã®æœ‰é™æ¯é›†å›£ã‚’è€ƒãˆï¼Œ\\(X_i\\) ã‚’æ¨™æœ¬ã¨ã—ã¦æŠ½å‡ºã•ã‚ŒãŸè¦³æ¸¬å€¤ã¨ã—ã¾ã™ï¼ãªãŠï¼Œæœ‰é™æ¯é›†å›£ã«å±ã™ã‚‹å„å€‹ä½“ã®å€‹ä½“å€¤ã‚’ï¼Œ\n\\[\na_1, a_2, \\cdots, a_N\n\\]\nã¨ã—ã¾ã™ï¼ã‚µã‚¤ã‚º \\(n\\) ã®éå¾©å…ƒæŠ½å‡ºã¯ï¼Œä»»æ„ã®äº’ã„ã«ç•°ãªã‚‹ \\(i_1, \\cdots, i_n\\) ã«ã¤ã„ã¦ï¼Œä»¥ä¸‹ã®ã‚ˆã†ã«ç¢ºç‡ãŒå®šç¾©ã•ã‚Œã‚‹æ¨™æœ¬æŠ½å‡ºæ–¹æ³•ã§ã™ï¼š\n\\[\n\\begin{align*}\n\\Pr(X_1 = a_{i_1}, \\cdots, X_1 = a_{i_n}) = \\frac{1}{N(N-1)\\cdots(N-n+1)}\n\\end{align*}\n\\]\n â–¶Â  æœ‰é™æ¯é›†å›£ã®å¹³å‡ã¨åˆ†æ•£\næœ‰é™æ¯é›†å›£ã®å¹³å‡ã¨åˆ†æ•£ã¯\n\\[\n\\begin{gather*}\n\\mu = \\frac{1}{N}\\sum_{i=1}^Na_i\\\\\n\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^N(a_i - \\mu)^2\n\\end{gather*}\n\\]\nã¨å®šç¾©ã§ãã¾ã™ï¼\n â–¶Â  æ¨™æœ¬å¹³å‡ã®æœŸå¾…å€¤ã¨åˆ†æ•£\n\\[\n\\begin{align*}\n\\mathbb E[\\overline{{X}}]\n    &= \\frac{1}{n}\\sum_{i=1}^n\\mathbb E[X_i]\\\\\n    &= \\mu\\\\\n\\\\\n\\operatorname{Var}(\\overline{{X}})\n    &= \\frac{1}{n^2}\\operatorname{Var}(\\sum_{i=1}^nX_i)\\\\\n    &=\\frac{1}{n^2}\\left[\\sum_{i=1}^n\\operatorname{Var}(X_i) + \\sum_{i\\neq j}\\operatorname{Cov}(X_i, X_j)\\right]\\\\\n    &=\\frac{1}{n^2}\\left[n\\operatorname{Var}(X_1) + n(n-1)\\operatorname{Cov}(X_1, X_2)\\right]\n\\end{align*}\n\\]\nã“ã“ã§ï¼Œ\n\\[\n\\begin{align*}\n&\\operatorname{Cov}(X_1, X_2)\\\\\n    &= \\mathbb E[X_1X_2] - \\mathbb E[X_1]\\mathbb E[X_2]\\\\\n    &= \\frac{1}{N(N-1)}\\sum_{i\\neq j}a_ia_j - \\left(\\frac{1}{N}\\sum_{i=1}^Na_i\\right)^2\\\\\n    &= \\frac{1}{N(N-1)}\\left[(\\sum_{i=1}^Na_i)^2 - \\sum_{i=1}^Na_i^2\\right]- \\left(\\frac{1}{N}\\sum_{i=1}^Na_i\\right)^2\\\\\n    &= \\frac{(\\sum_{i=1}^Na_i)^2}{N^2(N-1)} - \\frac{\\sum_{i=1}^Na_i^2}{N(N-1)}\\\\\n    &= -\\frac{1}{N(N-1)}\\left(\\sum_{i=1}^Na_i^2 - \\frac{1}{N}(\\sum_{i=1}^Na_i)^2\\right)\\\\\n    &= -\\frac{1}{N(N-1)}\\sum_{i=1}^N(a_i - \\overline(a))^2\\\\\n    &= -\\frac{\\sigma^2}{N-1}\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\operatorname{Var}(\\overline{{X}}) = \\frac{\\sigma^2}{n}\\frac{N-n}{N-1}\n\\]\n\nğŸ“˜ REMARKS \nã‚µã‚¤ã‚º \\(N\\) ã®æœ‰é™æ¯é›†å›£ã‹ã‚‰ã‚µã‚¤ã‚º \\(n\\) ã®éå¾©å…ƒç„¡ä½œç‚ºæŠ½å‡ºã‚’å®Ÿæ–½ã™ã‚‹å ´åˆï¼Œ\n\\[\n\\{a_{i_1}, \\cdots, a_{i_n}\\}\n\\]\nã¨ã„ã†è¦ç´ ã®é‡è¤‡ã‚’è¨±ã—ãŸå¤šé‡é›†åˆã‚’ä¸€åº¦æŠ½å‡ºã—ï¼Œãã“ã‹ã‚‰æ”¹ã‚ã¦ï¼‘å€‹ãšã¤é †ã«ç„¡ä½œç‚ºã«æŠœãå‡ºã™ã¨ã„ã†æ–¹æ³•ã§ã‚‚åŒã˜æŠ½å‡ºæ–¹æ³•ã¨ãªã‚Šã¾ã™ï¼ ã“ã“ã‹ã‚‰ï¼Œ\\(X_i\\) ã®å‘¨è¾ºåˆ†å¸ƒã¯ \\(X_1\\) ã®å‘¨è¾ºåˆ†å¸ƒã¨åŒã˜ã«ãªã‚‹ã“ã¨ãŒåˆ†ã‹ã‚‹ã—ï¼Œã¾ãŸï¼Œ\\((X_i, X_j)\\) ã®ï¼’æ¬¡å…ƒåŒæ™‚åˆ†å¸ƒã¯ \\((X_1, X_2)\\) ã®ï¼’æ¬¡å…ƒåŒæ™‚åˆ†å¸ƒã¨åŒã˜ã§ã‚ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼\n\n â–¶Â  åˆ¥è§£: éå¾©å…ƒæŠ½å‡ºã«ãŠã‘ã‚‹ \\(\\operatorname{Cov}(X_1, X_2)\\) ã®æ±‚ã‚æ–¹\n\\[\n\\sum_{i=1}^N X_i = \\sum_{i=1}^N a_i\n\\]\nã¨å®šæ•°ã§ã‚ã‚‹ã®ã§ï¼Œ\\(\\operatorname{Var}(\\sum_{i=1}^N X_i) = 0\\) ã¨ãªã‚‹ï¼\n\\[\n\\begin{align*}\n\\operatorname{Var}(\\sum_{i=1}^N X_i)\n    &= \\sum_{i=1}^N \\operatorname{Var}(X_1) + \\sum_{i\\neq j}\\operatorname{Cov}(X_1, X_2)\\\\\n    &= N\\sigma^2 + N(N-1)\\operatorname{Cov}(X_1, X_2) = 0\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\operatorname{Cov}(X_1, X_2) = -\\frac{\\sigma^2}{N-1}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]",
    "crumbs": [
      "ç¢ºç‡åˆ†å¸ƒ",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>è¶…å¹¾ä½•åˆ†å¸ƒ</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html#å¤šå¤‰é‡è¶…å¹¾ä½•åˆ†å¸ƒ",
    "href": "posts/probability_distribution/hypergeometric.html#å¤šå¤‰é‡è¶…å¹¾ä½•åˆ†å¸ƒ",
    "title": "5Â  è¶…å¹¾ä½•åˆ†å¸ƒ",
    "section": "å¤šå¤‰é‡è¶…å¹¾ä½•åˆ†å¸ƒ",
    "text": "å¤šå¤‰é‡è¶…å¹¾ä½•åˆ†å¸ƒ\n\nDef: å¤šå¤‰é‡è¶…å¹¾ä½•åˆ†å¸ƒ \nå„å€‹ä½“ãŒ \\(c_1, c_2, \\cdots, c_k\\) ã®ã„ãšã‚Œã‹ã«æ‰€å±ã™ã‚‹ã‚ˆã†ãªã‚¯ãƒ©ã‚¹ã‚µã‚¤ã‚º \\(N\\) æœ‰é™æ¯é›†å›£ã‚’è€ƒãˆã‚‹(å„ \\(c_i\\) ã®ã‚µã‚¤ã‚ºã¯ \\(C_i\\) ã¨ã™ã‚‹)ï¼ã¤ã¾ã‚Šï¼Œ\n\\[\n\\sum_{j=1}^kC_j = N\n\\]\nã“ã®æœ‰é™æ¯é›†å›£ã‹ã‚‰ï¼Œã‚µã‚¤ã‚º \\(n\\) ã®éå¾©å…ƒç„¡ä½œç‚ºæŠ½å‡ºã‚’ã™ã‚‹å ´åˆï¼Œãã®åŒæ™‚ç¢ºç‡é–¢æ•°ã¯\n\\[\n\\begin{gather*}\n\\Pr(X_1=x_1, \\cdots, X_k=x_k) = \\frac{\\left(\\begin{array}{c}C_1\\\\x_1 \\end{array}\\right)\\left(\\begin{array}{c}C_2\\\\x_2 \\end{array}\\right)\\cdots\\left(\\begin{array}{c}C_k\\\\ x_k \\end{array}\\right)}\n{\\left(\\begin{array}{c}N\\\\n \\end{array}\\right)}\\\\\n\\text{where } \\sum_{i=1}^kx_i = n\n\\end{gather*}\n\\]\nã¨ãªã‚‹ï¼ã“ã®ã¨ãï¼Œ\\(k\\) æ¬¡å…ƒç¢ºç‡å¤‰æ•°ãƒ™ã‚¯ãƒˆãƒ« \\(X\\) ã¯ \\(\\operatorname{Multi-hypergeometric}(N, (C_1, \\cdots, C_k), n)\\) ã«å¾“ã†ï¼\n\n â–¶Â  å‘¨è¾ºç¢ºç‡åˆ†å¸ƒ\nå¤šå¤‰é‡è¶…å¹¾ä½•åˆ†å¸ƒã® \\(X_i\\) ã«ã¤ã„ã¦ã®å‘¨è¾ºç¢ºç‡åˆ†å¸ƒã¯ï¼Œ\\(X_i\\) ä»¥å¤–ã®ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ã¾ã¨ã‚ã¦ã‚·ãƒ³ãƒ—ãƒ«ãªè¶…å¹¾ä½•åˆ†å¸ƒã¨ã¿ãªã—ã¦è€ƒãˆã‚‹ã“ã¨ãŒã§ãã‚‹ã®ã§\n\\[\n\\begin{gather*}\n\\Pr(X_i=x) = \\frac{\\left(\\begin{array}{c}C_i\\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-C_i\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N\\\\ n\\end{array}\\right)}\\\\\n\\text{where } \\max\\{0, n+C_i-N\\} \\leq x \\leq \\min\\{n, C_i\\}\n\\end{gather*}\n\\]\n â–¶Â  æœŸå¾…å€¤ã¨åˆ†æ•£\n\\[\n\\begin{gather*}\n\\mathbb E[X_i] = n\\frac{C_i}{N}\\\\\n\\operatorname{Var}(X_i) = n\\frac{C_i}{N}\\frac{N-C_i}{N}\\frac{N-n}{N-1}\\\\\n\\operatorname{Cov}(X_i, X_j) = -n\\frac{N-n}{N-1}\\frac{C_i}{N}\\frac{C_j}{N}\n\\end{gather*}\n\\]",
    "crumbs": [
      "ç¢ºç‡åˆ†å¸ƒ",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>è¶…å¹¾ä½•åˆ†å¸ƒ</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html#references",
    "href": "posts/probability_distribution/hypergeometric.html#references",
    "title": "5Â  è¶…å¹¾ä½•åˆ†å¸ƒ",
    "section": "References",
    "text": "References\n\nLibreTexts Statistics &gt; The Multivariate Hypergeometric Distribution",
    "crumbs": [
      "ç¢ºç‡åˆ†å¸ƒ",
      "<span class='chapter-number'>5</span>Â  <span class='chapter-title'>è¶…å¹¾ä½•åˆ†å¸ƒ</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_101/fisher_exact_test.html",
    "href": "posts/statistical_hypothesis_test_101/fisher_exact_test.html",
    "title": "6Â  Fisherâ€™s exact test",
    "section": "",
    "text": "\\(2\\times 2\\)ã‚¯ãƒ­ã‚¹ã‚»ãƒ«è¡¨ã¨Fisherâ€™s exact test\nå„ã‚°ãƒ«ãƒ¼ãƒ—ã®åˆè¨ˆã¨ã„ã†å‘¨è¾ºã®å€¤ãŒå›ºå®šã•ã‚Œã¦ã„ã‚‹ã¨è€ƒãˆãŸã¨ãï¼Œ(Treated, Positive)ã®äººæ•°ã¨ã„ã†ç¢ºç‡å¤‰æ•°ãŒå¾“ã†åˆ†å¸ƒã¯è¶…å¹¾ä½•åˆ†å¸ƒã¨ã¿ãªã™ã“ã¨ãŒã§ãã‚‹ï¼ ã¤ã¾ã‚Šï¼Œ\nã¨ã—ãŸã¨ãï¼Œ\\(X_{11}\\)ã®ç¢ºç‡ã¯\n\\[\n\\begin{align*}\n\\Pr(X_{11}=x) &= \\frac{{}_{x_{1\\cdot}}C_{x}\\times {}_{x_{2\\cdot}}C_{x_{\\cdot 1} - x} }{{}_{N}C_{x_{\\cdot 1}}}\\\\\n              &= \\frac{x_{\\cdot 1}!x_{\\cdot 2}!x_{2\\cdot}!x_{2\\cdot}!}{x_{11}!x_{12}!x_{21}!x_{22}!N!}\n\\end{align*}\n\\]\nã“ã®ã¨ãï¼Œ\\(x\\) ã®ç¯„å›²ã¯ \\(\\max(0, x_{1\\cdot} - x_{2\\cdot}) \\leq x \\leq \\min(x_{1\\cdot}, x_{\\cdot 1})\\) ã«ãªã‚‹ï¼\nâ–¶Â  Null hypothesis vs Alternative hypothesis\nä¸Šè¨˜ã®å•é¡Œè¨­å®šã«ãŠã‘ã‚‹Fisherâ€™s exact testã«ãŠã‘ã‚‹æ¤œå®šä»®èª¬è¨­å®šä¾‹ã¯ã¨ï¼Œä¸¡å´æ¤œå®šãªã‚‰ã°\n\\(H_0\\)ã®ä»®å®šã®ä¸‹ã§ã¯ï¼Œ\\(X_{11}\\)ã¯è¶…å¹¾ä½•åˆ†å¸ƒ(hypergeometric distribution)ã«å¾“ã†ã¯ãšãªã®ã§ï¼Œã“ã®ä»®å®šã«åŸºã¥ã„ã¦På€¤ã‚’è¨ˆç®—ã—ã¾ã™ï¼ä¸¡å´æ¤œå®šã§ã®På€¤ã®è¨ˆç®—æ–¹æ³•ä¾‹ã¨ã—ã¦\n\\[\n\\begin{align*}\n\\text{p-value} = \\sum_{x} \\Pr(X_{11}={x}) \\text{ s.t } \\{x \\vert \\Pr(X_{11}={x}) \\leq \\Pr(X_{11}={x_{11}})\\}\n\\end{align*}\n\\]",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šå…¥é–€",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Fisher's exact test</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#times-2ã‚¯ãƒ­ã‚¹ã‚»ãƒ«è¡¨ã¨fishers-exact-test",
    "href": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#times-2ã‚¯ãƒ­ã‚¹ã‚»ãƒ«è¡¨ã¨fishers-exact-test",
    "title": "6Â  Fisherâ€™s exact test",
    "section": "References",
    "text": "å•é¡Œè¨­å®š \nã‚ã‚‹åŒ»è–¬å“è©¦é¨“ã®RCTã«ã¦ï¼Œï¼•ï¼äººã®æ‚£è€…ã‚’ç„¡ä½œç‚ºã«treatedã¨ãƒ—ãƒ©ã‚»ãƒœ(control)ã«åˆ†ã‘ã¦ï¼Œä¸€å®šæœŸé–“å¾Œã®å¥åº·çŠ¶æ…‹(Positive vs Negative)ã‚’ç¢ºèªã—ãŸã¨ã“ã‚ ä»¥ä¸‹ã®ã‚ˆã†ãªçµæœã«ãªã£ãŸï¼\n\n\n\n\n\nÂ \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\nåˆè¨ˆ\n\n\n\n\n\n\nPositive\n\n\n\n\n21\n\n\n\n\n15\n\n\n\n\n36\n\n\n\n\n\n\nNegative\n\n\n\n\n4\n\n\n\n\n10\n\n\n\n\n14\n\n\n\n\n\n\nåˆè¨ˆ\n\n\n\n\n25\n\n\n\n\n25\n\n\n\n\n50\n\n\n\n\n\nã“ã®ã¨ãï¼Œãƒ—ãƒ©ã‚»ãƒœã¨ã‚°ãƒ«ãƒ¼ãƒ—ã¨åŒ»è–¬å“æŠ•å…¥ã‚°ãƒ«ãƒ¼ãƒ—é–“ã§å¥åº·çŠ¶æ…‹åˆ†å¸ƒãŒç•°ãªã‚‹ã‹ã©ã†ã‹æ¤œå®šã—ãŸã„ï¼\n\n\n\n\n\n\n\n\nÂ \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\nåˆè¨ˆ\n\n\n\n\n\n\nPositive\n\n\n\n\n\\(X_{11}\\)\n\n\n\n\n\\(X_{12}\\)\n\n\n\n\n\\(x_{1\\cdot}\\)\n\n\n\n\n\n\nNegative\n\n\n\n\n\\(X_{21}\\)\n\n\n\n\n\\(X_{22}\\)\n\n\n\n\n\\(x_{2\\cdot}\\)\n\n\n\n\n\n\nåˆè¨ˆ\n\n\n\n\n\\(x_{\\cdot 1}\\)\n\n\n\n\n\\(x_{\\cdot 2}\\)\n\n\n\n\n\\(N\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\): å‡¦ç½®(Treatment)ã¨ä¸€å®šæœŸé–“å¾Œã®å¥åº·çŠ¶æ…‹(ä¸»è¦è©•ä¾¡é …ç›®)ã¯ç‹¬ç«‹\n\\(H_1\\): å‡¦ç½®(Treatment)ã¨ä¸€å®šæœŸé–“å¾Œã®å¥åº·çŠ¶æ…‹(ä¸»è¦è©•ä¾¡é …ç›®)ã¯ç‹¬ç«‹ã§ã¯ãªã„ \\(\\Rightarrow \\Pr(\\text{Positive}\\vert \\text{Treated})\\neq \\Pr(\\text{Positive}\\vert \\text{Control})\\)\n\n\n\n\n\n\nCode\nimport math\nimport numpy as np\nimport polars as pl\nimport plotly.express as px\n\n\ndef compute_prob(\n    x: int, positive: int, negative: int, treated: int, denom: int\n) -&gt; np.float64:\n    return math.comb(positive, x) * math.comb(negative, treated - x) / denom\n\n\nDENOM = math.comb(50, 25)\nX_DOMAIN = np.arange(11, 25)\n\nprob = list(\n    map(\n        lambda x: compute_prob(x, positive=36, negative=14, treated=25, denom=DENOM),\n        X_DOMAIN,\n    )\n)\n\n# create polars.DataFrame\ndf = pl.DataFrame({\"x\": X_DOMAIN, \"prob\": prob})\n\n# plotly\nfig = px.bar(df, x=\"x\", y=\"prob\", title=\"Null hypothesisä¸‹ã«ãŠã‘ã‚‹ç¢ºç‡åˆ†å¸ƒ\")\nfig.update_layout(\n    xaxis_title=\"Treatedã«ãŠã‘ã‚‹Positiveã®äººæ•°\", yaxis_title=\"probability\"\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nexact p-valueã®è¨ˆç®—\n â–¶Â  ç‰‡å´æ¤œå®š\n\\(X_{11} \\geq x\\) ã¨ãªã‚‹å ´åˆã®p-valueã‚’scipy.stats.fisher_exactã§è¨ˆç®—ã™ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼\n\nfrom scipy.stats import fisher_exact\ntable = np.array([[21, 15], [4, 10]])\nres_greater = fisher_exact(table, alternative='greater')\nprint(\"scipy-p-value: {:.6f}\".format(res_greater.pvalue))\n\nscipy-p-value: 0.056829\n\n\nä¸€æ–¹ï¼Œä¸Šã§è¨ˆç®—ã—ãŸprobabilityã«å‰‡ã£ã¦ä¸Šå´ç¢ºç‡ã‚’è¦‹ã¦ã¿ã‚‹ã¨\n\nprint(\"self-computed-pvalue: {:.6f}\".format(df.filter((pl.col(\"x\") &gt;= 21))['prob'].sum()))\n\nself-computed-pvalue: 0.056824\n\n\nã¨æ•°å€¤è¨ˆç®—èª¤å·®ã‚’ç„¡è¦–ã—ã¦ã—ã¾ãˆã°å¤§ã¾ã‹ã«ä¸€è‡´ã™ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ï¼\n â–¶Â  ä¸¡å´æ¤œå®š\nä¸¡å´æ¤œå®šã«ãŠã‘ã‚‹p-valueã¯\n\\[\n\\begin{align*}\n\\text{p-value} = \\sum_{x} \\Pr(X_{11}={x}) \\text{ s.t } \\{x \\vert \\Pr(X_{11}={x}) \\leq \\Pr(X_{11}={x_{11}})\\}\n\\end{align*}\n\\]\nãªã®ã§\n\nthreshold = df.filter((pl.col(\"x\") == 21))[\"prob\"].to_numpy()[0]\nres_twosided = fisher_exact(table, alternative=\"two-sided\")\nmyres_twosided = df.filter((pl.col(\"prob\") &lt;= threshold))[\"prob\"].sum()\nprint(\"\"\"scipy-p-value: {:.6f},self-computed-pvalue: {:.6f}\n      \"\"\".format(res_twosided.pvalue, myres_twosided))\n\nscipy-p-value: 0.113657,self-computed-pvalue: 0.113652\n      \n\n\nã©ã¡ã‚‰ã®è¨ˆç®—ã§ã‚‚ãŠã‚ˆã \\(11.37\\%\\) ã§ã‚ã‚‹ã“ã¨ãŒç¢ºèªã§ãã¾ã™ï¼\n\nğŸ“˜ REMARKS \n\nçµ„ã¿åˆã‚ã›ã®æ•°ãŒå¤§ãã™ãï¼Œexact p-valueã®è¨ˆç®—ãŒé›£ã—ã„å ´åˆã¯Monte Carloæ³•ã‚’ç”¨ã„ã¦è¨ˆç®—ã—ã¾ã™\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nT\nT\nT\nT\nT\nC\nC\nC\nC\nC\n\n\nPromoted\n1\n1\n1\n1\n0\n1\n1\n0\n0\n0\n\n\n\nã¨ã„ã†Treatedã®ã†ã¡ï¼”äººãŒPromotedã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚ŒãŸå ´åˆï¼ŒTreatedã‹ã¤Promotedã®äººæ•°ã‚’ \\(X\\) ã¨ã—ãŸã¨ãï¼Œ \\(\\Pr(X \\geq 4)\\) ã®ã¤ã„ã¦è¨ˆç®—å‚ã™ã‚‹å ´åˆã¯\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nT\nT\nT\nT\nT\nC\nC\nC\nC\nC\n\n\nPromoted\n1\n0\n1\n0\n0\n1\n1\n1\n1\n1\n\n\n\nã®ã‚ˆã†ã«ï¼’è¡Œç›®ã«ã¤ã„ã¦Permutationã‚’ãƒ©ãƒ³ãƒ€ãƒ ã« \\(Y\\) å›å®Ÿæ–½ã—ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã‹ã‚‰ \\(\\Pr(X \\geq 4)\\) ã‚’è¨ˆç®—ã—ã¾ã™ï¼ˆä¸Šã®ä¾‹ã§ã¯ \\(X = 3\\)ï¼‰ã¨ãªã£ã¦ã„ã‚‹ï¼ã“ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚ŒãŸp-valueã¯fisherâ€™s exact p-valueã®Monte Carlo approximationã¨å‘¼ã‚“ã ã‚Šã—ã¾ã™ï¼\n\n\n\nOdds ratio\nscipy.stats.fisher_exactã§ã¯pvalueã®ã»ã‹ã«statisticã¨ã„ã†è¿”ã‚Šå€¤ã‚’ã‚‚ã£ã¦ã„ã¾ã™ï¼\n\nprint(res_twosided.statistic)\n\n3.5\n\n\nã“ã® 3.5 ã¯ã„ã‚ã‚†ã‚‹odds ratioã§\n\\[\n3.5 = \\frac{21 / 4}{15 / 10}\n\\]\nã§è¨ˆç®—ã•ã‚Œã¾ã™ï¼\n\nDef: Odds \nç¢ºç‡äº‹è±¡ \\(A\\) ã«ã¤ã„ã¦ã® odds ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«è¨ˆç®—ã•ã‚Œã‚‹\n\\[\n\\begin{align*}\n\\text{odds}(A) = \\frac{\\Pr(A)}{1 - \\Pr(A)} = \\frac{\\Pr(A)}{\\Pr(A^c)}\n\\end{align*}\n\\]\n\noddsã‚’ç”¨ã„ã‚‹ã“ã¨ã§è¡¨ç¾ãŒã‚·ãƒ³ãƒ—ãƒ«ã«ãªã‚‹ã‚±ãƒ¼ã‚¹ã¨ã—ã¦ãƒ•ã‚§ã‚¢ãªè³­ã‘ã«ãŠã„ã‘ã‚‹å€ç‡ã®è¨ˆç®—ãŒä¸Šã’ã‚‰ã‚Œã¾ã™ï¼ ä¾‹ã¨ã—ã¦ï¼Œç¢ºç‡äº‹è±¡ A ã«å¯¾ã—ã¦1å††ã‚’è³­ã‘ã‚‹çŠ¶æ³ã‚’è€ƒãˆã¾ã™ï¼ç¢ºç‡äº‹è±¡ A ãŒç™ºç”Ÿã—ãªã‹ã£ãŸã‚‰1å††ã‚’å¤±ã„ï¼Œç¢ºç‡äº‹è±¡ A ãŒç™ºç”Ÿã—ãŸã‚‰1å††ã¯ã‚­ãƒ¼ãƒ— & x å††ã®ãƒªã‚¿ãƒ¼ãƒ³ã‚’å¾—ã‚‰ã‚Œã‚‹ã¨ã—ã¾ã™ï¼\nã“ã®ã¨ãï¼Œã“ã®è³­ã‘ãŒãƒ•ã‚§ã‚¢ã§ã‚ã‚‹ãŸã‚ã«ã¯ï¼ŒæœŸå¾…åˆ©å¾—ãŒ0ã§ã‚ã‚‹ã“ã¨ãŒå¿…è¦ã§ã™ãŒï¼Œä»¥ä¸‹ã®ã‚ˆã†ã« \\(x = \\text{odds}(A^c)\\) ã¨ãƒªã‚¿ãƒ¼ãƒ³ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã¨ãƒ•ã‚§ã‚¢ãªè³­ã‘ã«ãªã‚Šã¾ã™ï¼\n\\[\n\\begin{align*}\n&\\text{expected return} = x \\times \\Pr(A) + (-1) \\times \\Pr(A^c)\\\\\n&\\Rightarrow x = \\frac{\\Pr(A^c)}{\\Pr(A)} \\because \\text{exptected return should be 0}\\\\\n& \\Rightarrow x = \\text{odds}(A^c) = 1/\\text{odds}(A)\n\\end{align*}\n\\]\n\nDef: Odds ratio \nã¨ã‚ã‚‹æ¯é›†å›£ã«ãŸã„ã—ã¦ï¼Œã¨ã‚ã‚‹ç–¾æ‚£ã®ç™ºç—‡ã‚’æŠ‘åˆ¶ã™ã‚‹ã¨è¬³ã£ã¦ã„ã‚‹æ–°è–¬ã‚’è€ƒãˆã¾ã™ï¼\n\nç–¾æ‚£ãŒç™ºç—‡ã—ãŸãªã‚‰Positive, ç™ºç—‡ã—ãªã‹ã£ãŸã‚‰Negative\næ–°è–¬ã‚’å‡¦æ–¹ã•ã‚ŒãŸã‚‰Treated, ã•ã‚Œãªã‹ã£ãŸã‚‰Control\n\nã¨ã—ã¦ï¼Œæ¯é›†å›£ã®å„çµ„ã¿åˆã‚ã›ã«å¯¾ã™ã‚‹äº‹å‰å‰²å½“ç¢ºç‡ãŒä»¥ä¸‹ã®ã‚ˆã†ãªã‚¯ãƒ­ã‚¹ã‚»ãƒ«ã§å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ã—ã¾ã™ï¼\n\n\n\n\n\nÂ \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\n\n\nPositive\n\n\n\n\n\\(p_{11}\\)\n\n\n\n\n\\(p_{12}\\)\n\n\n\n\n\n\nNegative\n\n\n\n\n\\(p_{21}\\)\n\n\n\n\n\\(p_{22}\\)\n\n\n\n\n\nã“ã®ã¨ãï¼Œtreated/controlé–“ã®ç–¾æ‚£ç™ºç—‡ã®odds ratioã¯\n\\[\n\\text{odds ratio} = \\frac{p_{11}p_{22}}{p_{21}p_{12}}\n\\]\nã§è¡¨ç¾ã•ã‚Œã‚‹ï¼\n\n\nä»®ã« Treated, Controlä¸¡æ–¹ã®ã‚°ãƒ«ãƒ¼ãƒ—ã§ç–¾æ‚£ç™ºç—‡ãŒãƒ¬ã‚¢ãªã‚¤ãƒ™ãƒ³ãƒˆã ã¨ã™ã‚‹ã¨ \\(1- \\Pr(\\text{Positive} \\vert \\text{Treated}), 1-\\Pr(\\text{Positive} \\vert \\text{Control})\\) ã¯ã¨ã‚‚ã«ååˆ†å°ã•ããªã‚Šï¼Œ\n\\[\n\\text{odds}(\\text{Positive}\\vert\\text{Treated}) \\approx Pr(\\text{Positive} \\vert \\text{Treated})\n\\]\nã¨ã¿ãªã›ã‚‹ã®ã§\n\\[\n\\frac{\\text{odds}(\\text{Positive}\\vert\\text{Treated})}{\\text{odds}(\\text{Positive}\\vert\\text{Control})} \\approx \\frac{Pr(\\text{Positive} \\vert \\text{Treated})}{Pr(\\text{Positive} \\vert \\text{Control})}\n\\]\nOdds ratioãŒ0.7ã ã¨ã™ã‚‹ã¨ï¼ŒTreated ã¯ Controlã«ãã‚‰ã¹ 30% ã»ã©ç–¾æ‚£ç™ºç—‡ç¢ºç‡ãŒä½ã„ã¨ã„ã†è§£é‡ˆã«ç¹‹ãŒã‚Šã¾ã™ï¼\n\nOdds ratioã®æ¨å®šã¨ä¿¡é ¼åŒºé–“\n\n\n\n\n\nÂ \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\nåˆè¨ˆ\n\n\n\n\n\n\nPositive\n\n\n\n\n\\(x_{11}\\)\n\n\n\n\n\\(x_{12}\\)\n\n\n\n\n\\(x_{1\\cdot}\\)\n\n\n\n\n\n\nNegative\n\n\n\n\n\\(x_{21}\\)\n\n\n\n\n\\(x_{22}\\)\n\n\n\n\n\\(x_{2\\cdot}\\)\n\n\n\n\n\n\nåˆè¨ˆ\n\n\n\n\n\\(x_{\\cdot 1}\\)\n\n\n\n\n\\(x_{\\cdot 2}\\)\n\n\n\n\n\\(N\\)\n\n\n\n\n\nä¸Šè¨˜ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ï¼Œprior odds ratio \\(\\theta\\) ã®æ¨å®šã¯\n\\[\n\\hat\\theta = \\frac{\\hat p_{11}\\hat p_{22}}{\\hat p_{21}\\hat p_{12}} \\  \\ \\text{where } \\hat p_{ij} = \\frac{x_{ij}}{N}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\hat\\theta = \\frac{x_{11}x_{22}}{x_{21}x_{12}}\n\\]\n â–¶Â  Confidence Intervalã®è¨ˆç®—\nConfidence Intervalã¯ï¼Œå®Ÿå‹™ã§ã¯ \\(\\log(\\theta)\\) ã‚’ç”¨ã„ãŸCLTã¨delta methodã«ã‚ˆã‚‹è¿‘ä¼¼ã§è¨ˆç®—ã•ã‚Œã¾ã™ï¼\n\\[\n\\begin{align*}\n\\mathbf p = (p_{11},p_{12},p_{21},p_{22})\n\\end{align*}\n\\]\nã¨ã—ãŸã¨ãï¼Œã‚‚ã¨ã‚‚ã¨ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã¯ã‚¯ãƒ©ã‚¹4ã®å¤šé …åˆ†å¸ƒã¨ã¿ãªã›ã‚‹ã®ã§ \\(\\mathbf p\\) ã«ã¤ã„ã¦ã®å…±åˆ†æ•£è¡Œåˆ— \\(\\Sigma\\) ã¯\n\\[\n\\begin{align*}\n\\Sigma = \\frac{1}{n}\\left(\n    \\begin{array}{cccc}\n    (1-p_{11}) p_{11} & -p_{11} p_{12} & -p_{11} p_{21} & -p_{11} p_{22} \\\\\n     -p_{11} p_{12} & \\left(1-p_{12}\\right) p_{12} & -p_{12} p_{21} & -p_{12} p_{22} \\\\\n     -p_{11} p_{21} & -p_{12} p_{21} & \\left(1-p_{21}\\right) p_{21} & -p_{21} p_{22} \\\\\n     -p_{11} p_{22} & -p_{12} p_{22} & -p_{21} p_{22} & (1-p_{22}) p_{22}\n    \\end{array}\n\\right)\n\\end{align*}\n\\]\nã¾ãŸï¼Œ\\(\\log(\\theta) = \\log(p_{11}) - \\log(p_{12}) - \\log(p_{21}) + \\log(p_{22})\\) ã«ã¤ã„ã¦ã®åˆ†æ•£ã¯delta methodã‚’ç”¨ã„ã¦\n\\[\n\\begin{align*}\n&\\operatorname{Var}(\\log(\\mathrm{OR})) = (\\nabla f \\Sigma )\\times \\nabla f^T\\\\\n&\\nabla f = \\left(\\frac{1}{p_{11}},-\\frac{1}{p_{12}},-\\frac{1}{p_{21}},\\frac{1}{p_{22}}\\right)\n\\end{align*}\n\\]\nã¨è¡¨ã›ã¾ã™ï¼ã“ã‚Œã‚’æ¨å®šå€¤ \\(\\hat p_{ij}\\) ã‚’ç”¨ã„ã¦è¨ˆç®—ã™ã‚‹ã¨\n\\[\n\\begin{align*}\n&\\widehat{\\operatorname{Var}(\\log(\\operatorname{OR})}=\\frac{1}{x_{11}}+\\frac{1}{x_{12}}+\\frac{1}{x_{21}}+\\frac{1}{x_{22}}\\\\\n&\\widehat{\\operatorname{SE}(\\log(\\operatorname{OR})}=\\sqrt{\\frac{1}{x_{11}}+\\frac{1}{x_{12}}+\\frac{1}{x_{21}}+\\frac{1}{x_{22}}}\n\\end{align*}\n\\]\n\\(\\mathbf p\\) ã¯ \\(N\\) ãŒååˆ†å¤§ãã„ã¨ãCLTã‚ˆã‚Šæ­£è¦åˆ†å¸ƒã«è¿‘ä¼¼ã§ãã‚‹ã¨è€ƒãˆã‚‰ã‚Œã‚‹ã®ã§ \\(\\log(\\hat\\theta)\\) ã«ã¤ã„ã¦ã®Confidence Intervalã¯\n\\[\n\\text{CI(log odds ratio)} = \\widehat{\\log(\\operatorname{OR})}\\pm z_{1-\\alpha/2}\\times \\widehat{\\operatorname{SE}(\\log(\\operatorname{OR})}\n\\]\nã¾ãŸï¼Œodds ratioã®Confidence Intervalã¯å¯¾æ•°ã‚’å†åº¦å¤‰æ›ã™ã‚Œã°è‰¯ã„ã®ã§\n\\[\n\\text{CI(odds ratio)} = \\exp(\\widehat{\\log(\\operatorname{OR})}\\pm z_{1-\\alpha/2}\\times \\widehat{\\operatorname{SE}(\\log(\\operatorname{OR})})\n\\]\nã¨è¨ˆç®—ã§ãã‚‹ï¼\n\nğŸ“˜ REMARKS \n\nä¸Šè¨˜ã®æ–¹æ³•ã§ã®Confidence intervalã¯ \\(\\log(\\hat\\theta)\\) è‡ªä½“ã®æ¨å®šåˆ†æ•£ã§ã¯ãªãï¼ŒCLTã‚’ç”¨ã„ã¦ã„ã‚‹ã®ã§ã‚ãã¾ã§åˆ†æ•£ã«ã¤ã„ã¦ã®æ¥µé™åˆ†å¸ƒã‚’ç”¨ã„ã¦ã„ã‚‹\n\\(p_{21}\\) ã‚„ \\(p_{12}\\) è‡ªä½“ã¯0ã«ãªã‚Šå¾—ã‚‹ã“ã¨ã‚’è€ƒãˆã‚‹ã¨ï¼Œ\\(\\hat\\theta\\) ã‚„ \\(\\log(\\hat\\theta)\\) ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚‚è€ƒãˆã‚‰ã‚Œã‚‹\n\n\n\n\nReferences\n\nPennState STAT 504 &gt; 4.5 - Fisherâ€™s Exact Test",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šå…¥é–€",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Fisher's exact test</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#references",
    "href": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#references",
    "title": "6Â  Fisherâ€™s exact test",
    "section": "",
    "text": "PennState STAT 504 &gt; 4.5 - Fisherâ€™s Exact Test",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šå…¥é–€",
      "<span class='chapter-number'>6</span>Â  <span class='chapter-title'>Fisher's exact test</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html",
    "title": "7Â  Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š",
    "section": "",
    "text": "Fisheræµæ¤œå®šã®è€ƒãˆæ–¹\nï¼’æ¨™æœ¬å•é¡Œã‚’è€ƒãˆãŸã¨ãï¼Œï¼’æ¨™æœ¬ã®å¹³å‡ã®å·®ãŒãã®ãƒãƒ©ãƒ„ã‚­ã®å¤§ãã•ï¼ˆï¼æ¨™æº–èª¤å·®ï¼‰ã¨æ¯”ã¹ã¦å¤§ãã‘ã‚Œã°å¤§ãã„ã»ã© ã€Œæ¯é›†å›£ã«å·®ãŒã‚ã‚Šã€ã®ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åŠ›ãŒé«˜ã„ã¨ã„ã†è€ƒãˆãŒFisheræµæ¤œå®šã¨ãªã‚Šã¾ã™ï¼På€¤è‡ªä½“ã¯ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã«ä¾å­˜ã™ã‚‹ã¨ç•™æ„ã—ã¦ã„ã¾ã—ãŸãŒï¼Œ Fisheræµã§ã¯På€¤ãŒå°ã•ã„ã»ã©ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åŠ›ãŒé«˜ã„ã¨ã„ã†è§£é‡ˆã«ãªã‚Šã¾ã™ï¼ã•ã‚‰ã«ï¼Œ\nã¨ã„ã†ãƒ¢ãƒã‚µã‚·ã®ææ¡ˆã‚’Fisherã¯ã—ã¾ã—ãŸï¼ã“ã‚ŒãŒç¾åœ¨ã®æœ‰æ„æ°´æº–(significance level) 5% ã¨ã„ã†æ…£ç¿’ã®ç”±æ¥ã§ã‚ã‚‹ã¨è¨€ã‚ã‚Œã¦ã„ã¾ã™ï¼\nãªãŠï¼ŒFisherã¯På€¤ã‚’çµ±è¨ˆå®¶ãŒãƒ‡ãƒ¼ã‚¿ã®è§£æçµæœã‚’ã€Œå ±å‘Šã€ã™ã‚‹ã¨ãã®ãƒ¢ãƒã‚µã‚·ã¨ã—ã¦ã®ææ¡ˆã«ã¨ã©ã¾ã£ã¦ãŠã‚Šï¼Œ åŠ¹æœãŒã‚ã£ãŸã‹å¦ã‹ã®ã€Œåˆ¤å®šã€ã¯ï¼Œçµ±è¨ˆå®¶ã ã‘ã§ãªãé–¢é€£å°‚é–€å®¶ãŒå‚åŠ ã™ã‚‹ã‚°ãƒ«ãƒ¼ãƒ—è¨è­°ã«ã‚ˆã£ã¦ï¼Œå ±å‘Šã•ã‚ŒãŸPå€¤ï¼Œåˆ†æå¯¾è±¡ï¼Œã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºç­‰ã‚’åŸå‘³ã—ã¦ç·åˆçš„ã«ã€Œåˆ¤å®šã€ã™ã¹ãã§ã‚ã‚‹ã¨è€ƒãˆã¦ã¾ã™ï¼",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#fisheræµæ¤œå®šã®è€ƒãˆæ–¹",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#fisheræµæ¤œå®šã®è€ƒãˆæ–¹",
    "title": "7Â  Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š",
    "section": "",
    "text": "å¹³å‡ã®å·®ãŒæ¨™æº–èª¤å·®ã®ï¼’å€æœªæº€ã§ã‚ã‚Œã°å¹³å‡ã®å·®ã¯ãƒãƒ©ãƒ„ã‚­ã«ã‚ˆã‚‹å·®ã§ã‚ã£ã¦è€ƒæ…®ã«å€¤ã—ãªã„ï¼Œ\n2å€ä»¥ä¸Šã®å·®ãŒã‚ã‚‹ã¨ãï¼Œå¶ç„¶ã®ã¿ã«æ”¯é…ã•ã‚ŒãŸãƒãƒ©ãƒ„ã‚­ã«æ¯”ã¹ã‚‹ã¨æŒ‡æ¨™ã®å€¤ãŒç›¸å¯¾çš„ã«å¤§ãã„ã¨è¨€ãˆã‚‹â†’åˆã‚ã¦ç§‘å­¦çš„ã«æ„å‘³ã®ã‚ã‚‹å·®ã§ã‚ã‚‹ã‹å¦ã‹ã‚’æ¤œè¨ã™ã‚‹å¯¾è±¡ã«ãªã‚Šã†ã‚‹ï¼ˆæ­£è¦åˆ†å¸ƒã‚’ä»®å®šã—ãŸã¨ãï¼Œç´„5ï¼…æ°´æº–ã«ç›¸å½“ï¼‰",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#neyman-pearsonæµæ¤œå®šã®è€ƒãˆæ–¹",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#neyman-pearsonæµæ¤œå®šã®è€ƒãˆæ–¹",
    "title": "7Â  Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š",
    "section": "Neyman-Pearsonæµæ¤œå®šã®è€ƒãˆæ–¹",
    "text": "Neyman-Pearsonæµæ¤œå®šã®è€ƒãˆæ–¹\nNeyman-Pearsonæµã¯çµ±è¨ˆçš„æ¤œå®šã«ã¤ã„ã¦\n\n\\(H_0: \\theta \\in \\Theta_0\\), Null hypothesis\n\\(H_1: \\theta \\not\\in \\Theta_0\\), Alternative hypothesis\n\nã®ï¼’ã¤ã‚’è¨­å®šã—ï¼Œè¦³å¯Ÿã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã©ã¡ã‚‰ã®ä»®èª¬ãŒã‚ˆã‚Šå¦¥å½“ãªä»®èª¬ã§ã‚ã‚‹ã‹ã‚’åˆ¤å®šã™ã‚‹å•é¡Œã¨ã„ã†çµ±è¨ˆçš„åˆ¤å®šå•é¡Œã‚’è€ƒãˆã¾ã—ãŸï¼ çµ±è¨ˆçš„åˆ¤å®šå•é¡Œã®ãŠã‘ã‚‹åˆ¤å®šã®èª¤ã‚Šã«ã¤ã„ã¦ï¼Œ\n\nType I Error: \\(H_0\\) ãŒæ­£ã—ã„ã®ã«èª¤ã£ã¦ \\(H_0\\) ã‚’æ£„å´ã™ã‚‹ã‚¨ãƒ©ãƒ¼\nType II Error: \\(H_1\\) ãŒæ­£ã—ã„ã®ã«èª¤ã£ã¦ \\(H_0\\) ã‚’æ¡æŠã™ã‚‹ã‚¨ãƒ©ãƒ¼\n\nã®ï¼’ç¨®é¡ãŒã‚ã‚‹ã¨ã—ï¼ŒType I Errorã®ç¢ºç‡ã‚’ \\(\\alpha\\) ã«æŠ‘ãˆãŸä¸Šã§ï¼ŒType II Errorã®ç¢ºç‡ \\(\\beta\\) ã‚’æœ€å°ã«ã™ã‚‹åˆ¶ç´„ä»˜ãæœ€å°åŒ–å•é¡Œ ã¨ã—ã¦çµ±è¨ˆçš„åˆ¤å®šå•é¡Œã‚’å®šå¼åŒ–ã—ã¾ã—ãŸï¼\n\n\n\n\n\nÂ \n\n\n\n\nTruth\n\n\n\n\n\n\n\\(H_0\\)\n\n\n\n\n\\(H_1\\)\n\n\n\n\n\n\n\n\n\n\n\næ¤œå®šçµæœ\n\n\n\n\n\\(H_0\\)\n\n\n\n\næ­£ã—ã„(\\(1- \\alpha\\))\n\n\n\n\nType II Error(\\(\\beta\\))\n\n\n\n\n\n\n\\(H_1\\)\n\n\n\n\nType I Error(æœ‰æ„æ°´æº–: \\(\\alpha\\))\n\n\n\n\næ­£ã—ã„ï¼ˆæ¤œå‡ºåŠ›: \\(1 - \\beta\\)ï¼‰\n\n\n\n\n\næ¤œå®šå•é¡Œã«å¯¾å¿œã™ã‚‹ æ¤œå®šçµ±è¨ˆé‡ \\(T\\), \\(H_0\\) ã®æ£„å´åŸŸã‚’ \\(R\\) ã§è¡¨ã™ã¨ãã‚Œãã‚Œä»¥ä¸‹ã®ã‚ˆã†ã«è¡¨ç¾ã•ã‚Œã¾ã™\n\nType I Error rate, \\(\\alpha = \\Pr(T \\in R \\vert H_0)\\)\nType II Error rate: \\(\\beta = \\Pr(T \\not\\in R \\vert H_1)\\)\n\nFisheræµã§ã¯På€¤ã®å¤§ãã•ãŒã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åŠ›ã¨ã„ã†æ„å‘³ã‚’æŒã¤ã“ã¨ã«å¯¾ã—ã¦ï¼ŒNeyman-Pearsonæµã§ã¯\n\näº‹å‰ã«å®šã‚ã‚‰ã‚ŒãŸæœ‰æ„æ°´æº– \\(\\alpha\\) ã‚’På€¤ãŒä¸‹å›ã‚‹ãªã‚‰åŠ¹æœã‚ã‚Šã¨ã®åˆ¤å®š\nãã†ã§ãªã„ãªã‚‰ï¼ŒåŠ¹æœãªã—ã¨ã®åˆ¤å®š\n\\(P = 0.00001\\) ã ã‚ã†ãŒ \\(P = 0.049\\) ã ã‚ã†ãŒPå€¤ã®æ°´æº–è‡ªä½“ã«ã¯æ„å‘³ã‚’æ±‚ã‚ãªã„\n\nã¨ã„ã†é•ã„ãŒã‚ã‚Šã¾ã™ï¼\n\nğŸ“˜ REMARKS \nNeyman-Pearsonæµã§ã¯ï¼Œ \\(\\alpha, \\beta\\) ã‚’ç”¨ã„ã¦çµ±è¨ˆçš„ã«åŠ¹æœãŒã‚ã‚‹ã¨è¨€ãˆã‚‹ã‹ï¼Ÿã¨ã„ã†çµ±è¨ˆçš„åˆ¤å®šå•é¡Œã¨ã—ã¦ä»®èª¬æ¤œå®šã‚’å®šå¼åŒ–ã—ã¾ã—ãŸãŒï¼Œ\n\nçµ±è¨ˆçš„æ¤œå®šã¯æ±ºå®šã™ã‚‹ãŸã‚ã®æ–¹æ³•ã§ã¯ãªãï¼Œçµæœã‚’å ±å‘Šã™ã‚‹ãŸã‚ã®æ–¹æ³•ã§ã‚ã‚‹ by F.Mostelller(1916-2006)\n\nã¨ç†è§£ã™ã‚‹ã«ã¨ã©ã‚ãŸã»ã†ãŒè‰¯ã„ã¨ã•ã‚Œã¦ã„ã¾ã™ï¼",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#æ¢ç´¢çš„ãƒªã‚µãƒ¼ãƒã¨æ¤œè¨¼çš„ãƒªã‚µãƒ¼ãƒ",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#æ¢ç´¢çš„ãƒªã‚µãƒ¼ãƒã¨æ¤œè¨¼çš„ãƒªã‚µãƒ¼ãƒ",
    "title": "7Â  Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š",
    "section": "æ¢ç´¢çš„ãƒªã‚µãƒ¼ãƒã¨æ¤œè¨¼çš„ãƒªã‚µãƒ¼ãƒ",
    "text": "æ¢ç´¢çš„ãƒªã‚µãƒ¼ãƒã¨æ¤œè¨¼çš„ãƒªã‚µãƒ¼ãƒ\nç‰¹å®šã®ç–¾æ‚£ã‚’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã¨ã—ã¦è¡Œã‚ã‚Œã‚‹åŒ»è–¬å“ã®é–‹ç™ºéç¨‹ï¼ˆè©³ç´°ã¯ã“ã¡ã‚‰ï¼‰ã‚’ä¾‹ã«ã™ã‚‹ã¨ï¼Œ\n\nå€™è£œåŒ–å­¦ç‰©è³ªã«ã¤ã„ã¦ï¼Œç™ºãŒã‚“æ€§è©¦é¨“ï¼Œå¤‰ç•°åŸæ€§è©¦é¨“ï¼Œè–¬åŠ¹è–¬ç†ç ”ç©¶ãªã©æ§˜ã€…ãªè©¦é¨“ã‚’ãƒ©ãƒƒãƒˆã‚„ç´°èƒã«å¯¾ã—ã¦æ¢ç´¢çš„ã«å®Ÿæ–½\nå¥å¸¸ãªãƒ’ãƒˆã‚’å¯¾è±¡ã«è‡¨åºŠç¬¬Iç›¸è©¦é¨“ã¨ã—ã¦ï¼Œå®‰å…¨æ€§ã‚„è–¬ç‰©å‹•æ…‹ãªã©ã‚’æ¢ç´¢çš„ã«ç ”ç©¶\nå½“è©²ç–¾æ‚£ã®æ‚£è€…ã‚’å¯¾è±¡ã«ç¬¬IIç›¸è‡¨åºŠè©¦é¨“ã¨ã—ã¦ï¼Œç—…æ°—ã®ç¨‹åº¦ã«ã‚ˆã£ã¦ã©ã®ã‚ˆã†ãªåŠ¹ãç›®ã‚’ç™ºæ®ã™ã‚‹ã®ã‹ï¼ˆæœ‰åŠ¹æ€§ï¼‰ã€å‰¯ä½œç”¨ã¯ã©ã®ç¨‹åº¦ã‹ï¼ˆå®‰å…¨æ€§ï¼‰ã€ã¾ãŸã©ã®ã‚ˆã†ãªä½¿ã„æ–¹ï¼ˆæŠ•ä¸é‡ãƒ»é–“éš”ãƒ»æœŸé–“ãªã©ï¼‰ã‚’ã—ãŸã‚‰ã‚ˆã„ã‹ã€ã‚’ç ”ç©¶\nç¬¬IIIç›¸è‡¨åºŠè©¦é¨“ã¨ã—ã¦ï¼ŒåŒ»è–¬å“ã®æœ‰åŠ¹æ€§ã¨å®‰å…¨æ€§ã‚’RCTã§æ¤œè¨¼\n\nç¬¬IIIç›¸è‡¨åºŠè©¦é¨“ã«ãŠã„ã¦ã¯ï¼ŒTreatmentã®Effect Sizeã®æƒ³å®šã¨ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºä¿ã—ãŸä¸Šã§RCTã‚’å®Ÿæ–½ï¼Œãã—ã¦å¾—ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦çµ±è¨ˆçš„æ„å‘³ã«ãŠã‘ã‚‹åŠ¹æœã®æœ‰ç„¡ã‚’æ¤œè¨¼ã—ã¦ã„ã¾ã™ï¼ ã“ã®ã‚ˆã†ãªãƒªã‚µãƒ¼ãƒã‚’æ¤œè¨¼çš„ãƒªã‚µãƒ¼ãƒã¨ã„ã„ã¾ã™ï¼\nä¸€æ–¹ï¼Œãã‚Œã¾ã§ã®å‹•ç‰©è©¦é¨“ï¼Œéè‡¨åºŠè©¦é¨“ï¼Œè‡¨åºŠç¬¬Iç›¸è©¦é¨“ï¼Œè‡¨åºŠç¬¬IIç›¸è©¦é¨“ã§ã¯ï¼ŒEffect Sizeã‚„ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒäº‹å‰ã«çµ±è¨ˆçš„ã«è¨­å®šã•ã‚Œã‚‹å ´åˆã¯å°‘ãªãï¼Œã‚ãã¾ã§ æ¬¡ã®åˆ†æã‚¹ãƒ†ãƒƒãƒ—ã«é€²ã‚€å€¤ã™ã‚‹ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹åé›†ã‚„ä»®èª¬ç«‹æ¡ˆã¨ã„ã†ç›®çš„ã§å®Ÿæ–½ã•ã‚Œã‚‹ãƒªã‚µãƒ¼ãƒã§ã™ï¼ã“ã®ã‚ˆã†ãªåˆ†æã‚’æ¢ç´¢çš„ãƒªã‚µãƒ¼ãƒã¨å‘¼ã³ã¾ã™ï¼\n\næ¤œè¨¼çš„ãƒªã‚µãƒ¼ãƒã«ãŠã‘ã‚‹ä»®èª¬æ¤œå®šæ‰‹é †\nã¨ã‚ã‚‹Populationã‚’å¯¾è±¡ã«å®Ÿæ–½ã™ã‚‹Treatmentã®åŠ¹æœã‚’RCTã§ä»®èª¬æ¤œå®šæ¤œè¨¼ã™ã‚‹å ´åˆï¼ŒåŸºæœ¬çš„ã«ã¯æ¬¡ã®ã‚ˆã†ãªä¸€é€£ã®æ‰‹é †ã§å®Ÿæ–½ã—ã¾ã™ï¼\n\nTable: æ¤œè¨¼çš„ãƒªã‚µãƒ¼ãƒæ‰‹é †\n\n\n\n\n\n\næ‰‹é †\nèª¬æ˜\n\n\n\n\næ‰‹é †(1)\nä¸»è¦è©•ä¾¡é …ç›® \\(\\delta\\) ã‚’å®šç¾©ã—ï¼ŒæœŸå¾…ã•ã‚Œã‚‹æ°´æº– \\(\\delta_0\\) ã‚’è¦‹ç©ã‚‚ã‚‹\n\n\næ‰‹é †(2)\n\\(H_0: \\delta = 0, H_1: \\delta \\neq 0\\) ã®ã‚ˆã†ã«Hypothesesã‚’è¨€èªåŒ–ã™ã‚‹\n\n\næ‰‹é †(3)\næœ‰æ„æ°´æº– \\(\\alpha\\), æ¤œå‡ºåŠ› \\(1 - \\beta\\) ã‚’å®šã‚ã‚‹\n\n\næ‰‹é †(4)\næœ‰æ„æ°´æº– \\(\\alpha\\), æ¤œå‡ºåŠ› \\(1 - \\beta\\) ã®ã‚‚ã¨ã§ \\(\\delta_0\\) ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®å¿…è¦ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã™ã‚‹\n\n\næ‰‹é †(5)\nPopulationã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«Entityã‚’ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦ï¼Œæ‰‹é †(4)ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’æº€ãŸã™ã‚ˆã†ã«Entityã‚’ãƒ©ãƒ³ãƒ€ãƒ  or å±¤åŒ–ãƒ©ãƒ³ãƒ€ãƒ ã§treated/controlã«å‰²ã‚Šå½“ã¦ã‚‹\n\n\næ‰‹é †(6)\ntreated, controlã®ãƒãƒ©ãƒ³ã‚¹ãƒã‚§ãƒƒã‚¯\n\n\næ‰‹é †(7)\ntreated, controlãŒã¨ã‚‚ã«å®Ÿé¨“ã‹ã‚‰é€¸è„±ã—ãªã„å½¢ã§ãã‚Œãã‚Œå‡¦ç½®ã‚’å—ã‘ã‚‹ã“ã¨ã‚’è¦³å¯Ÿ(= ãƒ—ãƒ­ãƒˆã‚³ãƒ«éµå®ˆã®ç¢ºä¿)\n\n\næ‰‹é †(8)\ntreated, controlã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã—ï¼ŒAttritionãªã©ã®å¯¾å¿œã‚’å®Ÿæ–½ã—ãŸä¸Šã§ï¼Œä¸»è¦è©•ä¾¡é …ç›®, æ¤œå®šçµ±è¨ˆé‡ã‚’è¨ˆç®—\n\n\næ‰‹é †(9)\næ‰‹é †(8)ã§è¨ˆç®—ã•ã‚ŒãŸæ¤œå®šçµ±è¨ˆé‡ã‚’å…ƒã«ï¼Œçµ±è¨ˆçš„æ¤œå®šã‚’å®Ÿæ–½ã—ï¼ŒPå€¤ãŒæœ‰æ„æ°´æº– \\(\\alpha\\) ä»¥ä¸‹ãªã‚‰ã°åŠ¹æœãŒã‚ã‚‹ã¨çµ±è¨ˆçš„åˆ¤æ–­ã‚’ä¸‹ã—ï¼Œãã‚Œä»¥å¤–ã®å ´åˆã§ã¯ \\(H_0\\) ãŒæ£„å´ã§ããªã‹ã£ãŸã¨ã™ã‚‹\n\n\n\nä¸Šè¨˜ã®æ‰‹é †ã«å‰‡ã£ã¦ï¼Œ\\(H_0\\) ãŒæ£„å´ã•ã‚ŒãŸå ´åˆï¼Œå°‘ãªãã¨ã‚‚ \\(\\delta \\geq \\delta_0\\) ãªã®ã ã‚ã†ã¨ã„ã†çµ±è¨ˆçš„åˆ¤æ–­ãŒãªã•ã‚Œã¾ã™ï¼\n\n\næ¢ç´¢çš„ãƒªã‚µãƒ¼ãƒã¨ä»®èª¬æ¤œå®š\næ¢ç´¢çš„ãƒªã‚µãƒ¼ãƒã§ã¯ï¼Œå¤šãã®å ´åˆï¼Œã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚„ç‰¹å¾´é‡ãƒãƒ©ãƒ³ã‚¹ãŒã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã§ããªã„è¦³å¯Ÿãƒ‡ãƒ¼ã‚¿ã‚’å¯¾è±¡ã«åˆ†æã—ï¼Œ ã¾ãŸæ¬¡ã®ãƒªã‚µãƒ¼ãƒã«é€²ã‚€ãŸã‚ã®ä»®èª¬æ§‹ç¯‰ã‚„æ¤œè¨ã«å€¤ã™ã‚‹ç‰¹å¾´é‡ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç›®çš„ã¨ã™ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ï¼ã“ã®ã¨ãæ¤œå®šã‚’å®Ÿæ–½ã™ã‚‹ã¨ã—ã¦ã‚‚ï¼Œæœ‰æ„æ°´æº–ï¼Œæ¤œå‡ºåŠ›ï¼ŒEffect Sizeã‚’æƒ³å®šã—ãŸ Neyman-Pearsonæµã®æ¤œå®šã®å®Ÿæ–½ã¯é›£ã—ãï¼Œå¶ç„¶ã®ãƒãƒ©ãƒ„ã‚­ã«ã—ã¦ã¯å·®ãŒå¤§ããã†ã¨ã„ã†ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’å¾—ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ãŸFisheræµä»®èª¬æ¤œå®šã®ç”¨ã„æ–¹ã¨ãªã‚Šã¾ã™ï¼\nãŸã ï¼ŒPå€¤ã«åŸºã¥ã„ã¦æ¨è«–ã‚’è¡Œã†ã®ã§ã¯ãªãï¼Œå¹³å‡ã®å·®ã‚„ãƒã‚¶ãƒ¼ãƒ‰æ¯”ãªã©ã®æŒ‡æ¨™ã‚„ä¿¡é ¼åŒºé–“ï¼Œã¾ãŸãã®åˆ†é‡ã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’è€ƒæ…®ã—ãŸä¸Šã§ï¼Œ ç·åˆçš„ã«çµæœã‚’è§£é‡ˆâ†’ä»®èª¬ã®æ§‹ç¯‰ã‚’ã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã™ï¼",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#appendix-æ–°è–¬èª•ç”Ÿã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#appendix-æ–°è–¬èª•ç”Ÿã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹",
    "title": "7Â  Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š",
    "section": "Appendix: æ–°è–¬èª•ç”Ÿã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹",
    "text": "Appendix: æ–°è–¬èª•ç”Ÿã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹\n\n\n\nå‡ºå…¸: æ²»é¨“ã®ï¼“ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼Œç¾¤é¦¬å¤§å­¦åŒ»å­¦éƒ¨é™„å±ç—…é™¢ å…ˆç«¯åŒ»ç™‚é–‹ç™ºã‚»ãƒ³ã‚¿ãƒ¼è‡¨åºŠç ”ç©¶æ¨é€²éƒ¨\n\n\n\nTable: å„å·¥ç¨‹ã«ãŠã‘ã‚‹åˆ†æç›®çš„\n\n\n\n\n\n\nå·¥ç¨‹\nèª¬æ˜\n\n\n\n\næ–°è¦ç‰©è³ªã®æ¢ç´¢ãƒ»å‰µè£½\nè–¬ã«ãªã‚Šãã†ãªæ–°ã—ã„ç‰©è³ªã‚’æ¢ã—ãŸã‚Šï¼Œä½œã‚Šå‡ºã—ãŸã‚Šã™ã‚‹ã“ã¨\n\n\nç‰©ç†çš„åŒ–å­¦çš„ç ”ç©¶\næ–°è¦ç‰©è³ªã®æ§‹é€ ã‚„ç‰©ç†çš„ãƒ»åŒ–å­¦çš„ãªæ€§çŠ¶ãªã©ã‚’èª¿ã¹ã‚‹ã“ã¨\n\n\nè–¬åŠ¹è–¬ç†ç ”ç©¶\nã©ã®ã‚ˆã†ãªåŠ¹æœãŒã‚ã‚‹ã‹ï¼Œã©ã®ã‚ˆã†ãªãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã§åŠ¹æœã‚’ç¾ã™ã®ã‹ãªã©ã‚’èª¿ã¹ã‚‹ã“ã¨\n\n\nè–¬ç‰©å‹•æ…‹ç ”ç©¶\nã©ã®ã‚ˆã†ã«ï¼Œä½“å†…ã«å¸åã•ã‚Œï¼Œè‡“å™¨ãªã©ã«åˆ†å¸ƒã—ï¼Œä»£è¬ã•ã‚Œã¦æ’æ³„ã•ã‚Œã‚‹ã‹ãªã©ã‚’èª¿ã¹ã‚‹ã“ã¨\n\n\nä¸€èˆ¬è–¬ç†ç ”ç©¶\nã©ã®ã‚ˆã†ãªéƒ¨ä½ã«ã©ã‚“ãªä½œç”¨ã‚’åŠã¼ã™ã‹ãªã©ï¼Œè–¬åŠ¹è–¬ç†ä½œç”¨ä»¥å¤–ã®å®‰å…¨æ€§ã«é–¢ã™ã‚‹ä½œç”¨ã‚’èª¿ã¹ã‚‹ã“ã¨\n\n\nä¸€èˆ¬æ¯’æ€§ç ”ç©¶\næŠ•ä¸æœŸé–“ã‚’çŸ­ãƒ»ä¸­ãƒ»é•·æœŸãªã©ã«åˆ†ã‘ã¦ï¼Œæ¯’æ€§ï¼ˆå®‰å…¨æ€§ï¼‰ã‚’åºƒãèª¿ã¹ã‚‹ã“ã¨\n\n\nç‰¹æ®Šæ¯’æ€§ç ”ç©¶\nç™ºãŒã‚“æ€§ã‚„èƒå…ã¸ã®å½±éŸ¿ãŒãªã„ã‹ãªã©ï¼Œç‰¹åˆ¥ãªæ¯’æ€§ï¼ˆå®‰å…¨æ€§ï¼‰ã‚’èª¿ã¹ã‚‹ã“ã¨\n\n\nè‡¨åºŠç¬¬Iç›¸è©¦é¨“ï¼ˆè‡¨åºŠè–¬ç†è©¦é¨“ï¼‰\nå°‘æ•°ã®å¥åº·æˆäººãªã©ã«ã¤ã„ã¦ï¼Œä¸»ã«å®‰å…¨æ€§ã‚„è–¬ç‰©å‹•æ…‹ãªã©ã‚’èª¿ã¹ã‚‹è©¦é¨“\n\n\nè‡¨åºŠç¬¬IIç›¸è©¦é¨“ï¼ˆæ¢ç´¢çš„è©¦é¨“ï¼‰\næ¯”è¼ƒçš„å°‘æ•°ã®æ‚£è€…ã•ã‚“ã«ã¤ã„ã¦ï¼Œæœ‰åŠ¹æ€§ã¨å®‰å…¨æ€§ãªã©ã‚’èª¿ã¹ã‚‹è©¦é¨“\n\n\nè‡¨åºŠç¬¬IIIç›¸è©¦é¨“ï¼ˆæ¤œè¨¼çš„è©¦é¨“ï¼‰\nå¤šæ•°ã®æ‚£è€…ã•ã‚“ã«ã¤ã„ã¦ï¼Œæ¨™æº–çš„ãªã€Œãã™ã‚Šã€ãªã©ã¨æ¯”è¼ƒã—ã¦æœ‰åŠ¹æ€§ã¨å®‰å…¨æ€§ã‚’ç¢ºèªã™ã‚‹è©¦é¨“\n\n\nè£½é€ è²©å£²å¾Œèª¿æŸ»\nè£½é€ è²©å£²å¾Œã«å¤šãã®æ‚£è€…ã•ã‚“ã«ä½¿ç”¨ã•ã‚ŒãŸã¨ãã®å®‰å…¨æ€§ã‚„æœ‰åŠ¹æ€§ãªã©ã®æƒ…å ±ã‚’é›†ã‚ï¼Œãã‚Œã‚’åˆ†æãƒ» è©•ä¾¡ã—ã¦åŒ»ç™‚é–¢ä¿‚è€…ãªã©ã«ä¼ãˆã‚‹ã“ã¨",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ",
      "<span class='chapter-number'>7</span>Â  <span class='chapter-title'>Fisheræµæ¤œå®š vs Neyman-Pearsonæµæ¤œå®š</span>"
    ]
  },
  {
    "objectID": "posts/ExplanatoryDataAnalysis/gini_coefficient.html",
    "href": "posts/ExplanatoryDataAnalysis/gini_coefficient.html",
    "title": "8Â  ã‚¸ãƒ‹ä¿‚æ•°",
    "section": "",
    "text": "ã‚¸ãƒ‹ä¿‚æ•°ã¨ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š\nPythonã§å½¢çŠ¶ãƒ‘ãƒ©ãƒ¡ã‚¿ãƒ¼ 2.5 ã®ãƒ‘ãƒ¬ãƒ¼ãƒˆåˆ†å¸ƒã®ä¹±æ•°ã¨ \\(\\operatorname{Unif}(0, 1)\\) ã‚’20å€‹ãšã¤ç™ºç”Ÿã•ã›ä½œç”»ã—ãŸã®ãŒä»¥ä¸‹\nCode\nimport numpy as np\nfrom scipy.stats import pareto\nimport polars as pl\nimport plotly.express as px\n\nnp.random.seed(42)\n\nSAMPLESIZE = 20\nshape_parameter = 1\nx = pareto.rvs(shape_parameter, size=SAMPLESIZE)\nx2 = np.random.uniform(0, 1, SAMPLESIZE)\n\n# Compute ratio\nrelative_freq = np.arange(0, SAMPLESIZE + 1) / SAMPLESIZE\nrelative_cumulative_pareto = np.insert(np.cumsum(sorted(x)) / np.sum(x), 0, 0)\nrelative_cumulative_uniform = np.insert(np.cumsum(sorted(x2)) / np.sum(x2), 0, 0)\n\n# create dataframe\ndf = pl.DataFrame(\n    {\n        \"relative_freq\": relative_freq,\n        \"pareto\": relative_cumulative_pareto,\n        \"uniform\": relative_cumulative_uniform,\n    }\n)\n\n\n# compute gini\ndef compute_gini(relative_freq, relative_cumulative):\n    a = relative_freq[1:-1] - relative_cumulative[1:-1]\n    b = relative_freq[2:] - relative_freq[:-2]\n    return np.sum(a * b)\n\n\n# plot\npareto_gini = compute_gini(relative_freq, relative_cumulative_pareto)\nuniform_gini = compute_gini(relative_freq, relative_cumulative_uniform)\nfig = px.line(\n    df,\n    x=\"relative_freq\",\n    y=[\"pareto\", \"uniform\"],\n    color_discrete_sequence=[\"blue\", \"red\"],\n    markers=\"x\",\n    title=\"\"\"pareto gini coefficient: {:.2f}, uniform gini coeffient:  {:.2f}\"\"\".format(\n        pareto_gini, uniform_gini\n    ),\n)\n\nfig.update_yaxes(\n    scaleanchor=\"x\",\n    scaleratio=1,\n)\nBASE_SIZE = 600\nfig.update_layout(\n    autosize=True,\n    width=BASE_SIZE,\n    height=BASE_SIZE,\n    shapes=[\n        dict(\n            type=\"line\",\n            line_dash=\"dot\",\n            yref=\"y\",\n            y0=0,\n            y1=1,\n            xref=\"x\",\n            x0=0,\n            x1=1,\n            line=dict(color=\"gray\"),\n            label=dict(text=\"å®Œå…¨å¹³ç­‰ç·š\", textposition=\"middle center\"),\n        )\n    ],\n)\n\nfig.show()\nä¸Šè¨˜ã®figureã«ãŠã‘ã‚‹45åº¦ç·šã¯å®Œå…¨å¹³ç­‰ç·šã¨å‘¼ã°ã‚Œã‚‹ç·šã§ã™ï¼ã“ã®èµ¤ç·šã¨ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·šã§å›²ã¾ã‚ŒãŸã‚¨ãƒªã‚¢ã®é¢ç©ã®ï¼’å€ãŒã‚¸ãƒ‹ä¿‚æ•°ã«ç›¸å½“ã—ã¾ã™ï¼ã‚¸ãƒ‹ä¿‚æ•°ã¯èµ¤ç·šã¨é’ç·šã®ã‚¨ãƒªã‚¢ã‚’ä¸‰è§’å½¢ã¨å°å½¢ã«åˆ†ã‘ã¦ãã‚Œãã‚Œã‚’è¨ˆç®—ã—ï¼Œãã®åˆè¨ˆã®ï¼’å€ã§è¨ˆç®—ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼\nä¸Šè¨˜ã®ã‚ˆã†ã«sampleã‚¸ãƒ‹ä¿‚æ•°ã¯å°å½¢ã®é¢ç©ã®ï¼’å€ã§è¨ˆç®—ã—ã¾ã™ãŒï¼Œæ¯é›†å›£ã‚¸ãƒ‹ä¿‚æ•°ã¨æ¯”è¼ƒã—ã¦å°ã•ã‚ã«è¨ˆç®—ã•ã‚Œã¾ã™ï¼ ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãŒååˆ†å¤§ãã„å ´åˆã¯ç„¡è¦–ã§ãã‚‹ç¨‹åº¦ã§ã™ãŒï¼Œåº¦æ•°åˆ†å¸ƒè¡¨ã«åŸºã¥ãè¨ˆç®—ã®å ´åˆã‚„small sampleã®å ´åˆã¯ éå°æ–¹å‘ãƒã‚¤ã‚¢ã‚¹ã®ä¿®æ­£ãŒå¿…è¦ã«ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼\nã¾ãŸï¼Œã‚¸ãƒ‹ä¿‚æ•°ã®å°å‡ºå¼ã‚ˆã‚Šï¼ŒMAD(Mean absolute difference)ã¨ sample meanã®ç›¸å¯¾æ¯”ã«ã‚¸ãƒ‹ä¿‚æ•°ãŒæ¯”ä¾‹ã™ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ï¼\n\\[\n\\begin{align*}\n\\operatorname{Gini} &= \\frac{1}{2n^2\\overline{x}}\\sum_{i=1}^n\\sum_{j=1}^n \\vert x_i - x_j\\vert\\\\\n                    &= \\frac{1}{2}\\frac{\\sum_{i=1}^n\\sum_{j=1}^n \\vert x_i - x_j\\vert}{n^2}\\frac{1}{\\overline x}\\\\\n                    &\\propto \\frac{\\operatorname{MAD}}{\\operatorname{sample mean}}\n\\end{align*}\n\\]\nâ–¶Â  ã‚¸ãƒ‹ä¿‚æ•°ã®ç‰¹å¾´",
    "crumbs": [
      "Explanatory Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>ã‚¸ãƒ‹ä¿‚æ•°</span>"
    ]
  },
  {
    "objectID": "posts/ExplanatoryDataAnalysis/gini_coefficient.html#ã‚¸ãƒ‹ä¿‚æ•°ã¨ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š",
    "href": "posts/ExplanatoryDataAnalysis/gini_coefficient.html#ã‚¸ãƒ‹ä¿‚æ•°ã¨ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š",
    "title": "8Â  ã‚¸ãƒ‹ä¿‚æ•°",
    "section": "",
    "text": "Def: ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š \nãƒ‡ãƒ¼ã‚¿ \\(X = \\{x_1, \\cdots, x_n\\}\\) ã«ã¤ã„ã¦ï¼Œä»¥ä¸‹ã®ã‚ˆã†ãªé †åºçµ±è¨ˆé‡ã‚’ã¨ã‚‹\n\\[\nx_{[1]} \\leq \\cdots \\leq x_{[i]} \\leq \\cdots \\leq x_{[n]}\n\\]\nã“ã®ã¨ãï¼Œç›¸å¯¾åº¦æ•° \\(r_i\\) ã¨ç´¯ç©æ¯”ç‡ \\(I_i\\) ã‚’ãã‚Œãã‚Œä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã™ã‚‹ï¼š\n\\[\n\\begin{align*}\nr_i & = \\frac{i}{n}\\\\\nI_i &= \\frac{\\sum_{j=1}^i x_{[j]}}{\\sum_{j=1}^n x_{[j]}}\n\\end{align*}\n\\]\nç‚¹ \\((0,0), (r_1, I_1), \\cdots , (r_n, I_n)\\) ã‚’åŒºåˆ†çš„ã«ç›´ç·šã§çµã‚“ã§å¾—ã‚‰ã‚Œã‚‹æ›²ç·šãŒãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·šã§ã‚ã‚‹ï¼\n\n\n\n\n\nDef: ã‚¸ãƒ‹ä¿‚æ•° \n\nã‚¸ãƒ‹ä¿‚æ•°ã¯ãƒ‡ãƒ¼ã‚¿ã®åã‚Šã‚’ç¤ºã™æŒ‡æ¨™\n\n â–¶Â  ç›¸å¯¾åº¦æ•°ã«åŸºã¥ãã‚¸ãƒ‹ä¿‚æ•°\n\\(a_i\\) ã‚’åº¦æ•°è¡¨ã«åŸºã¥ãç´¯ç©ç›¸å¯¾é »åº¦ï¼Œ \\(b_i\\) ã‚’ç´¯ç©ç›¸å¯¾éšç´šå€¤ã¨ã—ãŸã¨ã\n\\[\n\\begin{align*}\n\\operatorname{Gini} = \\sum_{i=1}^{k-1} (a_i - b_i)(a_{i+1} - a_{i-1}) \\  \\ \\text{where } a_0 = 0, b_0 = 0\n\\end{align*}\n\\]\n â–¶Â  ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã‚¸ãƒ‹ä¿‚æ•°\n\\[\n\\begin{align*}\n\\operatorname{Gini}\n    &= \\frac{2}{n}\\sum_{n-1}^{i=1}\\left(\\frac{i}{n} - \\frac{\\sum_{j=1}^i x_{[j]}}{n\\overline{x}}\\right) \\\\\n    &= \\frac{1}{2n^2\\overline{x}}\\sum_{i=1}^n\\sum_{j=1}^n \\vert x_i - x_j\\vert\n\\end{align*}\n\\]\n\n\n\n\n\n\nãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·šï¼Œã‚¸ãƒ‹ä¿‚æ•°ã¨ã‚‚ã«åˆ†å¸ƒã®å°ºåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã«ä¾å­˜ã—ãªã„\n1ç‚¹ã«é›†ä¸­ã™ã‚‹åˆ†å¸ƒã®å ´åˆï¼Œãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·šã¯å®Œå…¨å¹³ç­‰ç·šã¨ä¸€è‡´ã—ï¼Œã‚¸ãƒ‹ä¿‚æ•°ã¯0ã¨ãªã‚‹\nã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¨ç•°ãªã‚Šï¼Œä¸€æ§˜åˆ†å¸ƒã®å ´åˆã«ã‚¸ãƒ‹ä¿‚æ•°ãŒæœ€å¤§ã‚’ã¨ã‚‹ã¨ã‹ã§ã¯ãªã„\n\n\nğŸ“˜ REMARKS \n\nãƒ‡ãƒ¼ã‚¿ã®åã‚Šã‚„é›†ä¸­æ€§ã‚’è¦‹ã‚‹æŒ‡æ¨™ã¨ã—ã¦ã‚¸ãƒ‹ä¿‚æ•°ã¯ä½¿ç”¨ã•ã‚Œã¾ã™ãŒï¼Œä»–ã«ã‚‚ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¨ã„ã†æŒ‡æ¨™ãŒã‚ã‚‹\n\nã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã«åˆ†é¡ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã«ãŠã„ã¦ï¼Œå„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ç·ä½“é »åº¦ã‚’ \\(\\hat p_i = f_i/n\\) ã¨ã—ãŸã¨ã\n\\[\n\\begin{align*}\nH(\\mathbf p) = -\\sum \\hat p_i \\log(\\hat p_i)\n\\end{align*}\n\\]\nHãŒå¤§ãã„ã»ã©ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ§˜ã«ãªã‚Šï¼Œé›†ä¸­æ€§ãŒã‚ã‚‹ã»ã©æŒ‡æ¨™ã¯å°ã•ããªã‚‹ï¼\n\n\nç„¡é™æ¯é›†å›£ã«ãŠã‘ã‚‹ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·š\nå®šç¾©åŸŸ \\((0, \\infty)\\), æœŸå¾…å€¤ \\(\\mu\\) ã‚’æŒã¤é€£ç¶šç¢ºç‡å¤‰æ•° \\(X\\) ã«ã¤ã„ã¦ï¼Œç´¯ç©åˆ†å¸ƒé–¢æ•°ã‚’ \\(F(x)\\), ç¢ºç‡å¯†åº¦é–¢æ•° \\(f(x)\\) ã¨ãŠãã¾ã™ï¼ã“ã®ã¨ãï¼Œ\\(z = F(x)\\) ã¨ã—ãŸã¨ãã®ãƒ­ãƒ¼ãƒ¬ãƒ³ãƒ„æ›²ç·šã¯\n\\[\n\\begin{align*}\n&F^{-1}(z) = x \\  \\ \\text{ (inverse function of cdf)}\\\\\n&L(z) =\\frac{\\int_0^{F^{-1}(z)} t f(t) \\mathrm{d}t}{\\mathbb E[X]}\n\\end{align*}\n\\]\nã¨ã—ã¦, \\((z, L(z))\\) ã§ä½œã‚‰ã‚Œã‚‹æ›²ç·šã¨ãªã‚Šã¾ã™ï¼ã‚¸ãƒ‹ä¿‚æ•°ã¯\n\\[\n\\begin{align*}\n\\operatorname{gini} &= 2\\int_0^1 (u - L(u))\\mathrm{d}u\\\\\n                    &= 1 - 2\\int_0^1 L(u)\\mathrm{d}u\n\\end{align*}\n\\]",
    "crumbs": [
      "Explanatory Data Analysis",
      "<span class='chapter-number'>8</span>Â  <span class='chapter-title'>ã‚¸ãƒ‹ä¿‚æ•°</span>"
    ]
  },
  {
    "objectID": "posts/mathematical_appendix/beta_function.html",
    "href": "posts/mathematical_appendix/beta_function.html",
    "title": "9Â  ãƒ™ãƒ¼ã‚¿é–¢æ•°",
    "section": "",
    "text": "ãƒ™ãƒ¼ã‚¿é–¢æ•°ã®æ€§è³ª",
    "crumbs": [
      "Mathematical Appendix",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ãƒ™ãƒ¼ã‚¿é–¢æ•°</span>"
    ]
  },
  {
    "objectID": "posts/mathematical_appendix/beta_function.html#ãƒ™ãƒ¼ã‚¿é–¢æ•°ã®æ€§è³ª",
    "href": "posts/mathematical_appendix/beta_function.html#ãƒ™ãƒ¼ã‚¿é–¢æ•°ã®æ€§è³ª",
    "title": "9Â  ãƒ™ãƒ¼ã‚¿é–¢æ•°",
    "section": "",
    "text": "Def: ãƒ™ãƒ¼ã‚¿é–¢æ•° \nå®Ÿæ•° \\(a, b\\) ã«ã¤ã„ã¦ï¼Œãƒ™ãƒ¼ã‚¿é–¢æ•° \\(\\operatorname{B}(a, b)\\) ã¯ä»¥ä¸‹ã®ã‚ˆã†ã«å®šç¾©ã•ã‚Œã‚‹ï¼\n\\[\n\\operatorname{B}(a, b) = \\int^1_0 x^{a-1}(1-x)^{b-1}\\mathrm{d}x\n\\]\nã¾ãŸï¼Œã‚¬ãƒ³ãƒé–¢æ•°ã‚’ç”¨ã„ã¦ä»¥ä¸‹ã®ã‚ˆã†ã«è¡¨ã›ã‚‹\n\\[\n\\operatorname{B}(a, b) = \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\n\\]\n\n\n\n\n\n\n\nProof: ãƒ™ãƒ¼ã‚¿é–¢æ•°ã¨ã‚¬ãƒ³ãƒé–¢æ•°ã®é–¢ä¿‚\n\n\n\n\n\nã‚¬ãƒ³ãƒé–¢æ•°ã®å®šç¾©ã‚’ç”¨ã„ã¦ï¼Œ\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &= \\int^\\infty_0 x^{a-1}\\exp(-x)\\mathrm{d}x \\int^\\infty_0 y^{b-1}\\exp(-y)\\mathrm{d}y \\\\\n                   &= \\int^\\infty_0 \\int^\\infty_0 x^{a-1}y^{b-1}\\exp(-x-y)\\mathrm{d}x \\mathrm{d}y \\\\\n\\end{align*}\n\\]\nã“ã“ã§, \\(x + y = u, x/(x + y) = v\\) ã¨ã„ã†å¤‰æ•°å¤‰æ›ã‚’è€ƒãˆã‚‹ï¼ã¤ã¾ã‚Šï¼Œ\n\\[\n\\begin{align*}\nx = uv, y = u(1-v)\n\\end{align*}\n\\]\nã“ã®ã¨ãã®ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ã¯\n\\[\n\\begin{align*}\n\\vert\\operatorname{det} J \\vert= u\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &=\\int^\\infty_0 \\int^\\infty_0 (uv)^{a-1}[u(1-v)]^{b-1}\\exp(-u) u\\mathrm{d}x \\mathrm{d}y \\\\\n                   &= \\int^\\infty_0 \\int^\\infty_0 u^{a+b-1}\\exp(-u) v^{a-1}(1-v)^{b-1}\\mathrm{d}x \\mathrm{d}y \\\\\n                   &= \\int^\\infty_0 \\int^1_0 u^{a+b-1}\\exp(-u) v^{a-1}(1-v)^{b-1}\\mathrm{d}v \\mathrm{d}u \\\\\n                   &= \\int^\\infty_0 u^{a+b-1}\\exp(-u) \\mathrm{d}u \\int^1_0 v^{a-1}(1-v)^{b-1}\\mathrm{d}v \\\\\n                   &= \\operatorname{\\Gamma}(a+b)\\operatorname{B}(a, b)\n\\end{align*}\n\\]\nã¤ã¾ã‚Šï¼Œ\n\\[\n\\operatorname{B}(a, b) = \\frac{\\operatorname{\\Gamma}(a+b)}{\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b)}\n\\]\n\n\n\n\n\n\n\n\n\nProof: åº§æ¨™å¤‰æ›\n\n\n\n\n\nã‚¬ãƒ³ãƒé–¢æ•°ã¯ \\(z^2 = x\\) ã¨ã„ã†å¤‰æ•°å¤‰æ›ã‚’ç”¨ã„ã‚‹ã¨ä»¥ä¸‹ã®ã‚ˆã†ã«å¤‰æ›ã§ãã‚‹\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a) &= \\int^\\infty_0 x^{a-1}\\exp(-x)\\mathrm{d}x \\\\\n          &= \\int^\\infty_0 z^{2a-2}\\exp(-z^2)\\frac{\\mathrm{d}x}{\\mathrm{d}z}\\mathrm{d}z \\\\\n          &= 2\\int^\\infty_0 z^{2a-1}\\exp(-z^2)\\mathrm{d}z\n\\end{align*}\n\\]\nã“ã‚Œã‚’ç”¨ã„ã¦\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &= 4\\int^\\infty_0 x^{2a-1}\\exp(-x^2)\\mathrm{d}x \\int^\\infty_0 y^{2b-1}\\exp(-y^2)\\mathrm{d}y \\\\\n                   &= 4\\int^\\infty_0 \\int^\\infty_0 x^{2a-1}y^{2b-1}\\exp(-(x^2+y^2))\\mathrm{d}x \\mathrm{d}y\n\\end{align*}\n\\]\nã“ã“ã§, \\(x = r\\cos\\theta, y=r\\sin\\theta\\) ã¨ã„ã†å¤‰æ•°å¤‰æ›ã‚’è¡Œã†ï¼ã“ã®ã¨ãã®ãƒ¤ã‚³ãƒ“ã‚¢ãƒ³ã¯\n\\[\n\\vert \\operatorname{det} J \\vert = r\n\\]\nã‚ˆã£ã¦ï¼Œ \\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &= 4\\int^\\infty_0 \\int^\\infty_0 x^{2a-1}y^{2b-1}\\exp(-(x^2+y^2))\\mathrm{d}x \\mathrm{d}y\\\\\n                   &= 4\\int^{\\pi/2}_0 \\int^\\infty_0 r^{2a+2b-2} \\cos^{2a-1}\\theta \\sin^{2b-1}\\theta \\exp(-r^2) r \\mathrm{d}r \\mathrm{d}\\theta\\\\\n                   &= \\left(2\\int^{\\pi/2}_0 \\cos^{2a-1}\\theta \\sin^{2b-1}\\theta \\mathrm{d}\\theta\\right) \\times \\left(\\int^\\infty_0r^{2(a+b)-1}\\exp(-r^2)\\mathrm{d}r \\right)\\\\\n                   &= \\operatorname{B}(a, b) \\times \\operatorname{\\Gamma}(a+b)\n\\end{align*}\n\\]\nå¾“ã£ã¦ï¼Œ\n\\[\n\\operatorname{B}(a, b) = \\frac{\\operatorname{\\Gamma}(a+b)}{\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b)}\n\\]\n\n\n\n\n\nTheorem 9.1 ä¸‰è§’é–¢æ•°ã¨ãƒ™ãƒ¼ã‚¿é–¢æ•°ã®é–¢ä¿‚ \næ­£ã®å®Ÿæ•° \\(a, b\\) ã«ã¤ã„ã¦ï¼Œä»¥ä¸‹ãŒæˆç«‹ã™ã‚‹\n\\[\n\\operatorname{B}(a, b) = 2\\int^{\\pi/2}_0\\cos^{2a-1}\\theta\\sin^{2b-1}\\theta \\mathrm{d}\\theta\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nãƒ™ãƒ¼ã‚¿é–¢æ•°ã«ã¤ã„ã¦ \\(x = \\cos^2\\theta\\) ã‚’ç”¨ã„ãŸç½®æ›ç©åˆ†ã§ä»¥ä¸‹ã®ã‚ˆã†ã«ç¤ºã™ã“ã¨ãŒã§ãã¾ã™ï¼\n\\[\n\\begin{align*}\n\\operatorname{B}(a, b) &= \\int^1_0 x^{a-1}(1-x)^{b-1} \\mathrm{d}x\\\\\n                       &= \\int^0_{\\pi/2} (\\cos^2\\theta)^{a-1}(1 - \\cos^2\\theta)^{b-1} \\cdot (-2\\cos\\theta\\sin\\theta) \\mathrm{d}\\theta\\\\\n                       &= 2\\int^{\\pi/2}_0 \\cos^{2a-1}\\theta \\sin^{2b-1}\\theta\\mathrm{d}\\theta\n\\end{align*}\n\\]\nãªãŠ, \\(\\sin^2\\theta = 1 - \\cos^2\\theta\\) åŠã³ \\(\\displaystyle\\frac{\\mathrm{d}\\cos^2\\theta}{\\mathrm{d}\\theta} = -2\\cos\\theta\\sin\\theta\\) ã‚’ç”¨ã„ã¦ã„ã‚‹ï¼\n\n\n\n\n\nTheorem 9.2 å¼•æ•°ã®äº¤æ›æ€§ \næ­£ã®å®Ÿæ•° \\(a, b\\) ã«ã¤ã„ã¦ï¼Œä»¥ä¸‹ãŒæˆç«‹ã™ã‚‹\n\\[\n\\operatorname{B}(a, b) = \\operatorname{B}(b, a)\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\operatorname{B}(a, b) &= \\int^1_0 x^{a-1}(1-x)^{b-1} \\mathrm{d}x\\\\\n                       &= \\int^0_1 (1-z)^{a-1}z^{b-1} \\frac{\\mathrm{d}x}{\\mathrm{d}z}\\mathrm{d}z\\\\\n                       &= \\int^1_0 (1-z)^{a-1}z^{b-1} \\mathrm{d}z\\\\\n                       &= \\operatorname{B}(b, a)\n\\end{align*}\n\\]",
    "crumbs": [
      "Mathematical Appendix",
      "<span class='chapter-number'>9</span>Â  <span class='chapter-title'>ãƒ™ãƒ¼ã‚¿é–¢æ•°</span>"
    ]
  },
  {
    "objectID": "posts/mathematical_appendix/jensen_inequality.html",
    "href": "posts/mathematical_appendix/jensen_inequality.html",
    "title": "10Â  Jensenâ€™s Inequality",
    "section": "",
    "text": "Def: convex function \nåŒºé–“ \\(I\\) ã§å®šç¾©ã•ã‚ŒãŸé–¢æ•° \\(f:I \\to \\mathbb R\\) ãŒconvex(å‡¸é–¢æ•°)ã§ã‚ã‚‹ã¨ã¯, ä»»æ„ã® \\(0 &lt; t &lt; 1\\) ã«ã¤ã„ã¦\n\\[\nf((1-t)x + ty) \\leq (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\nstrictly convexã§ã‚ã‚‹ã¨ã¯\n\\[\nf((1-t)x + ty) &lt; (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\n\n\n\nDef: concave function \nåŒºé–“ \\(I\\) ã§å®šç¾©ã•ã‚ŒãŸé–¢æ•° \\(f:I \\to \\mathbb R\\) ãŒconcave(å‡¹é–¢æ•°)ã§ã‚ã‚‹ã¨ã¯, ä»»æ„ã® \\(0 &lt; t &lt; 1\\) ã«ã¤ã„ã¦\n\\[\nf((1-t)x + ty) \\geq (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\nstrictly concaveã§ã‚ã‚‹ã¨ã¯\n\\[\nf((1-t)x + ty) &gt; (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\n\n\nä»¥ä¸‹ã®ã‚ˆã†ãª \\(\\exp(x), x^2, \\vert x\\vert\\) ãªã©ãŒå‡¸é–¢æ•°ã®ä¾‹ã§ã™.\n\n\nCode\nimport numpy as np\nimport plotly.express as px\nimport polars as pl\n\nx = np.linspace(-1, 1, 100)\nexp_x = np.exp(x)\nsquared_x = x**2\nabs_x = abs(x)\n\ndf = pl.DataFrame({\"x\": x, \"exp_x\": exp_x, \"squared_x\": squared_x, \"abs_x\": abs_x})\n\nfig = px.line(df, x=\"x\", y=[\"exp_x\", \"squared_x\", \"abs_x\"], title='example: convex fucntions')\nnewnames = {\"exp_x\": \"exp(x)\", \"squared_x\": \"x^2\", \"abs_x\": \"abs(x)\"}\nfig.for_each_trace(\n    lambda t: t.update(\n        name=newnames[t.name],\n        hovertemplate=t.hovertemplate.replace(t.name, newnames[t.name]),\n    )\n)\n\nfig.show()\n\n\n                                                \n\n\nã¾ãŸ, \\(\\ln(x), \\sqrt{x}\\) ã‚„convexté–¢æ•°ã« \\(-1\\) ã‚’æ›ã‘ãŸã‚‚ã®ã¯å‡¹é–¢æ•°ã®ä¾‹ã¨ãªã‚Šã¾ã™ï¼\n\n\nCode\nx = np.linspace(0.05, 1.5, 100)\n\nln_x = np.log(x)\nsqrt_x = np.sqrt(x)\nsquared_x = -(x**2)\n\ndf = pl.DataFrame({\"x\": x, \"ln_x\": ln_x, \"sqrt_x\": sqrt_x, \"squared_x\": squared_x})\n\nfig = px.line(\n    df, x=\"x\", y=[\"ln_x\", \"sqrt_x\", \"squared_x\"], title=\"example: concave fucntions\"\n)\nnewnames = {\"ln_x\": \"log(x)\", \"sqrt_x\": \"sqrt(x)\", \"squared_x\": \"-x^2\"}\nfig.for_each_trace(\n    lambda t: t.update(\n        name=newnames[t.name],\n        hovertemplate=t.hovertemplate.replace(t.name, newnames[t.name]),\n    )\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nTheorem 10.1 \né–¢æ•° \\(f\\) ãŒåŒºé–“ \\([a, b]\\) ã§é€£ç¶šã§ \\((a, b)\\) ã§ï¼’å›å¾®åˆ†å¯èƒ½ã¨ã™ã‚‹ï¼ã“ã®ã¨ãï¼Œ é–¢æ•° \\(f\\) ãŒå‡¸é–¢æ•°ã§ã‚ã‚‹ã“ã¨ã®å¿…è¦ååˆ†æ¡ä»¶ã¯\n\\[\nf^{\\prime\\prime}(x) \\geq 0 \\quad \\forall x\\in (a, b)\n\\]\n\n\n\n\n\nTheorem 10.2 : Subgradient Inequality \né–¢æ•° \\(f\\) ãŒåŒºé–“ \\([a, b]\\) ã§å‡¸é–¢æ•°ã§ã‚ã‚Šï¼Œå¾®åˆ†å¯èƒ½ã¨ã™ã‚‹ï¼ã“ã®ã¨ãä»¥ä¸‹ãŒæˆç«‹ã™ã‚‹\n\\[\nf(y) \\geq f(x) + f^{\\prime}(x)(y-x) \\quad \\forall x, y\\in (a, b)\n\\]\n\n\n\n\n\nTheorem 10.3 Jensenâ€™s Inequality \n\\(\\mathbb E[X] = \\mu &lt; \\infty\\) åŠã³ \\(I \\subset \\mathbb R\\) ã‚’ã‚µãƒãƒ¼ãƒˆã¨ã™ã‚‹ç¢ºç‡å¤‰æ•° \\(X\\) ã«ã¤ã„ã¦ï¼Œ\\(g:I\\to \\mathbb R\\) ã¨ã„ã†convex functionã‚’è€ƒãˆã‚‹ï¼\\(g\\) ãŒ åŒºé–“ \\(I\\) ã§å¾®åˆ†å¯èƒ½ã¨ã—ãŸã¨ãï¼Œ\n\\[\n\\mathbb E[g(X)] \\geq g(\\mathbb E[X])\n\\]\n\\(g\\) ãŒstrictly convexã®å ´åˆï¼Œ\\(X\\) ãŒdegenerateã§ã‚ã‚‹ã“ã¨ã®å¿…è¦ååˆ†æ¡ä»¶ã¯ \\(\\mathbb E[g(X)] = g(\\mathbb E[X])\\)ï¼\n\\(g(\\cdot)\\) ãŒconcaveã®å ´åˆã¯ï¼Œ\\(\\mathbb E[g(X)] \\leq g(\\mathbb E[X])\\) ãŒæˆç«‹ã™ã‚‹ï¼\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(g(\\cdot)\\) ã¯convex functionãªã®ã§,\n\\[\ng(X) \\geq g(\\mu) + g^\\prime(\\mu)(X - \\mu)\n\\]\nä¸¡è¾ºã«ã¤ã„ã¦æœŸå¾…å€¤ã‚’ã¨ã‚‹ã¨ï¼Œ\n\\[\n\\begin{align*}\n\\mathbb E[g(X)] &\\geq g(\\mathbb E[X]) + g^\\prime(\\mu)(\\mathbb E[X] - \\mu)\\\\\n                &= g(\\mathbb E[X])\n\\end{align*}\n\\]\n\n\n\n\nExample 10.1 \nç¢ºç‡å¤‰æ•° \\(X &gt;0\\) ãŒnon-degenerateã§ã‚ã‚‹ã¨ãï¼ŒJensenâ€™s inequalityã‚ˆã‚Š \\(g(x) = 1/x\\) ã¯strictly convexãªã®ã§\n\\[\n\\mathbb E\\left[\\frac{1}{X}\\right] &gt; \\frac{1}{\\mathbb E[X]}\n\\]",
    "crumbs": [
      "Mathematical Appendix",
      "<span class='chapter-number'>10</span>Â  <span class='chapter-title'>Jensen's Inequality</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/chapter_header.html",
    "href": "posts/statistics101/chapter_header.html",
    "title": "çµ±è¨ˆå­¦å…¥é–€",
    "section": "",
    "text": "â–¶Â  çµ±è¨ˆå­¦å…¥é–€ ã®ã‚¹ã‚³ãƒ¼ãƒ—\n\nç«¹æ‘å½°é€š (2020) ã‚’ãƒ™ãƒ¼ã‚¹ã«ï¼Œçµ±è¨ˆãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ã®ç¢ºç‡åˆ†å¸ƒæ—ã¨ï¼Œãã‚Œã‚‰ã«å¯¾ã™ã‚‹çµ±è¨ˆæ¨æ¸¬æ³•ã«ã¤ã„ã¦å‹‰å¼·ã™ã‚‹\nå‹‰å¼·å¯¾è±¡ã¯ä¸»ã«æ—¥ã€…ã®ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹åˆ†æã®ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ã‚ˆã†ãªçµ±è¨ˆåŸºç¤æ¦‚å¿µã‚„å®šç¾©ã«ãªã‚‹ãŒï¼Œã“ã‚Œã‚‰ã«ã¤ã„ã¦æ•°å­¦çš„ãªå®šç¾©ã¨ã¨ã‚‚ã«ã‚ã‹ã‚Šã‚„ã™ã„è¨€èªåŒ–ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã“ã¨ã‚’ç›®çš„ã«ã—ã¦ã„ã¾ã™\n\n â–¶Â  è¨˜è¿°çµ±è¨ˆã¨çµ±è¨ˆçš„æ¨æ¸¬\n\n è¨˜è¿°çµ±è¨ˆ(descriptive statistics)\n\nèª¿æŸ»ã‚„å®Ÿé¨“ã§å¾—ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’æ•´ç†ã—ã¦ï¼Œãã®è§£é‡ˆã‚’åŠ©ã‘ã‚‹ã‚ˆã†ãªçµ±è¨ˆçš„åˆ†æã®ã“ã¨\n\nçµ±è¨ˆçš„æ¨æ¸¬(statistical inference)\n\nç¢ºç‡çš„ãªå¤‰å‹•ã‚’å¤šãå«ã‚€ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ï¼Œãã®DGP(= Data generating process)ã«ä½•ã‹ã—ã‚‰ã®ä»®å®šã‚’æƒ³å®šã—ï¼Œãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã®æ¨å®šã‚„æ¤œå®šã‚’è¡Œã†åˆ†æã®ã“ã¨\n\n\n\nã€Œä¼ã›ã‚‰ã‚ŒãŸãƒˆãƒ©ãƒ³ãƒ—ã‚«ãƒ¼ãƒ‰ã‚’é€è¦–ã™ã‚‹ã“ã¨ã§ã‚¹ãƒ¼ãƒˆã‚’å½“ã¦ã‚‹ã“ã¨ãŒã§ãã‚‹ï¼ã€ã¨ã„ã†äººãŒã„ãŸã¨ã—ã¾ã™ï¼ ã“ã®èƒ½åŠ›ã‚’è©¦ã—ã¦ã¿ãŸã¨ã“ã‚ï¼•ï¼’æšã®ã‚«ãƒ¼ãƒ‰ã®å†…ï¼Œï¼”ï¼æšã‚’å½“ã¦ã‚‹ã“ã¨ãŒã§ããŸã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ãŒå¾—ã‚‰ã‚Œã¾ã—ãŸï¼ ã“ã®ï¼Œ40æšå½“ã¦ã‚‹ã“ã¨ãŒã§ããŸã¨ã„ã†ãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦ç¢ºç‡è«–çš„æ„å‘³ã‚’åˆ¤æ–­ã‚’ã™ã‚‹ã¨ã„ã†ã®ãŒçµ±è¨ˆçš„æ¨æ¸¬ã§ã™ï¼\nã“ã®ã‚ˆã†ã«çµ±è¨ˆçš„æ¨æ¸¬ã¨ã¯ç¢ºç‡ãƒ¢ãƒ‡ãƒ«ã‚’æƒ³å®šã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’è§£é‡ˆ/åˆ¤æ–­ã™ã‚‹åˆ†æãªã®ã§ï¼Œç¢ºç‡è«–ã‚’ä¸­å¿ƒã¨ã™ã‚‹æ•°å­¦çš„è¡¨ç¾ã‚’ç”¨ã„ãŸãƒ¢ãƒ‡ãƒ«ã®å®šå¼åŒ– ï¼ˆ=ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¹ã®æ³•å‰‡ã‚’æ‰±ã†æ•°å­¦ç†è«–ï¼‰ãŒå¿…è¦ã¨ãªã‚Šã¾ã™ï¼åŠ ãˆã¦ï¼Œ\n\næƒ³å®šã—ãŸç¢ºç‡ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãã†ã‹ï¼Ÿ\nä¸ãˆã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¨çŸ›ç›¾ã—ãªã„ã‹ï¼Ÿ\nä¹–é›¢ãŒã‚ã‚‹å ´åˆï¼Œæƒ³å®šã—ãŸãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å°ã‹ã‚Œã‚‹çµè«–ã¯ã©ã®ç¨‹åº¦å¦¥å½“ã™ã‚‹ã¨è¨€ãˆã‚‹ã®ã ã‚ã†ã‹ï¼Ÿ\n\nã¨ã„ã†åˆ†æä¸Šã®åˆ¤æ–­ã‚‚å¿…è¦ã¨ãªã‚Šã¾ã™ï¼ãã®ãŸã‚ï¼Œçµ±è¨ˆçš„æ¨æ¸¬ã¯ãƒ‡ãƒ¼ã‚¿åˆ†æåˆå¿ƒè€…ã«ã¨ã£ã¦ã¯æ•·å±…ãŒé«˜ã„æ‰‹æ³•ã¨ãªã‚Šã¾ã™ãŒï¼Œ ä¸€æ—¦ãƒ¢ãƒ‡ãƒ«åŒ–ã‚„ä»®å®šã®å¦¥å½“æ€§ã«ã¤ã„ã¦ã®èª¬æ˜ãŒã†ã¾ãè¡Œãã¨ï¼Œæ‰‹å…ƒã«å®Ÿéš›ã«ã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã®èƒŒå¾Œã«ã‚ã‚‹ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«åŸºã¥ã„ã¦æ¨æ¸¬ãŒè¡Œãˆã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™ï¼ ä¾‹ãˆã°ï¼Œå®Ÿéš›ã«è¦³æ¸¬ã§ããªã„Potential Outcomesã®åˆ†å¸ƒã«ã¤ã„ã¦ã®æ¨å®šã‚„å°†æ¥ã®äºˆæ¸¬ãªã©ãŒã‚ã‚Šã¾ã™ï¼\nã“ã®ã‚ˆã†ã«çµ±è¨ˆçš„æ¨æ¸¬ã¨ã¯ï¼Œä½¿ã„ã“ãªã™ã®ã¯å¤§å¤‰ã§ã™ãŒï¼Œä½¿ãˆã‚‹ã‚ˆã†ã«ãªã‚‹ã¨ã¨ã¦ã‚‚å¼·åŠ›ãªãƒ„ãƒ¼ãƒ«ã§ã™ï¼ã“ã®ãƒãƒ¼ãƒˆã‚’é€šã˜ã¦ï¼Œçµ±è¨ˆçš„æ¨æ¸¬ã®åŸºç¤ã‚„ã„ãã¤ã‹ã®å¿œç”¨åˆ†é‡ã®åˆ†æã‚’è¦‹ãªãŒã‚‰ãƒã‚¹ã‚¿ãƒ¼ã—ãŸã„ãªã¨æ€ã£ã¦ã„ã¾ã™ï¼\n â–¶Â  æ¸¬å®šã®å°ºåº¦\n\n\n\n\n\n\n\n\nç¨®é¡\nmeasurement\nèª¬æ˜\n\n\n\n\nã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿\nåç¾©å°ºåº¦(nominal scale)\nã‚ã‚‹å¯¾è±¡ãŒä»–ã¨åŒä¸€ã‹ï¼Œç•°ãªã‚‹ã‹ã‚’è¡¨ã™æ¸¬å®šä¾‹: æ€§åˆ¥, è¡€æ¶²å‹\n\n\nã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿\né †åºå°ºåº¦(ordinal scale)\nå¤§å°/å„ªåŠ£é–¢ä¿‚ã‚’è¡¨ã™æ¸¬å®šä¾‹: ï¼”æ®µéšè©•ä¾¡ã®å¥åº·çŠ¶æ…‹\n\n\né‡çš„ãƒ‡ãƒ¼ã‚¿\né–“éš”å°ºåº¦(interval scale)\n0ãŒç›¸å¯¾çš„ãªæ„å‘³ã‚’ã‚‚ã¤æŒ‡æ¨™ä¾‹: æ°—æ¸©ï¼ŒçŸ¥èƒ½æŒ‡æ•°ï¼Œæ¨™é«˜\n\n\né‡çš„ãƒ‡ãƒ¼ã‚¿\næ¯”ä¾‹å°ºåº¦(ratio scale)\n0ãŒçµ¶å¯¾çš„ãªæ„å‘³ã‚’æŒã¤æŒ‡æ¨™ä¾‹: èº«é•·ï¼Œé‡‘é¡ï¼Œæ™‚é–“ã®çµŒéï¼Œçµ¶å¯¾æ¸©åº¦\n\n\n\n\n\n\n\nç«¹æ‘å½°é€š (2020), ç¾ä»£æ•°ç†çµ±è¨ˆå­¦, å­¦è¡“å›³æ›¸å‡ºç‰ˆç¤¾.",
    "crumbs": [
      "çµ±è¨ˆå­¦å…¥é–€"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/chapter_header.html",
    "href": "posts/statistical_hypothesis_test_201/chapter_header.html",
    "title": "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ",
    "section": "",
    "text": "References",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/chapter_header.html#references",
    "href": "posts/statistical_hypothesis_test_201/chapter_header.html#references",
    "title": "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ",
    "section": "",
    "text": "æŸ³å·å ¯ (2018), På€¤: ãã®æ­£ã—ã„ç†è§£ã¨é©ç”¨, è¿‘ä»£ç§‘å­¦ç¤¾.\n\n\næ°¸ç”°é– (2003), ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã®æ±ºã‚æ–¹, æœå€‰æ›¸åº—.",
    "crumbs": [
      "çµ±è¨ˆçš„ä»®èª¬æ¤œå®šã®å®Ÿè·µ"
    ]
  },
  {
    "objectID": "posts/robust_statistics/chapter_header.html",
    "href": "posts/robust_statistics/chapter_header.html",
    "title": "Data Analysis and Outliers",
    "section": "",
    "text": "â–¶Â  Robust Statistics ã®ã‚¹ã‚³ãƒ¼ãƒ—\n\nè—¤æ¾¤æ´‹å¾³ (2017) ã‚’ãƒ™ãƒ¼ã‚¹ã«ï¼Œå¤–ã‚Œå€¤ã«å¯¾ã™ã‚‹åˆ†æä¸Šã®å¯¾å‡¦æ–¹æ³•ã«ã¤ã„ã¦å‹‰å¼·ã™ã‚‹\n\n â–¶Â  ãƒ­ãƒã‚¹ãƒˆæ¨å®šã¨ãƒ­ãƒã‚¹ãƒˆæ¤œå®š\n\nDef: ãƒ­ãƒã‚¹ãƒˆæ¨å®šã¨ãƒ­ãƒã‚¹ãƒˆæ¤œå®š \n\nãƒ­ãƒã‚¹ãƒˆæ¨å®š: å¤–ã‚Œå€¤ã«é ‘å¥ãªæ¨å®š(estimation)\nãƒ­ãƒã‚¹ãƒˆæ¤œå®š: å¤–ã‚Œå€¤ã®æ··å…¥ã«é ‘å¥ãªæ¤œå®š\n\n\n\n\n\n\nè—¤æ¾¤æ´‹å¾³ (2017), ãƒ­ãƒã‚¹ãƒˆçµ±è¨ˆ : å¤–ã‚Œå€¤ã¸ã®å¯¾å‡¦ã®ä»•æ–¹ï¼ˆISMã‚·ãƒªãƒ¼ã‚º : é€²åŒ–ã™ã‚‹çµ±è¨ˆæ•°ç† / çµ±è¨ˆæ•°ç†ç ”ç©¶æ‰€ç·¨, 6, è¿‘ä»£ç§‘å­¦ç¤¾.",
    "crumbs": [
      "Data Analysis and Outliers"
    ]
  },
  {
    "objectID": "posts/econometrics101/chapter_header.html",
    "href": "posts/econometrics101/chapter_header.html",
    "title": "Econometrics Topics",
    "section": "",
    "text": "Econometrics Topics ã®ã‚¹ã‚³ãƒ¼ãƒ—\n\n\n\n\n\nEconometric Analysisã®åŸºæœ¬çš„ãªè€ƒãˆ\n â–¶Â  ceteris paribus\n\nceteris paribusã¨ã¯ã€Œholding all other relevant factors fixedã€ã‚’æ„å‘³ã™ã‚‹æ¦‚å¿µ\n\nã¨ã‚ã‚‹ç¢ºç‡å¤‰æ•° \\(X\\) ã®å¤‰åŒ–ãŒåˆ¥ã®ç¢ºç‡å¤‰æ•° \\(Y\\) ã®å¤‰åŒ–ã‚’å¼•ãèµ·ã“ã™ï¼ˆcauseï¼‰ã¨ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä¸»å¼µã™ã‚‹ãŸã‚ã«ã¯ï¼Œå˜ã«åŒæ™‚åˆ†å¸ƒï¼ˆç›¸é–¢é–¢ä¿‚ï¼‰ã‚’ç¢ºèªã™ã‚‹ã ã‘ã§ã¯ä¸ååˆ†ã§ï¼Œä»–ã®å¤‰æ•°ã‚’å›ºå®šã—ãŸä¸Š(ceteris paribus)ã§ï¼Œ \\(X\\) ã®å¤‰åŒ–ãŒ \\(Y\\) ã®å¤‰åŒ–ã‚’ä¼´ã†ã“ã¨ã‚’ç¤ºã™å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼\n â–¶Â  Asymptotics\n\nfinite sample propertyã¨å¯¾ã«ãªã‚‹æ¦‚å¿µã§ï¼Œ\\(N\\to\\infty\\) ã«é£›ã°ã—ãŸæ¥µé™åˆ†å¸ƒã«ãŠã‘ã‚‹çµ±è¨ˆé‡ã®æ€§è³ªã®ã“ã¨\ncross section dataã®å ´åˆã¯, unit of observations ã‚’ \\(N\\to\\infty\\)\npanel data analysisã®å ´åˆã¯ï¼Œtime indexã‚’å›ºå®šã—ãŸä¸Šã§ unit of entitie sã‚’ \\(N\\to\\infty\\)\n\n â–¶Â  èª¬æ˜å¤‰æ•°(regressor)ãŒç¢ºç‡çš„ã§ã‚ã‚‹\n\nèª¬æ˜å¤‰æ•°ãŒéç¢ºç‡çš„ã§ã‚ã‚‹ä¾‹ã¨ã—ã¦ï¼Œå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®ã‚ˆã†ã«èª¬æ˜å¤‰æ•° \\(\\mathbf x_i\\) ã®æ°´æº–ã«ã¤ã„ã¦åˆ†æè€…ãŒäº‹å‰ã«æ±ºå®šã§ãã‚‹å ´åˆãŒã‚ã‚‹\n\nã“ã®å ´åˆï¼Œerror termã¨èª¬æ˜å¤‰æ•°ã®ç›¸é–¢ï¼ˆå†…ç”Ÿæ€§å•é¡Œï¼‰ã¯æ’é™¤ã§ãã‚‹\n\nè¦³æ¸¬ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ï¼Œå®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®ã‚ˆã†ã«èª¬æ˜å¤‰æ•° \\(\\mathbf x_i\\) ã®æ°´æº–ã«ã¤ã„ã¦ã¯æ±ºå®šã§ããªã„ãŸã‚ï¼Œã€Œéç¢ºç‡çš„ã€ã¨ã„ã†ä»®å®šã¯é€šå¸¸å½“ã¦ã¯ã¾ã‚‰ãªã„\n\nèª¬æ˜å¤‰æ•°ãŒç¢ºç‡çš„ã§ã‚ã‚‹å ´åˆï¼Œéç¢ºç‡çš„ã®ã‚‚ã¨ã§ã¯ä¸€è‡´æ€§ã‚’æº€ãŸã™æ¨å®šé‡(ä¾‹: GLS)ãŒä¸€è‡´æ€§ã‚’æº€ãŸã•ãªããªã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚Šã¾ã™ï¼",
    "crumbs": [
      "Econometrics Topics"
    ]
  }
]