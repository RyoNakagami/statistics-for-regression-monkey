[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics for Regression Monkeys",
    "section": "",
    "text": "Welcome\nこのQuarto Bookは以下のシリーズと連動して運用されています:",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Statistics for Regression Monkeys",
    "section": "References",
    "text": "References\n\n\n柳川堯 (2018), P値:\nその正しい理解と適用, 近代科学社.\n\n\n永田靖 (2003), サンプルサイズの決め方,\n朝倉書店.\n\n\n竹村彰通 (2020), 現代数理統計学,\n学術図書出版社.\n\n\n藤澤洋徳 (2017), ロバスト統計\n: 外れ値への対処の仕方（ISMシリーズ : 進化する統計数理 /\n統計数理研究所編, 6, 近代科学社.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html",
    "href": "posts/statistics101/averages.html",
    "title": "1  代表値",
    "section": "",
    "text": "平均\n▶  標本平均\nデータ \\(X = \\{x_1, \\cdots, x_n\\}\\) が与えられとき，標本平均（sample mean） \\(\\overline{x}\\) は次になります：\n\\[\n\\overline{x} = \\frac{x_1 + \\cdots + x_n}{n}\n\\]\n標本平均は分布の代表値として最も使用されるものだが，外れ値に対して弱い性質がある．\nimport numpy as np\n\nX_0 = np.array([5.6, 5.7, 5.4, 5.5, 5.8, 5.2, 5.3, 5.6, 5.4, 55.5])\nX_1 = np.array([5.6, 5.7, 5.4, 5.5, 5.8, 5.2, 5.3, 5.6, 5.4])\n\nprint(\n    \"\"\"X_0: sample mean = {}, median = {}\\nX_1: sample mean = {}, median = {}\n      \"\"\".format(\n        np.mean(X_0), np.median(X_0), np.mean(X_1), np.median(X_1)\n    )\n)\n\nX_0: sample mean = 10.5, median = 5.55\nX_1: sample mean = 5.5, median = 5.5\n上記の例のように，medianは外れ値の混入があってもその影響は軽微ですが，標本平均は大きく変わっており外れ値に対して弱いことがわかる．\n▶  刈り込み平均\n外れ値の影響を弱めて標本平均を推定する方法として，刈り込み平均(trimmed mean)があります． 上側 \\(100\\alpha \\%\\) と下側 \\(100\\alpha \\%\\) を使わないで推定する方法で，\\(x_{[i]}\\) を順序統計値として\n\\[\n\\hat\\mu_\\alpha = \\frac{1}{n-2m} \\sum_{i=m+1}^{n-m}x_{[i]}, \\  \\ m = \\lfloor n\\alpha \\rfloor\n\\]\nで推定する方法を刈り込み平均という．利用にあたって，外れ地の割合を事前に想定する必要がありますが， 少々適当に推定しても妥当な推定になりやすい特徴があります．\n\\(\\alpha = 0.1\\) としてPythonで計算してみると以下，\nfrom scipy import stats\nself_trimmed_mean = np.mean([5.7, 5.4, 5.5, 5.8, 5.4, 5.3, 5.6, 5.6])\ntrimmed_mean = stats.trim_mean(X_0, 0.1)\nprint(self_trimmed_mean, trimmed_mean)\n\n5.5375 5.5375\nTrimmed meanはARE(Asymptotic relative efficiency, 漸近相対効率)という観点からも大抵の裾の重さに対して（重すぎるのは厳しいですが．．．）高いパフォーマンスがあることが知られています．\n▶  幾何平均\n\\(x_i &gt; 0\\) となるようなデータについて，幾何平均は以下のように計算されます：\n\\[\n\\overline{x}_G = \\bigg(\\prod_{i=1}^n x_i \\bigg)^{\\frac{1}{n}}\n\\]\n2000年から2005年までのXこくのでの物価上昇率が2%, 5%, 2%, 5%, 10%とあるとき，年平均上昇率は算術平均ではなく幾何平均で計算すべきで\n\\[\n(1.02 \\times 1.05 \\times 1.02 \\times 1.05 \\times 1.1)^{1/5} \\approx 1.0476\n\\]\nすなわち年平均約4.8%の増加と報告すべきとなります．なお，相加相乗平均より，幾何平均は算術平均より小さい値になることがわかります．もし大きい値を出してしまっていたら計算ミスを疑うべきです．\n幾何平均について対数をとると以下のように算術平均で表すことができます\n\\[\n\\log(\\overline{x}_G) = \\frac{1}{n}\\sum \\log(x_i)\n\\]\nここから，幾何平均を計算するときは一旦log transformationを実行し，算術平均を計算し，その後 \\(\\exp(\\cdot)\\) で元のスケールに戻すという形でよく計算されます．\nクラス分類の評価指標との関係では，sensitivity(感応度)とspecificity(特異度)の幾何平均を用いたG-Mean(geometric mean)という指標があります．\n\\[\n\\begin{align*}\n\\operatorname{G-mean} &= \\sqrt{\\operatorname{sensitivity} \\times \\operatorname{specificity}}\\\\\n                      &= \\sqrt{\\operatorname{recall} \\times \\operatorname{True Negative Rate}}\n\\end{align*}\n\\]\n▶  調和平均\n\\(x_i &gt; 0\\) となるようなデータについて，調和平均(harmonic mean)は以下のように計算されます：\n\\[\n\\frac{1}{\\overline{x}_H} = \\frac{1}{n}\\sum\\frac{1}{x_i}\n\\]\nとある車が距離 \\(\\alpha\\) の区間Aでは25km/h, 距離 \\(\\beta\\) の区間Bでは15km/hで走っていたとします．このとき，この車の平均時速は\n\\[\n\\frac{1}{\\text{平均時速}} = \\frac{\\alpha}{\\alpha + \\beta} \\frac{1}{25} + \\frac{\\beta}{\\alpha + \\beta} \\frac{1}{15}\n\\]\n\\(\\alpha = \\beta\\) のときは\n\\[\n\\frac{1}{\\text{平均時速}}  = \\frac{1}{2} \\bigg(\\frac{1}{25} + \\frac{1}{15}\\bigg)\n\\]\n平均を計算するにあたって，値が同じスケールの単位である必要であるため，上の平均時速の例では調和平均を利用することが 好ましいとされます．なお区間Aをx時間で25km/h, 区間Bをy時間で15km/hという場合はウェイトが時間単位で表されているので\n\\[\n\\text{平均時速} = \\frac{x}{x + y} \\times 25 + \\frac{y}{x + y} \\times 15\n\\]\nモデルの評価指標の１つにprecisionとrecallを用いたF1-scoreがありますが，precisionとrecallも分子はそれぞれTrue Positiveで共通していますが，分母がそれぞれ \\(\\operatorname{TP} + \\operatorname{FP}, \\operatorname{TP} + \\operatorname{FN}\\) と異なっているので，調和平均を用いて以下のように計算します：\n\\[\n\\begin{align*}\n\\operatorname{F1-score} &= \\frac{1}{\\frac{1}{2} \\left(\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}\\right)}\\\\\n&= \\frac{2}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}}\n\\end{align*}\n\\]\nなお，これはウェイトが等しい場合を意味しており，weighted harmonic meanへ拡張する場合は以下のように \\(\\operatorname{F_\\beta-score}\\) を用いて計算します\n\\[\n\\operatorname{F_\\beta-score} = \\frac{1 + \\beta^2}{\\frac{1}{\\text{precision}} + \\frac{\\beta^2}{\\text{recall}}}\n\\]\nウェイトが \\(\\frac{1}{1 + \\beta^2}, \\frac{\\beta^2}{1 + \\beta^2}\\) の形を取っているのは一見不自然に見えますが，その考察で面白いのがvan Rijs-bergen’s E (effectiveness) functionに基づいた説明です．",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>代表値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#平均",
    "href": "posts/statistics101/averages.html#平均",
    "title": "1  代表値",
    "section": "",
    "text": "Theorem 1.1 \n定義域が \\(\\mathbb R_+\\) の確率変数 \\(X\\) を考える（つまり \\(X &gt; 0\\)）. このとき,\n\n\\(H_x\\): 調和平均\n\\(G_x\\): 幾何平均\n\\(\\overline{X}\\): 標本平均\n\nとして以下が常に成り立つ\n\\[\nH_x \\leq G_x \\leq \\overline{X}\n\\]\n\n\n\n\n\n\n\n\nProof: Jensen’s inequalityを用いた証明\n\n\n\n\n\nJensen’s inequalityより 関数 \\(g\\) を凸関数(convex function)とすると\n\\[\n\\frac{1}{n}\\sum_{i=1}^ng(x_i)\\geq g(\\overline{x})\n\\]\nという不等式が成り立つ.\n ▶  \\(\\overline{X} \\geq G_x\\) の証明\n\\(f(x) = -\\log(x)\\) とすると \\(f\\) は単調減少の凸関数であるので\n\\[\n\\begin{align*}\n-\\log(\\overline{x}) &\\leq -\\frac{1}{n}\\sum_{i=1}^n\\log(x_i)\\\\\n                    &= -\\log(\\prod_{i=1}^n x_i^{1/n})\\\\\n                    &= -\\log(G_x)\n\\end{align*}\n\\]\nつまり，\\(\\log(\\overline{x})\\geq \\log(G_x) \\Rightarrow \\overline{X} \\geq G_x\\)\n ▶  \\(G_x \\geq H_x\\) の証明\n\\(1/x_i = y_i\\) と変換すると\n\\[\n\\begin{align*}\nG_x &= \\left(\\prod \\frac{1}{y_i}\\right)^{1/n}\\\\\nH_x &= \\frac{1}{\\overline y}\n\\end{align*}\n\\]\nそれぞれについて \\(f(x) = \\log(x)\\) とすると\n\\[\n\\begin{align*}\n\\log(G_x) &= \\frac{1}{n}\\sum_{i=1}^n(-\\log(y_i))\\\\\n\\log(H_x) &= -\\log(\\overline y)\n\\end{align*}\n\\]\n\\(-\\log(\\cdot)\\) は凸関数であるので\n\\(\\log(G_x) \\geq \\log(H_x) \\Rightarrow G_x \\geq H_x\\) を得る．",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>代表値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#中央値",
    "href": "posts/statistics101/averages.html#中央値",
    "title": "1  代表値",
    "section": "中央値",
    "text": "中央値\n\nDef: median \nデータ \\(x_1, \\cdots, x_n\\) を小さい順に並び替えた順序統計量\n\\[\nx_{[1]} &lt; \\cdots &lt; x_{[n]}\n\\]\nについて，真ん中の値を中央値という．つまり，\n\\[\n\\operatorname{Med}(X) = \\left\\{\\begin{array}{cl}\nx_{[k]} & \\text{where } n = 2k-1\\\\\n\\displaystyle \\frac{x_{[k]} + x_{[k+1]}}{2} & \\text{where } n = 2k\n\\end{array}\\right.\n\\]\n\n ▶  Hodges-Lehmann推定量\n標本の中からペアを選び，そのヘアの平均の中央値を用いて中央値を推定するのがホッジスレーマン推定値です．\n\\[\n\\hat\\mu_{HL} = \\operatorname{Med}\\bigg(\\bigg\\{\\frac{x_i + x_j}{2}\\bigg\\}_{1\\leq i \\leq j \\le n}\\bigg)\n\\]\ncomputation上少し重たいですが計算例として以下，\n\nimport itertools\n\ndef HL_mean(x: list[tuple]):\n    return np.median([np.mean(t) for t in itertools.combinations(x, 2)])\n\nX_0 = np.array([5.6, 5.7, 5.4, 5.5, 5.8, 5.2, 5.3, 5.6, 5.4, 55.5])\nprint(HL_mean(X_0))\n\n5.55\n\n\n\nTheorem: Asymptotic distribution of sample quantile-p \n\\(y_1, \\cdots, y_n\\) を density function \\(f\\) 及びquantile function \\(Q^{(p)}\\) を持つ分布からのi.i.dとします．このとき, sample quantile \\(\\hat Q^{(p)}\\) は\n\\[\n\\sqrt{n}(\\hat Q^{(p)} - Q^{(p)}) \\rightarrow_d \\mathbb N\\left(0,\\frac{p(1-p)}{f(Q^{(p)})^2}\\right)\n\\]\n\nここでは，連続変数分布を想定して解説します．連続なdensity function \\(f_x\\) を持つ連続確率分布 \\(F\\) という分布について\n\\[\nX = \\{x_1, \\cdots, x_n\\}  \\overset{\\mathrm{iid}}{\\sim} F\n\\]\nと確率変数列が与えられたとします．この確率変数に対して\n\\[\nZ_i\\equiv 1\\{x_i \\leq x\\}\n\\]\nという変数を考えます．この \\(Z_i\\) は Bernoulli分布に従うと考えられるので，\\(F\\) のCDFを \\(F_X\\) とおくと\n\\[\n\\begin{align*}\n\\mathbb E(Z_i) &=  \\mathbb E\\left(I\\{X_i\\le x\\}\\right) = P(X_i\\le x)=F_X(x)\\\\\n\\operatorname{Var}(Z_i) &= F_X(x)[1-F_X(x)]\n\\end{align*}\n\\]\nここで，\\(Z_i\\) のsample meanを以下のように定義する．\n\\[\nY_n(x) =  \\frac 1n\\sum_{i=1}^nZ_i\n\\]\nこのように定義した \\(Y_n(x)\\) はいわゆる経験分布関数 \\(F_n(x)\\) であるとみなせます．また，定義より\n\\[\n\\begin{align*}\n&E[F_n(x)] = F_X(x)\\\\\n&\\operatorname{Var}(F_n(x)) = (1/n)F_X(x)[1-F_X(x)]\\\\\n&\\sqrt n\\Big(F_n(x) - F_X(x)\\Big) \\rightarrow_d \\mathbb N\\left(0,F_X(x)[1-F_X(x)]\\right) \\because{\\text{CLT}}\n\\end{align*}\n\\]\nここでCDFの逆関数 \\(F^{-1}_X\\) とする(monotonicityより自明)と delta methodを用いると\n\\[\n\\begin{align*}\n&\\frac {d}{dt}F^{-1}_X(t) = \\frac 1{f_x\\left(F^{-1}_X(t)\\right)}\\\\\n&\\sqrt n\\Big(F^{-1}_X(F_n(x)) - F^{-1}_X(F_X(x))\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {F_X(x)[1-F_X(x)]}{\\left[f_x\\left(F^{-1}_X(F_X(x))\\right)\\right]^2} \\right)\n\\end{align*}\n\\]\nつまり，\n\\[\n\\sqrt n\\Big(F^{-1}_X(F_n(x)) - x\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {F_X(x)[1-F_X(x)]}{\\left[f_x(x)\\right]^2} \\right)\n\\]\nここで \\(x = m\\)(population median)と設定すると\n\\[\n\\sqrt n\\Big(F^{-1}_X(F_n(m)) - m\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {1}{\\left[2f_x(m)\\right]^2} \\right)\n\\]\nまた，\n\\[\nF^{-1}_X(\\hat F_n(m)) = \\inf\\{x : F_X(x) \\geq \\hat F_n(m)\\} = \\inf\\{x : F_X(x) \\geq \\frac 1n \\sum_{i=1}^n I\\{X_i\\leq m\\}\\}\n\\]\nより, 不等式のRHSは 1/2 に収束するので \\(F^{-1}_X(\\hat F_n(m))\\) はsample mean \\(\\hat m\\) に収束することがわかる．従って，\n\\[\n\\sqrt n\\Big(\\hat m - m\\Big) \\rightarrow_d \\mathbb N\\left(0,\\frac {1}{\\left[2f_x(m)\\right]^2} \\right)\n\\]\n\n\nTheorem 1.2 標本平均とMedianの距離 \n独立に同一の分布に従う確率変数列 \\(\\{X_i\\}_{i=1}^n\\) を考える．この標本平均を \\(\\overline{X}\\), 不偏分散を \\(S^2\\), メディアン \\(X_{\\operatorname{med}}\\) とすると\n\\[\n\\vert \\overline{X} - X_{\\operatorname{med}}\\vert &lt; S\n\\]\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(X_{\\operatorname{med}}\\) はL1ノルムの和を最小にするような値であるので\n\\[\n\\begin{align*}\n\\vert \\overline{X} - X_{\\operatorname{med}}\\vert\n    &= \\bigg\\vert \\frac{1}{n}\\sum_{i=1}^n(X_i - X_{\\operatorname{med}})\\bigg\\vert\\\\\n    &\\leq \\frac{1}{n}\\sum_{i=1}^n\\bigg\\vert X_i - X_{\\operatorname{med}}\\bigg\\vert\\\\\n    &\\leq\\frac{1}{n}\\sum_{i=1}^n\\bigg\\vert X_i - \\overline{X}\\bigg\\vert\\\\\n    &\\leq\\sqrt{\\frac{1}{n}\\sum_{i=1}^n( X_i - \\overline{X})^2}\\\\\n    &=\\sqrt{\\frac{n-1}{n}}S\\\\\n    &\\leq S\n\\end{align*}\n\\]",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>代表値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#分散と標準偏差",
    "href": "posts/statistics101/averages.html#分散と標準偏差",
    "title": "1  代表値",
    "section": "分散と標準偏差",
    "text": "分散と標準偏差\n\nDef: Variance \nmean \\(\\mu\\) をもつ確率変数 \\(X\\) の分散は\n\\[\n\\begin{align*}\n\\operatorname{Var}(X) &= \\mathbb E[(X - \\mu)^2]\\\\\n                      &= \\mathbb E[X^2] - \\mathbb E[X]^2\n\\end{align*}\n\\]\n標準偏差(standard deviation)は分散のsquare rootで定義される．\n\n上の定義より標準偏差について以下のことがわかります：\n\n\\(X\\) と同じ単位で表される\n\\(X - \\mathbb E[X]\\) の L2ノルムと解釈できる\npopulation meanからどれだけ分布がバラついているか(dispersion)を示す指標の一つ\n\n\n\nTheorem 1.3 \n確率変数 \\(X\\sim D(\\mu, \\sigma^2)\\) とする．このとき\n\\[\n\\begin{align*}\n\\mathbb E[\\vert X - \\mu\\vert] \\leq \\sigma\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\nProof: Jensen’s Inequality\n\n\n\n\n\n\\(g(x) = \\sqrt{x}\\) という関数はconcaveなので，Jensen’s Inequalityより\n\\[\n\\begin{align*}\n\\mathbb E[\\vert X - \\mu \\vert]\n    &= \\mathbb E[\\sqrt{( X - \\mu)^2}]\\\\\n    &\\leq \\sqrt{\\mathbb E[( X - \\mu)^2]}\\\\\n    &= \\sigma\n\\end{align*}\n\\]\n\n\n\n\n変動係数\n確率変数のバラツキを表す指標として範囲(Range), 四分位範囲（IQR）, 分散がありますが，分布の中心の位置が著しく異なるような場合 には，これらを用いて分布の散らばり具合を比較することは難しいです．このような場合に，変動係数(Coefficient of variation) という単位のない統計量を用いたりします．\n\nDef: Coefficient of variation \n比例尺度にもとづく測定が行われ，その測定結果をnon-negative 確率変数 \\(X_i &gt;0\\) で表すとする．\\(\\{X_i\\}_{i=1}^n\\) の標本平均を \\(\\overline{X}\\), 標本標準偏差を \\(S\\) としたとき，変動係数は以下のように計算される\n\\[\n\\operatorname{C_V} = \\frac{S}{\\overline{X}}\n\\]\n\n上記の定義より以下のことがわかります\n\n変動係数は，実際のゼロ点を持つ測定値（i.e., 比率尺度）に対してのみ用いることができます\n変動係数の計算対象となる測定は，non-negativeである必要がある\nサイズ \\(N\\) のfinite sampleにおける \\(\\operatorname{C_V}\\) のレンジは \\(\\operatorname{CV}\\in[0, \\sqrt{N-1}]\\) である\n\n\nExample 1.1 東京 日平均気温の月平均値（℃） \n国土交通省気象庁より以下のように東京都の気象データを取得します．\n\n\nCode\nimport polars as pl\nimport plotly.express as px\n\ndata = {\n    \"Year\": [2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023],\n    \"Jan\": [5.8, 6.1, 5.8, 4.7, 5.6, 7.1, 5.4, 4.9, 5.7],\n    \"Feb\": [5.7, 7.2, 6.9, 5.4, 7.2, 8.3, 8.5, 5.2, 7.3],\n    \"Mar\": [10.3, 10.1, 8.5, 11.5, 10.6, 10.7, 12.8, 10.9, 12.9],\n    \"Apr\": [14.5, 15.4, 14.7, 17.0, 13.6, 12.8, 15.1, 15.3, 16.3],\n    \"May\": [21.1, 20.2, 20.0, 19.8, 20.0, 19.5, 19.6, 18.8, 19.0],\n    \"Jun\": [22.1, 22.4, 22.0, 22.4, 21.8, 23.2, 22.7, 23.0, 23.2],\n    \"Jul\": [26.2, 25.4, 27.3, 28.3, 24.1, 24.3, 25.9, 27.4, 28.7],\n    \"Aug\": [26.7, 27.1, 26.4, 28.1, 28.4, 29.1, 27.4, 27.5, 29.2],\n    \"Sep\": [22.6, 24.4, 22.8, 22.9, 25.1, 24.2, 22.3, 24.4, 26.7],\n    \"Oct\": [18.4, 18.7, 16.8, 19.1, 19.4, 17.5, 18.2, 17.2, 18.9],\n    \"Nov\": [13.9, 11.4, 11.9, 14.0, 13.1, 14.0, 13.7, 14.5, 14.4],\n    \"Dec\": [9.3, 8.9, 6.6, 8.3, 8.5, 7.7, 7.9, 7.5, 9.4],\n}\n\ndf = pl.DataFrame(data)\ndf_unpivoted = df.unpivot(index=\"Year\", variable_name=\"Month\", value_name=\"Celsius\")\npx.line(df_unpivoted, x=\"Month\", y=\"Celsius\", color=\"Year\", title=\"東京都月別平均気温\")\n\n\n                                                \n\n\nここで，以下のようにFahrenheitに変換してみます．\n\n\nCode\ndf_unpivoted = df_unpivoted.with_columns(\n    (pl.col(\"Celsius\") * 9 / 5 + 32).alias(\"Fahrenheit\")\n)\ndf_unpivoted.head()\n\n\n\nshape: (5, 4)\n\n\n\nYear\nMonth\nCelsius\nFahrenheit\n\n\ni64\nstr\nf64\nf64\n\n\n\n\n2015\n\"Jan\"\n5.8\n42.44\n\n\n2016\n\"Jan\"\n6.1\n42.98\n\n\n2017\n\"Jan\"\n5.8\n42.44\n\n\n2018\n\"Jan\"\n4.7\n40.46\n\n\n2019\n\"Jan\"\n5.6\n42.08\n\n\n\n\n\n\nここで，Celsius, Fahrenheit両方のカラムについて変動係数を計算します．\n\n\nCode\ndef compute_cv(df, col: str) -&gt; float:\n    return df_unpivoted[col].std() / df_unpivoted[col].mean()\n\n\nprint(\n    \"\"\"Celsius CV: {:.2f}, Fahrenheit CV: {:.2f}\"\"\".format(\n        compute_cv(df_unpivoted, \"Celsius\"), compute_cv(df_unpivoted, \"Fahrenheit\")\n    ))\n\n\nCelsius CV: 0.45, Fahrenheit CV: 0.22\n\n\nこのように，Celsius, Fahrenheitともに同じ温度を単位の違う方法で表しているのにも関わらず変動係数は異なります．Celsius, Fahrenheitともに間隔尺度であること，及び変数変換の観点からもlocation/scale parameterを異なる値で調整しているので同じデータを扱っているにも関わらずCVが一致しないという現象が発生してしまいます．\n\n ▶  Bias Correction\nサイズ \\(N\\) のsampleベースで計算された変動係数はpopulation変動係数 \\(\\gamma_V\\) と比較して過小推定されているということが知られています．population変動係数のunbiased estimate \\(\\widehat{\\operatorname{C_V}}\\) は以下のように計算されます\n\\[\n\\widehat{\\operatorname{C_V}} = \\left(1 + \\frac{1}{4N}\\right)\\operatorname{C_V}\n\\]",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>代表値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/averages.html#references",
    "href": "posts/statistics101/averages.html#references",
    "title": "1  代表値",
    "section": "References",
    "text": "References\n\nYutaka Sasaki, The truth of the F-measure, 2007",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>代表値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/density_function.html",
    "href": "posts/statistics101/density_function.html",
    "title": "2  確率密度関数",
    "section": "",
    "text": "連続確率変数と確率密度関数\n\\(f\\) のnon-negativity性質は，累積分布関数はnon-decreasingであること，及び \\(F^\\prime(x) = f(x)\\) であることから分かる． また確率変数 \\(X\\) が確率密度関数 \\(f(x)\\) を持つとき，「\\(X\\) は \\(f(x)\\) に従う」とよく言われる．",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>確率密度関数</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/density_function.html#連続確率変数と確率密度関数",
    "href": "posts/statistics101/density_function.html#連続確率変数と確率密度関数",
    "title": "2  確率密度関数",
    "section": "",
    "text": "Def: 絶対連続型の確率変数 \n累積分布関数 \\(F\\) をもつ確率変数 \\(X\\) が次の条件を満たす確率密度関数 \\(f\\) を持つとき，絶対連続(absolutely continuous)という：\n\\[\n\\begin{gather}\nf(x) \\geq 0 \\quad \\forall x\\\\\nF(b) - F(a) = \\int^b_a f(x)\\mathrm{d}x \\quad \\text{where } a\\leq b\n\\end{gather}\n\\]\n\n\n\n\nTheorem 2.1 変数変換と確率密度関数 \n\\(f\\) を確率密度関数，\\(a &gt; 0\\) とし，\n\\[\ng(x) = af(ax)\n\\]\nと関数 \\(g\\) を定義すると\n\\[\n\\int^\\infty_{-\\infty} g(x)\\mathrm{d} x = 1\n\\]\nとなる\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(a &gt; 0, f\\geq 0\\) より \\(g\\geq 0\\) は自明．また，\\(ax = z\\) と変数変換すると\n\\[\n\\begin{align*}\n\\int^\\infty_{-\\infty} g(x)\\mathrm{d} x &= \\int^\\infty_{-\\infty} af(ax)\\mathrm{d} x \\\\\n                                       &= \\int^\\infty_{-\\infty} af(z) \\frac{\\mathrm{d} x}{\\mathrm{d} z}\\mathrm{d} z\\\\\n                                       &= \\int^\\infty_{-\\infty} af(z) \\frac{1}{a}\\mathrm{d} z = 1\n\\end{align*}\n\\]",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>確率密度関数</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html",
    "href": "posts/statistics101/expectation.html",
    "title": "3  期待値",
    "section": "",
    "text": "期待値の性質\n定義より確率密度関数で重みづけた平均が確率変数の期待値になると解釈することができます．meanは分布の位置を表すパラメーターとも解釈できるので location parameter（位置母数）と呼ぶこともあります．一方，標準偏差 \\(\\sigma\\) はscale parameter（尺度母数）といいます．",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>期待値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html#期待値の性質",
    "href": "posts/statistics101/expectation.html#期待値の性質",
    "title": "3  期待値",
    "section": "",
    "text": "Def: 連続確率変数の期待値 \n\\(f\\) を確率変数 \\(X\\) の確率密度関数とする．\\(\\int_{\\mathbb R} \\vert x\\vert f(x) \\mathrm{d}x &lt; \\infty\\) のとき，\\(X\\) の期待値は以下のように定義する:\n\\[\n\\mathbb E[X] = \\int_{\\mathbb R} x f(x) \\mathrm{d}x\n\\]\nまた，\\(X\\) の関数 \\(g(X)\\) の期待値は \\(\\int_{\\mathbb R} \\vert g(x)\\vert f(x) \\mathrm{d}x &lt; \\infty\\) ならば\n\\[\n\\mathbb E[g(X)] = \\int_{\\mathbb R} g(x) f(x) \\mathrm{d}x\n\\]\n\n\n\nExample 3.1 指数分布の期待値 \nrate parameter \\(\\lambda\\) の指数分布に従う確率変数 \\(X\\) を考えます．\n\\[\n\\begin{align*}\n\\mathbb E[X] &= \\int^\\infty_0 x \\lambda \\exp(-\\lambda x)\\mathrm{d}x\\\\\n             &= \\bigg[-x\\exp(-\\lambda x)\\bigg]^\\infty_0 + \\int^\\infty_0 \\exp(-\\lambda x)\\mathrm{d}x\\\\\n             &= \\int^\\infty_0 \\exp(-\\lambda x)\\mathrm{d}x\\\\\n             &= -\\frac{1}{\\lambda}\\bigg[\\exp(-\\lambda x)\\bigg]^\\infty_0\\\\\n             &= \\frac{1}{\\lambda}\n\\end{align*}\n\\]\n指数分布は電球の寿命などに応用される分布ですが，rate parameter \\(\\lambda\\) が小さいほど期待値（= 電球の寿命）が大きくなることが分かります．\n\n\nExample 3.2 期待値が定義できない離散分布 \n確率変数 \\(X\\) のsupportを加算集合 \\(\\{2, 2^2, 2^3, \\cdots\\}\\) とする．確率関数を\n\\[\n\\Pr(X = 2^i) = \\frac{1}{2^i} \\quad (i = 1, 2, \\cdots)\n\\]\nこのとき，\n\\[\n\\sum_{i=1}^\\infty \\Pr(X=2^i) = \\sum_{i=1}^\\infty\\frac{1}{2^i} = 1\n\\]\nと確率の公理を満たしていることが分かる．一方，\n\\[\n\\begin{align*}\n\\mathbb E[X]\n    &= \\sum_{i=1}^\\infty 2^i \\frac{1}{2^i}\\\\\n    &= \\sum_{i=1}^\\infty 1 = \\infty\n\\end{align*}\n\\]\n従って，確率変数 \\(X\\) の分布は，期待値が定義できない分布であることがわかる．\n\n\nExample 3.3 期待値が定義できない連続分布 \n確率密度関数 \\[\nf(x) = \\begin{cases}\n0 & x &lt; 1\\\\\n\\frac{1}{x^2} & x\\geq 1\n\\end{cases}\n\\]\nという確率変数 \\(X\\) を考える．\n\\[\n\\begin{align*}\n\\int_1^\\infty f(x) \\mathrm{d}x\n    &= \\left[\\frac{1}{x}\\right]^1_\\infty = 1\n\\end{align*}\n\\]\n一方，\n\\[\n\\begin{align*}\n\\mathbb E[X]\n    &= \\int_1^\\infty xf(x) \\mathrm{d}x\\\\\n    &= \\int_1^\\infty\\frac{1}{x}\\mathrm{d}x\\\\\n    &= \\left[\\log(x)\\right]_1^\\infty = \\infty\n\\end{align*}\n\\]\n従って，確率変数 \\(X\\) の分布は，期待値が定義できない分布であることがわかる．\n\n\n\nTheorem 3.1 Tail probabilities \n\\([0, b]\\) の定義域をもつ非負確率変数 \\(X\\) を考える．\\(F\\) を累積分布関数とするとき\n\\[\n\\mathbb E[X] = \\int_0^b (1 - F(x))\\mathrm{d}x\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\bigg[xF(x)\\bigg]^b_0 = \\int^b_0xf(x) \\mathrm{d}x + \\int^b_0F(x) \\mathrm{d}x\n\\]\nを用いると\n\\[\n\\begin{align*}\n\\mathbb E[X] &= b - \\int^b_0F(x) \\mathrm{d}x\\\\\n             &= \\int^b_0 1 \\mathrm{d}x - \\int^b_0F(x) \\mathrm{d}x\\\\\n             &= \\int_0^b (1 - F(x))\\mathrm{d}x\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.2 \n\\([0, \\infty)\\) の定義域をもつ非負確率変数 \\(X\\) を考える．\\(\\mathbb E[\\vert X^{p+1} \\vert] &lt;\\infty\\) が定義可能及び， \\(F\\) を累積分布関数とするとき\n\\[\n\\mathbb E[X^p] = \\int_0^\\infty px^{p-1} (1 - F(x))\\mathrm{d}x \\quad \\text{where } p &gt; 0\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\bigg[x^p(1 - F(x))\\bigg]^\\infty_0 = \\int^\\infty_0 p x^{p-1}(1 -F(x))\\mathrm{d}x - \\int^\\infty_0 x^{p}f(x)\\mathrm{d}x\n\\end{align*}\n\\]\n\\(\\text{RHS} = 0\\) であるので\n\\[\n\\mathbb E[X^p] = \\int_0^\\infty px^{p-1} (1 - F(x))\\mathrm{d}x\n\\]\n\n\n\n\nExample 3.4 \n同様の考えで定義域を \\(0,1,2,3,\\cdots\\) とする離散確率変数 \\(X\\) について\n\\[\n\\mathbb E[X] = \\sum_{k=0}^\\infty \\Pr(X &gt; k)\n\\]\nが成立します．\n\\[\n\\begin{align*}\n\\Pr(X &gt; k) &= \\Pr(X = k+1) + \\Pr(X = k+2) + \\cdots\\\\\n           &= \\sum_{l=k+1}^\\infty \\Pr(X=l)\n\\end{align*}\n\\]\n従って，\n\\[\n\\begin{align*}\n\\sum_{k=0}^\\infty \\Pr(X &gt; k) &= \\sum_{k=0}^\\infty \\sum_{l=k+1}^\\infty \\Pr(X=l)\\\\\n                             &= \\sum_{l=1}^\\infty\\sum_{k=0}^{l-1}\\Pr(X=l) \\quad\\because \\Pr(X=l) &gt; 0 \\\\\n                             &= \\sum_{l=1}^\\infty l\\Pr(X=l)\\\\\n                             &= \\sum_{l=0}^\\infty l\\Pr(X=l)\\\\\n                             &= \\mathbb E[X]\n\\end{align*}\n\\] \\[\\tag*{\\(\\blacksquare\\)}\\]\n\n\nExample 3.5 \n\\(0,1,2,3,\\cdots\\) とする離散確率変数 \\(X\\) について\n\\[\n\\mathbb E[X^2] = \\sum_{k=0}^\\infty \\Pr(X &gt; k)(2k+1)\n\\]\nも成立する．\n\\[\n\\begin{align*}\n\\sum_{k=0}^\\infty \\Pr(X &gt; k)(2k+1)\n    &= \\sum_{k=0}^\\infty \\sum_{l=k+1}^\\infty \\Pr(X=l)(2k+1)\\\\\n    &= \\sum_{l=1}^\\infty \\sum_{k=0}^{l-1}\\Pr(X=l)(2k+1)\\\\\n    &= \\sum_{l=1}^\\infty \\Pr(X=l)\\sum_{k=0}^{l-1}(2k+1)\\\\\n    &= \\sum_{l=1}^\\infty l^2\\Pr(X=l)\\\\\n    &= \\mathbb E[X^2]\n\\end{align*}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]\n\n\n\nTheorem 3.3 期待値の線型性 \n\\(a, b\\) を実数，確率変数 \\(X, Y\\) について以下が成り立つ\n\\[\n\\mathbb E[aX + bY] = a\\mathbb E[X] + b\\mathbb E[Y]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n確率変数 \\(X, Y\\) が有限加算な標本空間で定義されているケースにて以下を示す．\n\n\\(\\mathbb E[X + Y] = \\mathbb E[X] + \\mathbb E[Y]\\)\n\\(\\mathbb E[cX] = c\\mathbb E[X]\\)\n\n ▶  1. \\(\\mathbb E[X + Y] = \\mathbb E[X] + \\mathbb E[Y]\\)\n確率変数 \\(X\\) は \\(\\{x_1, \\cdots, x_m\\}\\), 確率変数 \\(Y\\) は \\(\\{y_1, \\cdots, y_n\\}\\) の値をそれぞれ取りうるとする． このとき，\\(Z = X + Y\\) の標本空間 \\(\\{z_1, \\cdots, z_k\\}\\) について \\(k\\leq m + n\\) が成り立つ．\n\\(A_l = \\{(i,j): x_i + y_j = z_l\\}\\) としたとき，\n\\[\n\\begin{align*}\n\\mathbb E[X+Y]\n    &= \\sum_{l=1}^kz_l\\Pr(A_l)\\\\\n    &= \\sum_{l=1}^k\\sum_{(i,j)\\in Z_l}(x_i + y_j)\\Pr(x_i, y_j)\\\\\n    &= \\sum_{i=1}^m\\sum_{j=1}^n(x_i + y_j)\\Pr(x_i, y_j)\\\\\n    &= \\sum_{i=1}^m\\sum_{j=1}^nx_i\\Pr(x_i, y_j) + y_j\\Pr(x_i, y_j)\\\\\n    &= \\sum_{i=1}^m\\sum_{j=1}^n[x_i\\Pr(x_i, y_j) + y_j\\Pr(x_i, y_j)]\\\\\n    &= \\sum_{i=1}^mx_i\\sum_{j=1}^nPr(x_i, y_j) + \\sum_{j=1}^ny_j\\sum_{i=1}^m\\Pr(x_i, y_j)\\\\\n    &=\\sum_{i=1}^mx_i \\Pr(x_i) + \\sum_{j=1}^ny_j \\Pr(y_j)\\\\\n    &= \\mathbb E[X] + \\mathbb E[Y]\n\\end{align*}\n\\]\n ▶  2. \\(\\mathbb E[cX] = c\\mathbb E[X]\\)\n\\[\n\\begin{align*}\n\\mathbb E[cX]\n    &= \\sum_{i=1}^m cx_i = \\Pr(cX = cx_i)\\\\\n    &= c\\sum_{i=1}^m x_i = \\Pr(X = x_i)\\\\\n    &= c\\mathbb E[X]\n\\end{align*}\n\\]\n\n\n\n\nExample 3.6 : 変数変換と分散 \nmean \\(\\mu\\) をもつ確率変数 \\(X\\) と実数 \\(a, b\\) について\n\\[\n\\operatorname{Var}(aX + b) = a^2\\operatorname{Var}(X)\n\\]\nが成立します．証明は以下，\n\\[\n\\begin{align*}\n\\operatorname{Var}(aX + b)\n    &= \\mathbb E[(aX + b) - (a\\mu +b)^2]\\\\\n    &= \\mathbb E[a^2(X - \\mu)^2]\\\\\n    &= a^2 \\mathbb E[(X - \\mu)^2]\\\\\n    &= a^2\\operatorname{Var}(X)\n\\end{align*}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]\n\n\n\nTheorem 3.4 positive operator \n確率変数 \\(X, Y\\) について，\\(X\\geq Y\\) が成り立つとき，\n\\[\n\\mathbb E[X] \\geq \\mathbb E[Y]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(X\\geq Y\\) より \\(X - Y \\geq 0\\). 期待値はpositive operatorなので\n\\[\n\\mathbb E[X - Y] \\geq 0\n\\]\n従って，期待値の線型性を用いると\n\\[\n\\begin{align*}\n\\mathbb E[X - Y] &= \\mathbb E[X] - \\mathbb E[Y] \\geq 0\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.5 \n確率変数 \\(X\\) について,\n\\[\n\\mathbb E[\\vert X \\vert] \\geq \\vert \\mathbb E[X] \\vert\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(\\vert X\\vert \\geq X\\) より\n\\[\n\\mathbb E[\\vert X \\vert] \\geq \\mathbb E[X]\n\\]\nまた, \\(\\vert X\\vert + X \\geq 0\\) より，\\(\\mathbb E[\\vert X\\vert + X] \\geq 0\\)， つまり，\n\\[\n\\mathbb E[\\vert X \\vert] \\geq -\\mathbb E[X]\n\\]\n以上より，\\(\\mathbb E[\\vert X \\vert] \\geq \\vert \\mathbb E[X] \\vert\\)\n\n\n\n\n\nTheorem 3.6 互いに独立な確率変数の積の期待値 \n\\(\\mathbb E[\\vert X\\vert ]&lt;\\infty, \\mathbb E[\\vert Y\\vert ]&lt;\\infty\\) を満たす, 確率空間 \\((\\Omega, \\mathscr{F},P)\\) 上で定義された確率変数 \\(X, Y\\) を考える． \\(X \\perp Y\\) であるとき，次が成立する\n\\[\n\\mathbb E[XY] = \\mathbb E[X]\\mathbb E[Y]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\mathbb E[XY] &= \\int\\int_\\Omega xy f(x, y)\\mathrm{d}x\\mathrm{d}y\\\\\n              &= \\int\\int_\\Omega xy f_X(x)f_Y(y)\\mathrm{d}x\\mathrm{d}y \\quad\\because{\\text{independence}}\\\\\n              &= \\left(\\int xf_X(x)\\mathrm{d}x\\right)\\left(\\int yf_Y(y)\\mathrm{d}y\\right)\\\\\n              &= \\mathbb E[X]\\mathbb E[Y]\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.7 Schwarz inquality \n確率変数 \\(X, Y\\) についてシュワルツの不等式が成立することを示せ\n\\[\n\\left(\\mathbb E[XY]\\right)^2 \\leq \\mathbb E[X^2]\\mathbb E[Y^2]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nQuadratic functionを以下のように定義します\n\\[\n\\begin{align*}\ng(t)\n    &= \\mathbb E[(tX - Y)^2]\\\\\n    &= t^2\\mathbb E[X^2] - 2t\\mathbb E[XY] + E[Y^2]\\\\\n    &\\geq 0\n\\end{align*}\n\\]\nこのとき，\\(g(t)\\) はnon-negativeなので判別式について以下が成立する\n\\[\nD/4 = \\left(\\mathbb E[XY]\\right)^2 - \\mathbb E[X^2]\\mathbb E[Y^2]\\leq 0\n\\]\n従って，\\(\\left(\\mathbb E[XY]\\right)^2 \\leq \\mathbb E[X^2]\\mathbb E[Y^2]\\)\n\n\n\n\n\nTheorem 3.8 : Triangle inequality \n確率変数 \\(X, Y\\) について，以下のような三角不等式が成立することを示せ\n\\[\n\\sqrt{\\mathbb E[(X+Y)^2]} \\leq \\sqrt{\\mathbb E[X^2]} + \\sqrt{\\mathbb E[Y^2]}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nシュワルツの不等式を用いて以下のように示せる\n\\[\n\\begin{align*}\n\\mathbb E[(X+Y)^2]\n    &= \\mathbb E[X^2] + 2\\mathbb E[XY] + \\mathbb E[Y^2]\\\\\n    &= \\mathbb E[X^2] + 2\\sqrt{(\\mathbb E[XY])^2} + \\mathbb E[Y^2]\\\\\n    &\\leq \\mathbb E[X^2] + 2\\sqrt{\\mathbb E[X^2]\\mathbb E[Y^2]} + \\mathbb E[Y^2]\\\\\n    &= (\\sqrt{\\mathbb E[X^2]} + \\sqrt{\\mathbb E[Y^2]})^2\n\\end{align*}\n\\]\n両辺について，square rootをとると，\n\\[\n\\sqrt{\\mathbb E[(X+Y)^2]} \\leq \\sqrt{\\mathbb E[X^2]} + \\sqrt{\\mathbb E[Y^2]}\n\\]\n\n\n\n\n条件付き期待値\n\n\nTheorem 3.9 Law of Total Expectation \n\\[\n\\mathbb E[Y] = \\mathbb E[\\mathbb E[Y\\vert X]]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\mathbb E[\\mathbb E[Y\\vert X]]\n    &= \\int \\mathbb E[Y\\vert X=u]f_X(u)\\mathrm{d}u\\\\\n    &= \\int \\left[\\int t f_Y(t\\vert x=u)\\mathrm{d}t\\right]f_X(u)\\mathrm{d}u\\\\\n    &= \\int \\int t f_Y(t\\vert x=u)f_X(u)\\mathrm{d}u\\mathrm{d}t\\\\\n    &= \\int t\\left[\\int f_{X,Y}(u, t)\\mathrm{d}u\\right]\\mathrm{d}t\\\\\n    &= \\int t f_Y(t)\\mathrm{d}t\\\\\n    &= \\mathbb E[Y]\n\\end{align*}\n\\]\n\n\n\n\n\nTheorem 3.10 : CEF Decomposition Property \n確率変数 \\(X, Y\\) について，\n\\[\nY = \\mathbb E[Y\\vert X] + \\epsilon\n\\]\nとしたとき，\n\n\\(\\epsilon\\) は \\(X\\) について mean-independent, i.e., \\(\\mathbb E[\\epsilon\\vert X] = 0\\)\n\\(\\epsilon\\) は \\(X\\) の任意の関数に対して無相関, i.e., \\(\\operatorname{Cov}(h(X), \\epsilon) = 0\\)\n\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n ▶  (1)\n\\[\n\\begin{align*}\n\\mathbb E[\\epsilon\\vert X]\n    &= \\mathbb E[Y - \\mathbb E[Y\\vert X]\\vert X]\\\\\n    &= \\mathbb E[Y\\vert X] - \\mathbb E[Y\\vert X]\\\\\n    &= 0\n\\end{align*}\n\\]\n ▶  (2)\n\\[\n\\begin{align*}\n\\mathbb E[h(X)\\epsilon] &= E[\\mathbb E[h(X)\\epsilon\\vert X]]\\\\\n                        &= E[h(X)\\mathbb E[\\epsilon\\vert X]]\\\\\n                        &= 0 \\quad \\because{\\text{mean independence}}\n\\end{align*}\n\\]\n\n\n\n\n📘 REMARKS \nCEF Decomposition Propertyは，確率変数 \\(Y\\) は確率変数 \\(X\\) で説明できるパートと，\\(X\\) の任意の関数と直行（orthogonal） な誤差項のパートに分解できることを示しています．",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>期待値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html#markov-and-chebyshev-inequalities",
    "href": "posts/statistics101/expectation.html#markov-and-chebyshev-inequalities",
    "title": "3  期待値",
    "section": "Markov and Chebyshev Inequalities",
    "text": "Markov and Chebyshev Inequalities\n確率変数 \\(X\\) について，確率密度関数や分布関数がわかっている状況は少ないです．また，データが得られたとしても それらを計算することはかんたんではありません．その中で，\n\n\\(X\\) が mean \\(\\mu\\) からどれくらい離れる可能性があるのか\n\\(\\Pr(\\vert X \\leq a\\vert )\\) のupper boundはどれくらいか？\n\nという統計的推測をしたいときに使用されるMarkov and Chebyshev Inequalitiesを解説します．\n\nMarkov’s Inequality\n\n\nTheorem 3.11 Markov’s Inequality \nnon-negative 確率変数 \\(X \\geq 0\\)，constant \\(k &gt;0\\) について以下が成立する\n\\[\n\\Pr(X \\geq k) \\leq \\frac{\\mathbb E[X]}{k}\n\\]\nつまり，\n\\[\n\\Pr(X \\geq k\\mathbb E[X]) \\leq \\frac{1}{k}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\mathbb E[X] &= \\int_0^\\infty xf(x)\\mathrm{d}x\\\\\n             &= \\int_0^k xf(x)\\mathrm{d}x + \\int_k^\\infty xf(x)\\mathrm{d}x\\\\\n             &\\leq \\int_k^\\infty xf(x)\\mathrm{d}x\\\\\n             &\\leq \\int_k^\\infty kf(x)\\mathrm{d}x\\\\\n             &= k \\Pr(X \\geq k)\n\\end{align*}\n\\]\n\n\n\n\n\n\n\n\n\nProof: 変数変換\n\n\n\n\n\n\\[\nY =\n\\begin{cases}\n    0 & \\text{if} X &lt; k\\\\[5pt]\n    k & \\text{if} X \\geq k\n\\end{cases}\n\\]\nのように変数変換をすると常に \\(Y \\leq X\\) であるので \\(\\mathbb E[Y] \\leq \\mathbb E[X]\\).\n\\[\n\\begin{align*}\n&\\mathbb E[Y] = k\\Pr(X\\geq k)\\\\\n\\Rightarrow &\\Pr(X\\geq k)\\leq \\frac{\\mathbb E[X]}{k}\n\\end{align*}\n\\]\n\n\n\n\n📘 REMARKS \n\nMarkov’s inequalityは 確率変数 \\(X\\) がnon-negative, population mean \\(\\mu\\) の知識のみで使用可能\n一方，bound幅は大きく，weakest inequalityである\n\n\n\nExample 3.7 \n点数範囲が \\(\\Omega_x=[0, 110]\\) の試験をついて，そのテストスコア確率変数 \\(X\\) を考える．分布の情報はわからないが population meanは 25 であることが知られている．このとき，\\(\\Pr(X \\geq 100)\\) のupper boundはMarkov’s inequalityを用いて 以下のように計算できます．\n\\(X\\) がnon-negativeなので\n\\[\n\\begin{align*}\n\\Pr(X\\geq 100) &\\leq \\frac{25}{100}\\\\\n               &= \\frac{1}{4}\n\\end{align*}\n\\]\n\n\nExample 3.8 : weak inequality \n\\(X_i \\overset{\\mathrm{iid}}{\\sim} \\operatorname{Bernoulli}(0.2)\\) を20回繰り返す試行を考える．この試行の結果のアウトカムを \\(Y\\) としたとき，\n\\[\n\\Pr(Y \\geq 16) = \\sum_{k=16}^{20} {}_{20}C_{k} 0.2^k 0.8^{20-k} \\approx 1.38\\cdot 10^{-8}\n\\]\n一方，Markov’s inequalityを用いると\n\\[\n\\begin{align*}\n\\Pr(Y \\geq 16) \\leq \\frac{4}{16} = \\frac{1}{4}\n\\end{align*}\n\\]\nこのように，bound幅は大きいことが分かる．\n\n\n\nChebyshev’s Inequality\n\n\nTheorem 3.12 Chebyshev’s inequality \n\\(X \\sim D(\\mu, \\sigma^2)\\) とする．ただし，\\(D\\) の形状はわからない．実数 \\(\\alpha &gt;0\\) について，以下が成立する\n\\[\n\\Pr(\\vert X - \\mu \\vert \\geq \\alpha) \\leq \\frac{\\sigma^2}{\\alpha^2}\n\\]\nつまり，\n\\[\n\\Pr(\\vert X - \\mu \\vert \\geq \\alpha \\sigma) \\leq \\frac{1}{\\alpha^2}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(I = \\{x: \\vert x -\\mu \\vert \\geq k\\}\\) とする．\n\\[\n\\begin{align*}\n\\sigma^2 &= \\int_{\\mathbb R} (x - \\mu)^2f(x)\\mathrm{d}x\\\\\n         &\\geq  \\int_{I} (x - \\mu)^2f(x)\\mathrm{d}x\\\\\n         &\\geq  \\int_{I} k^2f(x)\\mathrm{d}x\\\\\n         &= k^2 \\Pr(\\vert x - \\mu\\vert \\geq k)\n\\end{align*}\n\\]\n以上より，\\(\\displaystyle\\Pr(\\vert X - \\mu \\vert \\geq k) \\leq \\frac{\\sigma^2}{k^2}\\) を得る．\n\n\n\n\n\n\n\n\n\nProof: using Markov’s inequality\n\n\n\n\n\n\\((x - \\mu)^2\\) を確率変数と考えると，non-negative確率変数になる，つまりMarkov’s inequalityを用いることができるので\n\\[\n\\begin{align*}\n\\Pr(\\vert x - \\mu\\vert \\geq k) &= \\Pr((x - \\mu)^2 \\geq k)\\\\\n                               &\\leq \\frac{\\mathbb E[(x - \\mu)^2]}{k^2} \\because{\\text{Markov's inequality}}\\\\\n                               &= \\frac{\\sigma^2}{k^2}\n\\end{align*}\n\\]\n\n\n\n\nExample 3.9 Markov’s inequality vs Chebyshev’s inequality \n\\(X \\sim \\operatorname{Binom}(n=20, p=0.2)\\) について，weak inequality で確認したように，Markov’s inequalityのより\n\\[\n\\Pr(X \\geq 16) = \\Pr(X \\geq 4\\mathbb E[X]) \\leq \\frac{1}{4}\n\\]\n一方，Chebyshev’s inequalityを用いると\n\\[\n\\begin{align*}\n\\Pr(X \\geq 16) &\\leq \\Pr(\\vert X - 4\\vert \\geq 12)\\\\\n               &\\leq \\frac{\\operatorname{Var}(X)}{12^2}\\\\\n               &\\leq \\frac{3.2}{12^2}\\\\\n               &= \\frac{1}{45}\n\\end{align*}\n\\]\n\n\n📘 REMARKS \n\nChebyshev’s inequalityはMarkov’s inqualityと異なり，確率変数 \\(X\\) がnon-negativeである必要はない\nmeanからの距離についての情報を得ることができる\n\n\n\n\nWeak Law of Large Numbers\n\n\nTheorem 3.13 Weak Law of Large Numbers \n平均 \\(\\mu\\), 分散 \\(\\sigma^2\\) の分布に独立に従う確率変数 \\(X_1, \\cdots, X_n\\) を考える．標本平均を \\(\\overline{X_n} = \\frac{1}{n}\\sum_{i=1}^nX_i\\) とする．\nこのとき，任意の実数 \\(\\epsilon &gt;0\\) に対して，\n\\[\n\\lim_{n\\to\\infty}\\Pr(\\vert \\overline{X_n} - \\mu \\vert &gt; \\epsilon) = 0\n\\]\nつまり，標本平均は母平均に確率収束する．\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nChebyshev’s inequalityを用いて以下のように示せる\n\\[\n\\begin{align*}\n\\lim_{n\\to\\infty}\\Pr(\\vert \\overline{X_n} - \\mu \\vert &gt; \\epsilon)\n                &\\leq \\lim_{n\\to\\infty} \\frac{\\operatorname{Var}(\\overline{X_n})}{\\epsilon^2}\\\\\n                &= \\lim_{n\\to\\infty} \\frac{\\sigma^2}{n\\epsilon^2}\\\\\n                &=0\n\\end{align*}\n\\]",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>期待値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/expectation.html#分散",
    "href": "posts/statistics101/expectation.html#分散",
    "title": "3  期待値",
    "section": "分散",
    "text": "分散\n\n\nTheorem 3.14 : Bienaymé Equality \n互いに独立な確率変数 \\(X, Y\\) について以下が成立する\n\\[\n\\operatorname{Var}(X+Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\operatorname{Var}(X+Y)\n    &= \\mathbb E[((X+Y) - (\\mu_X+\\mu_Y))^2]\\\\\n    &= \\mathbb E[((X- \\mu_X)+(Y - \\mu_Y))^2]\\\\\n    &= \\mathbb E[(X- \\mu_X)^2] + 2\\mathbb E[(X- \\mu_X)(Y- \\mu_Y)] + \\mathbb E[(Y- \\mu_Y)^2]\\\\\n    &= \\mathbb E[(X- \\mu_X)^2] + 2\\mathbb E[(X- \\mu_X)]\\mathbb E[(Y- \\mu_Y)] + \\mathbb E[(Y- \\mu_Y)^2] \\quad \\because{\\text{独立性}}\\\\\n    &= \\operatorname{Var}(X) + \\operatorname{Var}(Y)\n\\end{align*}\n\\]\n\n\n\nなお，確率変数 \\(X, Y\\) が独立ではない場合は\n\\[\n\\operatorname{Var}(X + Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y) + 2\\operatorname{Cov}(X, Y)\n\\]\nが成立します．\n\n条件付き分散\n確率変数 \\(X, Y\\) についての条件付き分散は以下のような意味を持つ\n\n\\(\\operatorname{Var}(X\\vert Y=y)\\) は，\\(Y = y\\) と固定したときの \\(X\\) の分散\n\\(\\operatorname{Var}(X\\vert Y)\\) は，\\(Y\\) がランダムに選ばれた値に固定された場合の \\(X\\) の分散\n\n\\(\\operatorname{Var}(X\\vert Y)\\) は \\(Y\\) のランダムネスに依存した確率変数である一方， \\(\\operatorname{Var}(X\\vert Y=y)\\) は \\(y\\) の関数という違いがある\n\n\nTheorem 3.15 条件付き分散 \n\\[\n\\operatorname{Var}(Y\\vert X) = \\mathbb E[(Y^2\\vert X)] - (\\mathbb E[(Y\\vert X)])^2 = \\mathbb E[(Y - \\mathbb E[Y\\vert X])^2\\vert X]\n\\]\n\n\n\n\n\nTheorem 3.16 Law of Total Variance \n\\[\n\\operatorname{Var}(Y) = \\operatorname{Var}(\\mathbb E[Y\\vert X]) + \\mathbb E_X[\\operatorname{Var}(Y\\vert X)]\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(\\epsilon = Y - E\\mathbb E[Y\\vert X]\\) としたとき，\\(\\epsilon\\) と \\(E\\mathbb E[Y\\vert X]\\) は無相関なので，\n\\[\n\\operatorname{Var}(Y) = \\operatorname{Var}(\\mathbb E[Y\\vert X]) + \\operatorname{Var}(\\epsilon)\n\\]\n\\(\\mathbb E[\\epsilon] = 0\\) より，\n\\[\n\\begin{align*}\n\\operatorname{Var}(\\epsilon)\n    &= \\mathbb E[\\epsilon^2] - (\\mathbb E[\\epsilon])^2\\\\\n    &= \\mathbb E[\\epsilon^2]\\\\\n    &= \\mathbb E_X(\\mathbb E[\\epsilon^2\\vert X])\\\\\n    &= \\mathbb E_X[\\operatorname{Var}(Y\\vert X)]\n\\end{align*}\n\\]\n従って，\n\\[\n\\operatorname{Var}(Y) = \\operatorname{Var}(\\mathbb E[Y\\vert X]) + \\mathbb E_X[\\operatorname{Var}(Y\\vert X)]\n\\]\n\n\n\nLaw of Total Varianceより \\(Y\\) の分散は，CEFの分散 + 誤差項の分散に分解できることを示しています． 実務における分析において，賃金のバラツキを\n\n賃金を説明する各個人の特徴のバラツキ\n特徴で説明することのできない賃金のバラツキ(=誤差項)の期待値\n\nに分解して考察する際にLaw of Total Varianceを使用したりします．",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>期待値</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/order_statistic.html",
    "href": "posts/statistics101/order_statistic.html",
    "title": "4  順序統計量",
    "section": "",
    "text": "順序統計量\n▶  \\(X_{(i)}\\) の累積密度関数と確率密度関数\n\\(F\\) を密度関数 \\(f\\) を持つ連続分布として，\\(X_{(i)} \\leq x\\) となる事象を考える．この事象は \\(X_1, \\cdots, X_n\\) のなかで \\(x\\) 以下となるものの個数が \\(i\\) 個以上であるという事象と同地なので\n\\[\nB_k = \\{X_1, \\cdots, X_n\\text{のうち}k\\text{個が}x\\text{以下}\\}\n\\]\nと事象 \\(B_k\\) を設定すると，\n\\[\n\\Pr(X_{(i)}\\leq x) = \\sum_{k=i}^n \\Pr(B_k)\n\\]\nそれぞれの \\(X_j\\) について，独立に成功確率 \\(p = F(x)\\) のベルヌーイ試行と考えることができるので\n\\[\nF_{X_{(i)}}(X) = \\sum_{k=i}^n {}_nC_{k} p^k (1 - p)^{n-k}, \\ \\ p=F(x)\n\\]\nとなることがわかります．また，この式を \\(x\\) で微分することで \\(X_{(i)}\\) の確率密度関数がわかるので, \\(p(k, m)\\) を \\(\\operatorname{Binom}(m, p)\\) の確率関数とすると\n\\[\n\\begin{align*}\n&\\frac{\\mathrm{d}}{\\mathrm{d}p} {}_nC_{k} p^k (1 - p)^{n-k}\\\\\n&= \\frac{n!}{(k-1)!(n-k)!}p^{k-1}(1-p)^{n-k} - \\frac{n!}{k!(n-k-1)!}p^{k-1}(1-p)^{n-k-1}\\\\\n&= n (p(k-1, n-1) - p(k. n-1))\n\\end{align*}\n\\]\n従って，\\(p(n, n-1) =0\\) とすると，\n\\[\n\\begin{align*}\nf_{X_{(i)}}(x) &= nf(x)\\sum_{k=i}^n(p(k-1, n-1) - p(k. n-1))\\\\\n               &= nf(x) p(i-1, n-1)\\\\\n               &= \\frac{n!}{(i-1)!(n-i)!}f(x)F(x)^{i-1}(1 - F(x))^{n-i}\n\\end{align*}\n\\]\n▶  最大値の分布関数\n最大値の分布関数 \\(\\Pr(X_{(n)} \\leq x)\\) は\n\\[\n\\max_i X_i \\leq x \\Leftrightarrow X_i \\leq x, \\  \\ i = 1, \\cdots, n\n\\]\nなので，\n\\[\n\\begin{align*}\n&\\Pr(\\max_i X_i \\leq x )= F(x)^n\\\\\n&f_{X_{(n)}}(x) = nf(x)F(x)^{n-1}\n\\end{align*}\n\\]\n▶  最小値の分布関数\n最小値の分布関数 \\(\\Pr(X_{(1)} \\leq x) = \\Pr(\\min(X_i)\\leq x)\\) は\n\\[\n\\min_i X_i &gt; x \\Leftrightarrow X_i &gt; x, \\  \\ i = 1, \\cdots, n\n\\]\nより\n\\[\n\\begin{align*}\n&\\Pr(\\min_i X_i \\leq x )= 1 - (1 - F(x))^n\\\\\n&f_{X_{(1)}}(x) = nf(x)(1 - F(x))^{n-1}\n\\end{align*}\n\\]\nCode\nimport numpy as np\nfrom scipy.stats import beta\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nN = 10\nITER = 10000\nI = 9\nNBINS = 100\na, b = 10, 1\nnp.random.seed(42)\n\n\ndef random_sampling_from_unif(index, size):\n    return sorted(np.random.uniform(0, 1, size))[index]\n\n\nx = np.array(list(map(lambda x: random_sampling_from_unif(I, N), range(ITER))))\nbeta_x = np.linspace(beta.ppf(0.01, a, b), beta.ppf(0.99, a, b), NBINS)\n\n# plot\nnewnames = {\"0\": \"sample maximum\"}\nfig = px.histogram(x, histnorm=\"probability density\", nbins=NBINS, title=\"maximum value distribution of 10 rvs from Unif(0, 1)\")\nfig.for_each_trace(\n    lambda t: t.update(\n        name=newnames[t.name],\n        hovertemplate=t.hovertemplate.replace(t.name, newnames[t.name]),\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x=beta_x, y=beta.pdf(beta_x, a, b), mode=\"lines\", name=\"beta(10, 1) pdf\"\n    ),\n    row=1,\n    col=1,\n)\nfig.show()",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>順序統計量</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/order_statistic.html#順序統計量",
    "href": "posts/statistics101/order_statistic.html#順序統計量",
    "title": "4  順序統計量",
    "section": "",
    "text": "Def: 順序統計量 \n\\(X_1, \\cdots, X_n \\overset{\\mathrm{iid}}{\\sim} F\\) とするとき，これkらの確率変数の値を小さい順に並び替えたものを\n\\[\nX_{(1)}\\leq\\cdots\\leq X_{(i)}\\leq\\cdots \\leq X_{(n)}\n\\]\nと表し，順序統計量(order statistic)という．\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExample 4.1 一様分布に従う確率変数列の順序統計量とベータ分布 \n\\(X_1, \\cdots, X_n \\overset{\\mathrm{iid}}{\\sim} \\operatorname{Unif}(0, 1)\\) とするとき，第 \\(i\\) 順序統計量の確率密度関数と分布関数はそれぞれ以下のようになる\n\\[\n\\begin{align*}\nf_{X_{(i)}} &= \\frac{n!}{(i-1)!(n-i)!} x^{i-1}(1 - x)^{n-i}\\\\\n            &= \\frac{x^{i-1}(1 - x)^{n-i}}{\\operatorname{B}(i, n-i+1)}\\\\\nF_{X_{(i)}} &= \\sum_{k=i}^n \\frac{n!}{(n-k)!k!} x^k (1 - x)^{n-k}\\\\\n            &= \\frac{n!}{(i-1)!(n-i)!}\\int^x_0t^{i-1}(1 - t)^{n-i}\\mathrm{d}t\n\\end{align*}\n\\]\n従って，\\(X_{(i)}\\) はベータ分布 \\(\\operatorname{Beta}(i, n-i+1)\\) に従うことがわかる．ここから \\(\\operatorname{Beta}(1, 1)\\) が \\(\\operatorname{Unif}(0, 1)\\) に等しくなることもわかる．",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>順序統計量</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/order_statistic.html#最大値と最小値の同時密度関数",
    "href": "posts/statistics101/order_statistic.html#最大値と最小値の同時密度関数",
    "title": "4  順序統計量",
    "section": "最大値と最小値の同時密度関数",
    "text": "最大値と最小値の同時密度関数\n\n\nTheorem 4.1 最大値と最小値の同時密度関数 \n\\(X_1, \\cdots, X_n \\overset{\\mathrm{iid}}{\\sim} F\\) とするとき，\\(x&lt;y\\) とすると\n\\[\n\\begin{align*}\nF_{X_{(1)},X_{(n)}}(x, y) &= \\Pr(X_{(1)} \\leq x,X_{(n)}\\leq y)\\\\\n                          &= [F(y)]^n - [F(y) - F(x)]^n\n\\end{align*}\n\\]\n同時確率密度関数は\n\\[\nf_{X_{(1)},X_{(n)}}(x, y) = n(n-1)[F(y) - F(x)]^{n-2}f(x)f(y)\n\\]\n\n\n\\(x &lt; y\\) の条件のもとで，\n\\[\nF_{X_{(1)},X_{(n)}}(x, y) = \\Pr(X_{(1)} \\leq x,X_{(n)}\\leq y)\n\\]\nについてまず考える．確率事象の排他性より\n\\[\n\\Pr(X_{(n)} \\leq y) = \\Pr(X_{(1)}\\leq x, X_{(n)}\\leq y) + \\Pr(X_{(1)}&gt; x, X_{(n)}\\leq y)\n\\]\nここから，\\(\\Pr(X_{(1)}\\leq x, X_{(n)}\\leq y) = \\Pr(X_{(n)} \\leq y) - \\Pr(X_{(1)}&gt; x, X_{(n)}\\leq y)\\) を得る．\n\\[\n\\begin{align*}\n&\\Pr(X_{(1)}&gt; x, X_{(n)}\\leq y)\\\\\n&= \\Pr(x &lt; X_{(1)} \\leq y, \\cdots, x &lt; X_{(i)} \\leq y, \\cdots, x&lt; X_{(n)}\\leq y)\\\\\n&= [F(y) - F(x)]^n \\because{\\operatorname{i.i.d}}\n\\end{align*}\n\\]\n\\(\\Pr(X_{(n)}\\leq y) = [F(y)]^n\\) であるのは上で確認したので，従って，\n\\[\n\\begin{align*}\nF_{X_{(1)},X_{(n)}}(x, y) &= \\Pr(X_{(1)} \\leq x,X_{(n)}\\leq y)\\\\\n                          &= [F(y)]^n - [F(y) - F(x)]^n\n\\end{align*}\n\\]\n同時確率密度関数は\n\\[\n\\begin{align*}\nf_{X_{(1)},X_{(n)}}(x, y) &= \\frac{\\mathrm{d}}{\\mathrm{d}x}\\frac{\\mathrm{d}}{\\mathrm{d}x}\\{[F(y)]^n - [F(y) - F(x)]^n\\}\\\\\n&= \\frac{\\mathrm{d}}{\\mathrm{d}x}\\{n[F_y]^{n-1}f(y) - n[F(y) - F(x)]^{n-1}f(y)\\}\\\\\n&= n(n-1)[F(y) - F(x)]^{n-2}f(y)f(x)\n\\end{align*}\n\\]\n ▶  A heuristic approach for calculating the joint pdf\n\\(\\min X_i = x, \\max X_i =y\\), と決まっており, それ以外の値は \\((x, y)\\) 区間に収まっていれば何でも良いので， index通りに順番があるならば\n\\[\nf(x)[F(y) - F(x)]^{n-2}f(y)\n\\]\nまた，この並べ方は \\(n!\\) 通り存在するが，\\(X_{(1)}, X_{(n)}\\) 以外の並び方には区別はいらないので\n\\[\n\\frac{n!}{(n-2)!}f(x)[F(y) - F(x)]^{n-2}f(y) = n(n-1)f(x)[F(y) - F(x)]^{n-2}f(y)\n\\]\n\n📘 REMARKS \n並び替えの考えで同様に \\((X_{(1)}, \\cdots, X_{(n)})\\) の同時確率密度関数は\n\\[\nf_{X_{(1)}, \\cdots, X_{(n)}}(x_1, \\cdots, x_n) = n!f(x_1)f(x_2)\\cdots f(x_n)\n\\]\nであることがわかる．\n\\(X_{(i)}, X_{(j)}\\) の同時確率密度関数は\n\\[\nf_{X_{(i)}, X_{(j)}}(x, y)=\\frac{n!}{(i-1)!(j-i-1)!}(n-j)!f(x)f(y)F(x)^{i-1}[F(y)-F(x)]^{j-i-1}[1 - F(y)]^{n-j}\n\\]",
    "crumbs": [
      "統計学入門",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>順序統計量</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html",
    "href": "posts/probability_distribution/hypergeometric.html",
    "title": "5  超幾何分布",
    "section": "",
    "text": "超幾何分布の性質\nツボに \\(K\\) 個の赤玉と \\(N-K\\) 個の白玉，つまり合計 \\(N\\) 個の玉が入っている中から，\\(n\\) 個の玉をランダムに 非復元(without replacement)で抽出するとする．このとき取り出した赤玉の個数を \\(X\\) としたとき，この \\(X\\) は超幾何分布 \\(\\operatorname{Hypergeometric}(N, K, n)\\) に従います．\n▶  確率関数の合計が1になることの証明\n恒等式\n\\[\n(1 + t)^N = (1 + t)^{K}(1 + t)^{N-K}\n\\]\nを考える．RHSを展開し，\\(t^n\\) の係数 \\(\\beta_n\\) を見てみると\n\\[\n\\begin{align*}\n\\beta_n = \\sum_{\\max(n+K-N, 0)}^{\\min(K, n)} {}_KC_{x} \\times {}_{N-K}C_{n-x}\n\\end{align*}\n\\]\n一方，LHSでみると\n\\[\n\\beta_n = {}_NC_n\n\\]\n従って，\n\\[\n\\begin{gather*}\n\\sum_{\\max(n+K-N, 0)}^{\\min(K, n)} {}_KC_{x} \\times {}_{N-K}C_{n-x} = {}_NC_n\\\\\n\\Rightarrow \\sum_{\\max(n+K-N, 0)}^{\\min(K, n)}\\Pr(X=k) = 1\n\\end{gather*}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]",
    "crumbs": [
      "確率分布",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>超幾何分布</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html#超幾何分布の性質",
    "href": "posts/probability_distribution/hypergeometric.html#超幾何分布の性質",
    "title": "5  超幾何分布",
    "section": "",
    "text": "Def: 超幾何分布 \nParameters \\((N, K, n)\\) の超幾何分布に従う確率変数 \\(X\\) について，その確率関数は\n\\[\n\\begin{gather*}\n\\Pr(X = x) = \\frac{{}_KC_x \\cdot {}_{N-K}C_{n-x}}{{}_NC_n}\\\\\n\\text{where} \\max\\{0, n+K-N\\} \\leq x \\leq \\min\\{n, K\\}\n\\end{gather*}\n\\]\nまた \\(\\max\\{0, n+K-N\\} \\leq x \\leq \\min\\{n, K\\}\\) の範囲外の \\(x\\) については \\(\\Pr(X = x) = 0\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 5.1 期待値 \n確率変数 \\(X \\sim \\operatorname{Hypergeometric}(N, K, n)\\) について\n\\[\n\\mathbb E[X] = n\\frac{K}{N}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\left(\\begin{array}{c}n\\\\k\\end{array}\\right)= \\frac{n}{k} \\left(\\begin{array}{c}n-1\\\\ k-1\\end{array}\\right)\n\\]\nという関係式をもちいると\n\\[\n\\begin{align*}\n\\mathbb E[X]\n    &= \\sum_x\\frac{x \\left(\\begin{array}{c}K\\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-K\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N\\\\ n\\end{array}\\right)}\\\\\n    &= \\frac{nK}{N}\\sum_x\\frac{ \\left(\\begin{array}{c}K-1\\\\ x-1\\end{array}\\right)\\left(\\begin{array}{c}N-K\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N-1\\\\ n-1\\end{array}\\right)}\\\\\n    &= \\frac{nK}{N}\\sum_x\\frac{ \\left(\\begin{array}{c}K-1\\\\ x-1\\end{array}\\right)\\left(\\begin{array}{c}N-1-(K-1)\\\\ n-1 - (x-1)\\end{array}\\right)}{\\left(\\begin{array}{c}N-1\\\\ n-1\\end{array}\\right)}\n\\end{align*}\n\\]\n最後の式変形は，ツボに \\(K-1\\) 個の赤玉と \\(N-1 - (K-1)\\) 個の白玉，つまり合計 \\(N-1\\) 個の玉が入っている中から \\(n-1\\) 個のボールを選ぶ場合の確率関数と同じなので\n\\[\n\\begin{align*}\n\\sum_x\\frac{ \\left(\\begin{array}{c}K-1\\\\ x-1\\end{array}\\right)\\left(\\begin{array}{c}N-1-(K-1)\\\\ n-1 - (x-1)\\end{array}\\right)}{\\left(\\begin{array}{c}N-1\\\\ n-1\\end{array}\\right)} = 1\n\\end{align*}\n\\]\n従って，\\(\\displaystyle\\mathbb E[X] = \\frac{nK}{N}\\) を得る．\n\n\n\n\n\nTheorem 5.2 分散 \n確率変数 \\(X \\sim \\operatorname{Hypergeometric}(N, K, n)\\) について\n\\[\n\\operatorname{Var}(X) = n\\frac{K}{N}\\frac{N-K}{N}\\frac{N-n}{(N-1)}\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\operatorname{Var}(X) = \\mathbb E[X(X-1)] + E[X](1 - E[X])\n\\]\nなので，\\(\\mathbb E[X(X-1)]\\) がわかれば良い．\n\\[\n\\begin{align*}\n\\mathbb E[X(X-1)]\n    &= \\sum_{x}\\frac{x(x-1)\\left(\\begin{array}{c}K \\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-K \\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N \\\\ n\\end{array}\\right)}\\\\\n    &= \\frac{n(n-1)K(K-1)}{N(N-1)}\\sum_{x}\\frac{\\left(\\begin{array}{c}K-2 \\\\ x-2\\end{array}\\right)\\left(\\begin{array}{c}(N-2) - (K-2) \\\\ (n-2)-(x-2)\\end{array}\\right)}{\\left(\\begin{array}{c}N -2\\\\ n - 2\\end{array}\\right)}\\\\\n    &= \\frac{n(n-1)K(K-1)}{N(N-1)}\\sum_{l=x-2}\\frac{\\left(\\begin{array}{c}K-2 \\\\ l\\end{array}\\right)\\left(\\begin{array}{c}(N-2) - (K-2) \\\\ (n-2)-l\\end{array}\\right)}{\\left(\\begin{array}{c}N -2\\\\ n - 2\\end{array}\\right)}\\\\\n    &= \\frac{n(n-1)K(K-1)}{N(N-1)}\n\\end{align*}\n\\]\n従って，\n\\[\n\\operatorname{Var}(X) = n\\frac{K}{N}\\frac{N-K}{N}\\frac{N-n}{N-1}\n\\]\n\n\n\n\n📘 REMARKS \n\n\\(\\frac{N-n}{N-1}\\) は有限母集団修正と呼ばれる\n\n\n\n超幾何分布の極限と二項分布\n確率変数 \\(X \\sim \\operatorname{Hypergeometric}(N, K, n)\\) について, \\(\\frac{K}{N} = p \\text{ as } N, K \\to\\infty\\) が極限において 成立するとします．\n\\[\n\\begin{align*}\n&\\Pr(X = x)\\\\\n    &= \\frac{\\left(\\begin{array}{c}K\\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-K\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N\\\\n\\end{array}\\right)}\\\\\n    &= \\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)\\frac{K!}{(K-x)!}\\frac{(N-k)!}{(N-K-n+x)!}\\frac{(N-n)!}{N}\\\\\n    &= \\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)\\frac{K(K-1)\\cdots(K-x+1)}{N(N-1)\\cdots(N-x+1)}\\frac{(N-K)\\cdots(N-K-(n-x)+1)}{(N-x)\\cdots(N-x+1)}\n\\end{align*}\n\\]\nこのとき，\\(p = K/N\\) とすると，極限において\n\\[\n\\begin{gather*}\n\\frac{K(K-1)\\cdots(K-x+1)}{N(N-1)\\cdots(N-x+1)} \\approx p^x\\\\\n\\frac{(N-K)\\cdots(N-K-(n-x)+1)}{(N-x)\\cdots(N-x+1)}\\approx (1-p)^{n-x}\n\\end{gather*}\n\\]\n以上より\n\\[\n\\lim_{N,K\\to\\infty}\\Pr(X=x) = \\left(\\begin{array}{c}n\\\\ x\\end{array}\\right)p^x(1-p)^{n-x}\n\\]\n\n\n有限母集団からの非復元抽出と有限母集団修正\n有限母集団からの復元抽出は，i.i.d.確率変数が観測されるが，非復元抽出の場合は i.i.d.となりません． 大きさ \\(N\\) の有限母集団を考え，\\(X_i\\) を標本として抽出された観測値とします．なお，有限母集団に属する各個体の個体値を，\n\\[\na_1, a_2, \\cdots, a_N\n\\]\nとします．サイズ \\(n\\) の非復元抽出は，任意の互いに異なる \\(i_1, \\cdots, i_n\\) について，以下のように確率が定義される標本抽出方法です：\n\\[\n\\begin{align*}\n\\Pr(X_1 = a_{i_1}, \\cdots, X_1 = a_{i_n}) = \\frac{1}{N(N-1)\\cdots(N-n+1)}\n\\end{align*}\n\\]\n ▶  有限母集団の平均と分散\n有限母集団の平均と分散は\n\\[\n\\begin{gather*}\n\\mu = \\frac{1}{N}\\sum_{i=1}^Na_i\\\\\n\\sigma^2 = \\frac{1}{N}\\sum_{i=1}^N(a_i - \\mu)^2\n\\end{gather*}\n\\]\nと定義できます．\n ▶  標本平均の期待値と分散\n\\[\n\\begin{align*}\n\\mathbb E[\\overline{{X}}]\n    &= \\frac{1}{n}\\sum_{i=1}^n\\mathbb E[X_i]\\\\\n    &= \\mu\\\\\n\\\\\n\\operatorname{Var}(\\overline{{X}})\n    &= \\frac{1}{n^2}\\operatorname{Var}(\\sum_{i=1}^nX_i)\\\\\n    &=\\frac{1}{n^2}\\left[\\sum_{i=1}^n\\operatorname{Var}(X_i) + \\sum_{i\\neq j}\\operatorname{Cov}(X_i, X_j)\\right]\\\\\n    &=\\frac{1}{n^2}\\left[n\\operatorname{Var}(X_1) + n(n-1)\\operatorname{Cov}(X_1, X_2)\\right]\n\\end{align*}\n\\]\nここで，\n\\[\n\\begin{align*}\n&\\operatorname{Cov}(X_1, X_2)\\\\\n    &= \\mathbb E[X_1X_2] - \\mathbb E[X_1]\\mathbb E[X_2]\\\\\n    &= \\frac{1}{N(N-1)}\\sum_{i\\neq j}a_ia_j - \\left(\\frac{1}{N}\\sum_{i=1}^Na_i\\right)^2\\\\\n    &= \\frac{1}{N(N-1)}\\left[(\\sum_{i=1}^Na_i)^2 - \\sum_{i=1}^Na_i^2\\right]- \\left(\\frac{1}{N}\\sum_{i=1}^Na_i\\right)^2\\\\\n    &= \\frac{(\\sum_{i=1}^Na_i)^2}{N^2(N-1)} - \\frac{\\sum_{i=1}^Na_i^2}{N(N-1)}\\\\\n    &= -\\frac{1}{N(N-1)}\\left(\\sum_{i=1}^Na_i^2 - \\frac{1}{N}(\\sum_{i=1}^Na_i)^2\\right)\\\\\n    &= -\\frac{1}{N(N-1)}\\sum_{i=1}^N(a_i - \\overline(a))^2\\\\\n    &= -\\frac{\\sigma^2}{N-1}\n\\end{align*}\n\\]\n従って，\n\\[\n\\operatorname{Var}(\\overline{{X}}) = \\frac{\\sigma^2}{n}\\frac{N-n}{N-1}\n\\]\n\n📘 REMARKS \nサイズ \\(N\\) の有限母集団からサイズ \\(n\\) の非復元無作為抽出を実施する場合，\n\\[\n\\{a_{i_1}, \\cdots, a_{i_n}\\}\n\\]\nという要素の重複を許した多重集合を一度抽出し，そこから改めて１個ずつ順に無作為に抜き出すという方法でも同じ抽出方法となります． ここから，\\(X_i\\) の周辺分布は \\(X_1\\) の周辺分布と同じになることが分かるし，また，\\((X_i, X_j)\\) の２次元同時分布は \\((X_1, X_2)\\) の２次元同時分布と同じであることがわかります．\n\n ▶  別解: 非復元抽出における \\(\\operatorname{Cov}(X_1, X_2)\\) の求め方\n\\[\n\\sum_{i=1}^N X_i = \\sum_{i=1}^N a_i\n\\]\nと定数であるので，\\(\\operatorname{Var}(\\sum_{i=1}^N X_i) = 0\\) となる．\n\\[\n\\begin{align*}\n\\operatorname{Var}(\\sum_{i=1}^N X_i)\n    &= \\sum_{i=1}^N \\operatorname{Var}(X_1) + \\sum_{i\\neq j}\\operatorname{Cov}(X_1, X_2)\\\\\n    &= N\\sigma^2 + N(N-1)\\operatorname{Cov}(X_1, X_2) = 0\n\\end{align*}\n\\]\n従って，\n\\[\n\\operatorname{Cov}(X_1, X_2) = -\\frac{\\sigma^2}{N-1}\n\\]\n\\[\\tag*{\\(\\blacksquare\\)}\\]",
    "crumbs": [
      "確率分布",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>超幾何分布</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html#多変量超幾何分布",
    "href": "posts/probability_distribution/hypergeometric.html#多変量超幾何分布",
    "title": "5  超幾何分布",
    "section": "多変量超幾何分布",
    "text": "多変量超幾何分布\n\nDef: 多変量超幾何分布 \n各個体が \\(c_1, c_2, \\cdots, c_k\\) のいずれかに所属するようなクラスサイズ \\(N\\) 有限母集団を考える(各 \\(c_i\\) のサイズは \\(C_i\\) とする)．つまり，\n\\[\n\\sum_{j=1}^kC_j = N\n\\]\nこの有限母集団から，サイズ \\(n\\) の非復元無作為抽出をする場合，その同時確率関数は\n\\[\n\\begin{gather*}\n\\Pr(X_1=x_1, \\cdots, X_k=x_k) = \\frac{\\left(\\begin{array}{c}C_1\\\\x_1 \\end{array}\\right)\\left(\\begin{array}{c}C_2\\\\x_2 \\end{array}\\right)\\cdots\\left(\\begin{array}{c}C_k\\\\ x_k \\end{array}\\right)}\n{\\left(\\begin{array}{c}N\\\\n \\end{array}\\right)}\\\\\n\\text{where } \\sum_{i=1}^kx_i = n\n\\end{gather*}\n\\]\nとなる．このとき，\\(k\\) 次元確率変数ベクトル \\(X\\) は \\(\\operatorname{Multi-hypergeometric}(N, (C_1, \\cdots, C_k), n)\\) に従う．\n\n ▶  周辺確率分布\n多変量超幾何分布の \\(X_i\\) についての周辺確率分布は，\\(X_i\\) 以外のグループをまとめてシンプルな超幾何分布とみなして考えることができるので\n\\[\n\\begin{gather*}\n\\Pr(X_i=x) = \\frac{\\left(\\begin{array}{c}C_i\\\\ x\\end{array}\\right)\\left(\\begin{array}{c}N-C_i\\\\ n-x\\end{array}\\right)}{\\left(\\begin{array}{c}N\\\\ n\\end{array}\\right)}\\\\\n\\text{where } \\max\\{0, n+C_i-N\\} \\leq x \\leq \\min\\{n, C_i\\}\n\\end{gather*}\n\\]\n ▶  期待値と分散\n\\[\n\\begin{gather*}\n\\mathbb E[X_i] = n\\frac{C_i}{N}\\\\\n\\operatorname{Var}(X_i) = n\\frac{C_i}{N}\\frac{N-C_i}{N}\\frac{N-n}{N-1}\\\\\n\\operatorname{Cov}(X_i, X_j) = -n\\frac{N-n}{N-1}\\frac{C_i}{N}\\frac{C_j}{N}\n\\end{gather*}\n\\]",
    "crumbs": [
      "確率分布",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>超幾何分布</span>"
    ]
  },
  {
    "objectID": "posts/probability_distribution/hypergeometric.html#references",
    "href": "posts/probability_distribution/hypergeometric.html#references",
    "title": "5  超幾何分布",
    "section": "References",
    "text": "References\n\nLibreTexts Statistics &gt; The Multivariate Hypergeometric Distribution",
    "crumbs": [
      "確率分布",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>超幾何分布</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_101/fisher_exact_test.html",
    "href": "posts/statistical_hypothesis_test_101/fisher_exact_test.html",
    "title": "6  Fisher’s exact test",
    "section": "",
    "text": "\\(2\\times 2\\)クロスセル表とFisher’s exact test\n各グループの合計という周辺の値が固定されていると考えたとき，(Treated, Positive)の人数という確率変数が従う分布は超幾何分布とみなすことができる． つまり，\nとしたとき，\\(X_{11}\\)の確率は\n\\[\n\\begin{align*}\n\\Pr(X_{11}=x) &= \\frac{{}_{x_{1\\cdot}}C_{x}\\times {}_{x_{2\\cdot}}C_{x_{\\cdot 1} - x} }{{}_{N}C_{x_{\\cdot 1}}}\\\\\n              &= \\frac{x_{\\cdot 1}!x_{\\cdot 2}!x_{2\\cdot}!x_{2\\cdot}!}{x_{11}!x_{12}!x_{21}!x_{22}!N!}\n\\end{align*}\n\\]\nこのとき，\\(x\\) の範囲は \\(\\max(0, x_{1\\cdot} - x_{2\\cdot}) \\leq x \\leq \\min(x_{1\\cdot}, x_{\\cdot 1})\\) になる．\n▶  Null hypothesis vs Alternative hypothesis\n上記の問題設定におけるFisher’s exact testにおける検定仮説設定例はと，両側検定ならば\n\\(H_0\\)の仮定の下では，\\(X_{11}\\)は超幾何分布(hypergeometric distribution)に従うはずなので，この仮定に基づいてP値を計算します．両側検定でのP値の計算方法例として\n\\[\n\\begin{align*}\n\\text{p-value} = \\sum_{x} \\Pr(X_{11}={x}) \\text{ s.t } \\{x \\vert \\Pr(X_{11}={x}) \\leq \\Pr(X_{11}={x_{11}})\\}\n\\end{align*}\n\\]",
    "crumbs": [
      "統計的仮説検定入門",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher's exact test</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#times-2クロスセル表とfishers-exact-test",
    "href": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#times-2クロスセル表とfishers-exact-test",
    "title": "6  Fisher’s exact test",
    "section": "References",
    "text": "問題設定 \nある医薬品試験のRCTにて，５０人の患者を無作為にtreatedとプラセボ(control)に分けて，一定期間後の健康状態(Positive vs Negative)を確認したところ 以下のような結果になった．\n\n\n\n\n\n \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\n合計\n\n\n\n\n\n\nPositive\n\n\n\n\n21\n\n\n\n\n15\n\n\n\n\n36\n\n\n\n\n\n\nNegative\n\n\n\n\n4\n\n\n\n\n10\n\n\n\n\n14\n\n\n\n\n\n\n合計\n\n\n\n\n25\n\n\n\n\n25\n\n\n\n\n50\n\n\n\n\n\nこのとき，プラセボとグループと医薬品投入グループ間で健康状態分布が異なるかどうか検定したい．\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\n合計\n\n\n\n\n\n\nPositive\n\n\n\n\n\\(X_{11}\\)\n\n\n\n\n\\(X_{12}\\)\n\n\n\n\n\\(x_{1\\cdot}\\)\n\n\n\n\n\n\nNegative\n\n\n\n\n\\(X_{21}\\)\n\n\n\n\n\\(X_{22}\\)\n\n\n\n\n\\(x_{2\\cdot}\\)\n\n\n\n\n\n\n合計\n\n\n\n\n\\(x_{\\cdot 1}\\)\n\n\n\n\n\\(x_{\\cdot 2}\\)\n\n\n\n\n\\(N\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(H_0\\): 処置(Treatment)と一定期間後の健康状態(主要評価項目)は独立\n\\(H_1\\): 処置(Treatment)と一定期間後の健康状態(主要評価項目)は独立ではない \\(\\Rightarrow \\Pr(\\text{Positive}\\vert \\text{Treated})\\neq \\Pr(\\text{Positive}\\vert \\text{Control})\\)\n\n\n\n\n\n\nCode\nimport math\nimport numpy as np\nimport polars as pl\nimport plotly.express as px\n\n\ndef compute_prob(\n    x: int, positive: int, negative: int, treated: int, denom: int\n) -&gt; np.float64:\n    return math.comb(positive, x) * math.comb(negative, treated - x) / denom\n\n\nDENOM = math.comb(50, 25)\nX_DOMAIN = np.arange(11, 25)\n\nprob = list(\n    map(\n        lambda x: compute_prob(x, positive=36, negative=14, treated=25, denom=DENOM),\n        X_DOMAIN,\n    )\n)\n\n# create polars.DataFrame\ndf = pl.DataFrame({\"x\": X_DOMAIN, \"prob\": prob})\n\n# plotly\nfig = px.bar(df, x=\"x\", y=\"prob\", title=\"Null hypothesis下における確率分布\")\nfig.update_layout(\n    xaxis_title=\"TreatedにおけるPositiveの人数\", yaxis_title=\"probability\"\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nexact p-valueの計算\n ▶  片側検定\n\\(X_{11} \\geq x\\) となる場合のp-valueをscipy.stats.fisher_exactで計算すると以下のようになります．\n\nfrom scipy.stats import fisher_exact\ntable = np.array([[21, 15], [4, 10]])\nres_greater = fisher_exact(table, alternative='greater')\nprint(\"scipy-p-value: {:.6f}\".format(res_greater.pvalue))\n\nscipy-p-value: 0.056829\n\n\n一方，上で計算したprobabilityに則って上側確率を見てみると\n\nprint(\"self-computed-pvalue: {:.6f}\".format(df.filter((pl.col(\"x\") &gt;= 21))['prob'].sum()))\n\nself-computed-pvalue: 0.056824\n\n\nと数値計算誤差を無視してしまえば大まかに一致することが確認できます．\n ▶  両側検定\n両側検定におけるp-valueは\n\\[\n\\begin{align*}\n\\text{p-value} = \\sum_{x} \\Pr(X_{11}={x}) \\text{ s.t } \\{x \\vert \\Pr(X_{11}={x}) \\leq \\Pr(X_{11}={x_{11}})\\}\n\\end{align*}\n\\]\nなので\n\nthreshold = df.filter((pl.col(\"x\") == 21))[\"prob\"].to_numpy()[0]\nres_twosided = fisher_exact(table, alternative=\"two-sided\")\nmyres_twosided = df.filter((pl.col(\"prob\") &lt;= threshold))[\"prob\"].sum()\nprint(\"\"\"scipy-p-value: {:.6f},self-computed-pvalue: {:.6f}\n      \"\"\".format(res_twosided.pvalue, myres_twosided))\n\nscipy-p-value: 0.113657,self-computed-pvalue: 0.113652\n      \n\n\nどちらの計算でもおよそ \\(11.37\\%\\) であることが確認できます．\n\n📘 REMARKS \n\n組み合わせの数が大きすぎ，exact p-valueの計算が難しい場合はMonte Carlo法を用いて計算します\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nT\nT\nT\nT\nT\nC\nC\nC\nC\nC\n\n\nPromoted\n1\n1\n1\n1\n0\n1\n1\n0\n0\n0\n\n\n\nというTreatedのうち４人がPromotedされたデータが得られた場合，TreatedかつPromotedの人数を \\(X\\) としたとき， \\(\\Pr(X \\geq 4)\\) のついて計算参する場合は\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTreatment\nT\nT\nT\nT\nT\nC\nC\nC\nC\nC\n\n\nPromoted\n1\n0\n1\n0\n0\n1\n1\n1\n1\n1\n\n\n\nのように２行目についてPermutationをランダムに \\(Y\\) 回実施してサンプリングから \\(\\Pr(X \\geq 4)\\) を計算します（上の例では \\(X = 3\\)）となっている．このように計算されたp-valueはfisher’s exact p-valueのMonte Carlo approximationと呼んだりします．\n\n\n\nOdds ratio\nscipy.stats.fisher_exactではpvalueのほかにstatisticという返り値をもっています．\n\nprint(res_twosided.statistic)\n\n3.5\n\n\nこの 3.5 はいわゆるodds ratioで\n\\[\n3.5 = \\frac{21 / 4}{15 / 10}\n\\]\nで計算されます．\n\nDef: Odds \n確率事象 \\(A\\) についての odds は以下のように計算される\n\\[\n\\begin{align*}\n\\text{odds}(A) = \\frac{\\Pr(A)}{1 - \\Pr(A)} = \\frac{\\Pr(A)}{\\Pr(A^c)}\n\\end{align*}\n\\]\n\noddsを用いることで表現がシンプルになるケースとしてフェアな賭けにおいける倍率の計算が上げられます． 例として，確率事象 A に対して1円を賭ける状況を考えます．確率事象 A が発生しなかったら1円を失い，確率事象 A が発生したら1円はキープ & x 円のリターンを得られるとします．\nこのとき，この賭けがフェアであるためには，期待利得が0であることが必要ですが，以下のように \\(x = \\text{odds}(A^c)\\) とリターンが設定されているとフェアな賭けになります．\n\\[\n\\begin{align*}\n&\\text{expected return} = x \\times \\Pr(A) + (-1) \\times \\Pr(A^c)\\\\\n&\\Rightarrow x = \\frac{\\Pr(A^c)}{\\Pr(A)} \\because \\text{exptected return should be 0}\\\\\n& \\Rightarrow x = \\text{odds}(A^c) = 1/\\text{odds}(A)\n\\end{align*}\n\\]\n\nDef: Odds ratio \nとある母集団にたいして，とある疾患の発症を抑制すると謳っている新薬を考えます．\n\n疾患が発症したならPositive, 発症しなかったらNegative\n新薬を処方されたらTreated, されなかったらControl\n\nとして，母集団の各組み合わせに対する事前割当確率が以下のようなクロスセルで定義されているとします．\n\n\n\n\n\n \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\n\n\nPositive\n\n\n\n\n\\(p_{11}\\)\n\n\n\n\n\\(p_{12}\\)\n\n\n\n\n\n\nNegative\n\n\n\n\n\\(p_{21}\\)\n\n\n\n\n\\(p_{22}\\)\n\n\n\n\n\nこのとき，treated/control間の疾患発症のodds ratioは\n\\[\n\\text{odds ratio} = \\frac{p_{11}p_{22}}{p_{21}p_{12}}\n\\]\nで表現される．\n\n\n仮に Treated, Control両方のグループで疾患発症がレアなイベントだとすると \\(1- \\Pr(\\text{Positive} \\vert \\text{Treated}), 1-\\Pr(\\text{Positive} \\vert \\text{Control})\\) はともに十分小さくなり，\n\\[\n\\text{odds}(\\text{Positive}\\vert\\text{Treated}) \\approx Pr(\\text{Positive} \\vert \\text{Treated})\n\\]\nとみなせるので\n\\[\n\\frac{\\text{odds}(\\text{Positive}\\vert\\text{Treated})}{\\text{odds}(\\text{Positive}\\vert\\text{Control})} \\approx \\frac{Pr(\\text{Positive} \\vert \\text{Treated})}{Pr(\\text{Positive} \\vert \\text{Control})}\n\\]\nOdds ratioが0.7だとすると，Treated は Controlにくらべ 30% ほど疾患発症確率が低いという解釈に繋がります．\n\nOdds ratioの推定と信頼区間\n\n\n\n\n\n \n\n\n\n\n\n\nTreated\n\n\n\n\nControl\n\n\n\n\n合計\n\n\n\n\n\n\nPositive\n\n\n\n\n\\(x_{11}\\)\n\n\n\n\n\\(x_{12}\\)\n\n\n\n\n\\(x_{1\\cdot}\\)\n\n\n\n\n\n\nNegative\n\n\n\n\n\\(x_{21}\\)\n\n\n\n\n\\(x_{22}\\)\n\n\n\n\n\\(x_{2\\cdot}\\)\n\n\n\n\n\n\n合計\n\n\n\n\n\\(x_{\\cdot 1}\\)\n\n\n\n\n\\(x_{\\cdot 2}\\)\n\n\n\n\n\\(N\\)\n\n\n\n\n\n上記のようなデータについて，prior odds ratio \\(\\theta\\) の推定は\n\\[\n\\hat\\theta = \\frac{\\hat p_{11}\\hat p_{22}}{\\hat p_{21}\\hat p_{12}} \\  \\ \\text{where } \\hat p_{ij} = \\frac{x_{ij}}{N}\n\\]\n従って，\n\\[\n\\hat\\theta = \\frac{x_{11}x_{22}}{x_{21}x_{12}}\n\\]\n ▶  Confidence Intervalの計算\nConfidence Intervalは，実務では \\(\\log(\\theta)\\) を用いたCLTとdelta methodによる近似で計算されます．\n\\[\n\\begin{align*}\n\\mathbf p = (p_{11},p_{12},p_{21},p_{22})\n\\end{align*}\n\\]\nとしたとき，もともとのテーブルはクラス4の多項分布とみなせるので \\(\\mathbf p\\) についての共分散行列 \\(\\Sigma\\) は\n\\[\n\\begin{align*}\n\\Sigma = \\frac{1}{n}\\left(\n    \\begin{array}{cccc}\n    (1-p_{11}) p_{11} & -p_{11} p_{12} & -p_{11} p_{21} & -p_{11} p_{22} \\\\\n     -p_{11} p_{12} & \\left(1-p_{12}\\right) p_{12} & -p_{12} p_{21} & -p_{12} p_{22} \\\\\n     -p_{11} p_{21} & -p_{12} p_{21} & \\left(1-p_{21}\\right) p_{21} & -p_{21} p_{22} \\\\\n     -p_{11} p_{22} & -p_{12} p_{22} & -p_{21} p_{22} & (1-p_{22}) p_{22}\n    \\end{array}\n\\right)\n\\end{align*}\n\\]\nまた，\\(\\log(\\theta) = \\log(p_{11}) - \\log(p_{12}) - \\log(p_{21}) + \\log(p_{22})\\) についての分散はdelta methodを用いて\n\\[\n\\begin{align*}\n&\\operatorname{Var}(\\log(\\mathrm{OR})) = (\\nabla f \\Sigma )\\times \\nabla f^T\\\\\n&\\nabla f = \\left(\\frac{1}{p_{11}},-\\frac{1}{p_{12}},-\\frac{1}{p_{21}},\\frac{1}{p_{22}}\\right)\n\\end{align*}\n\\]\nと表せます．これを推定値 \\(\\hat p_{ij}\\) を用いて計算すると\n\\[\n\\begin{align*}\n&\\widehat{\\operatorname{Var}(\\log(\\operatorname{OR})}=\\frac{1}{x_{11}}+\\frac{1}{x_{12}}+\\frac{1}{x_{21}}+\\frac{1}{x_{22}}\\\\\n&\\widehat{\\operatorname{SE}(\\log(\\operatorname{OR})}=\\sqrt{\\frac{1}{x_{11}}+\\frac{1}{x_{12}}+\\frac{1}{x_{21}}+\\frac{1}{x_{22}}}\n\\end{align*}\n\\]\n\\(\\mathbf p\\) は \\(N\\) が十分大きいときCLTより正規分布に近似できると考えられるので \\(\\log(\\hat\\theta)\\) についてのConfidence Intervalは\n\\[\n\\text{CI(log odds ratio)} = \\widehat{\\log(\\operatorname{OR})}\\pm z_{1-\\alpha/2}\\times \\widehat{\\operatorname{SE}(\\log(\\operatorname{OR})}\n\\]\nまた，odds ratioのConfidence Intervalは対数を再度変換すれば良いので\n\\[\n\\text{CI(odds ratio)} = \\exp(\\widehat{\\log(\\operatorname{OR})}\\pm z_{1-\\alpha/2}\\times \\widehat{\\operatorname{SE}(\\log(\\operatorname{OR})})\n\\]\nと計算できる．\n\n📘 REMARKS \n\n上記の方法でのConfidence intervalは \\(\\log(\\hat\\theta)\\) 自体の推定分散ではなく，CLTを用いているのであくまで分散についての極限分布を用いている\n\\(p_{21}\\) や \\(p_{12}\\) 自体は0になり得ることを考えると，\\(\\hat\\theta\\) や \\(\\log(\\hat\\theta)\\) が存在しないことも考えられる\n\n\n\n\nReferences\n\nPennState STAT 504 &gt; 4.5 - Fisher’s Exact Test",
    "crumbs": [
      "統計的仮説検定入門",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher's exact test</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#references",
    "href": "posts/statistical_hypothesis_test_101/fisher_exact_test.html#references",
    "title": "6  Fisher’s exact test",
    "section": "",
    "text": "PennState STAT 504 &gt; 4.5 - Fisher’s Exact Test",
    "crumbs": [
      "統計的仮説検定入門",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Fisher's exact test</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html",
    "title": "7  Fisher流検定 vs Neyman-Pearson流検定",
    "section": "",
    "text": "Fisher流検定の考え方\n２標本問題を考えたとき，２標本の平均の差がそのバラツキの大きさ（＝標準誤差）と比べて大きければ大きいほど 「母集団に差があり」のエビデンス力が高いという考えがFisher流検定となります．P値自体はサンプルサイズに依存すると留意していましたが， Fisher流ではP値が小さいほどエビデンス力が高いという解釈になります．さらに，\nというモノサシの提案をFisherはしました．これが現在の有意水準(significance level) 5% という慣習の由来であると言われています．\nなお，FisherはP値を統計家がデータの解析結果を「報告」するときのモノサシとしての提案にとどまっており， 効果があったか否かの「判定」は，統計家だけでなく関連専門家が参加するグループ討議によって，報告されたP値，分析対象，サンプルサイズ等を吟味して総合的に「判定」すべきであると考えてます．",
    "crumbs": [
      "統計的仮説検定の実践",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Fisher流検定 vs Neyman-Pearson流検定</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#fisher流検定の考え方",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#fisher流検定の考え方",
    "title": "7  Fisher流検定 vs Neyman-Pearson流検定",
    "section": "",
    "text": "平均の差が標準誤差の２倍未満であれば平均の差はバラツキによる差であって考慮に値しない，\n2倍以上の差があるとき，偶然のみに支配されたバラツキに比べると指標の値が相対的に大きいと言える→初めて科学的に意味のある差であるか否かを検討する対象になりうる（正規分布を仮定したとき，約5％水準に相当）",
    "crumbs": [
      "統計的仮説検定の実践",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Fisher流検定 vs Neyman-Pearson流検定</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#neyman-pearson流検定の考え方",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#neyman-pearson流検定の考え方",
    "title": "7  Fisher流検定 vs Neyman-Pearson流検定",
    "section": "Neyman-Pearson流検定の考え方",
    "text": "Neyman-Pearson流検定の考え方\nNeyman-Pearson流は統計的検定について\n\n\\(H_0: \\theta \\in \\Theta_0\\), Null hypothesis\n\\(H_1: \\theta \\not\\in \\Theta_0\\), Alternative hypothesis\n\nの２つを設定し，観察されたデータに基づいてどちらの仮説がより妥当な仮説であるかを判定する問題という統計的判定問題を考えました． 統計的判定問題のおける判定の誤りについて，\n\nType I Error: \\(H_0\\) が正しいのに誤って \\(H_0\\) を棄却するエラー\nType II Error: \\(H_1\\) が正しいのに誤って \\(H_0\\) を採択するエラー\n\nの２種類があるとし，Type I Errorの確率を \\(\\alpha\\) に抑えた上で，Type II Errorの確率 \\(\\beta\\) を最小にする制約付き最小化問題 として統計的判定問題を定式化しました．\n\n\n\n\n\n \n\n\n\n\nTruth\n\n\n\n\n\n\n\\(H_0\\)\n\n\n\n\n\\(H_1\\)\n\n\n\n\n\n\n\n\n\n\n\n検定結果\n\n\n\n\n\\(H_0\\)\n\n\n\n\n正しい(\\(1- \\alpha\\))\n\n\n\n\nType II Error(\\(\\beta\\))\n\n\n\n\n\n\n\\(H_1\\)\n\n\n\n\nType I Error(有意水準: \\(\\alpha\\))\n\n\n\n\n正しい（検出力: \\(1 - \\beta\\)）\n\n\n\n\n\n検定問題に対応する 検定統計量 \\(T\\), \\(H_0\\) の棄却域を \\(R\\) で表すとそれぞれ以下のように表現されます\n\nType I Error rate, \\(\\alpha = \\Pr(T \\in R \\vert H_0)\\)\nType II Error rate: \\(\\beta = \\Pr(T \\not\\in R \\vert H_1)\\)\n\nFisher流ではP値の大きさがエビデンス力という意味を持つことに対して，Neyman-Pearson流では\n\n事前に定められた有意水準 \\(\\alpha\\) をP値が下回るなら効果ありとの判定\nそうでないなら，効果なしとの判定\n\\(P = 0.00001\\) だろうが \\(P = 0.049\\) だろうがP値の水準自体には意味を求めない\n\nという違いがあります．\n\n📘 REMARKS \nNeyman-Pearson流では， \\(\\alpha, \\beta\\) を用いて統計的に効果があると言えるか？という統計的判定問題として仮説検定を定式化しましたが，\n\n統計的検定は決定するための方法ではなく，結果を報告するための方法である by F.Mostelller(1916-2006)\n\nと理解するにとどめたほうが良いとされています．",
    "crumbs": [
      "統計的仮説検定の実践",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Fisher流検定 vs Neyman-Pearson流検定</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#探索的リサーチと検証的リサーチ",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#探索的リサーチと検証的リサーチ",
    "title": "7  Fisher流検定 vs Neyman-Pearson流検定",
    "section": "探索的リサーチと検証的リサーチ",
    "text": "探索的リサーチと検証的リサーチ\n特定の疾患をターゲットとして行われる医薬品の開発過程（詳細はこちら）を例にすると，\n\n候補化学物質について，発がん性試験，変異原性試験，薬効薬理研究など様々な試験をラットや細胞に対して探索的に実施\n健常なヒトを対象に臨床第I相試験として，安全性や薬物動態などを探索的に研究\n当該疾患の患者を対象に第II相臨床試験として，病気の程度によってどのような効き目を発揮するのか（有効性）、副作用はどの程度か（安全性）、またどのような使い方（投与量・間隔・期間など）をしたらよいか、を研究\n第III相臨床試験として，医薬品の有効性と安全性をRCTで検証\n\n第III相臨床試験においては，TreatmentのEffect Sizeの想定と十分なサンプルサイズを確保した上でRCTを実施，そして得られたデータに基づいて統計的意味における効果の有無を検証しています． このようなリサーチを検証的リサーチといいます．\n一方，それまでの動物試験，非臨床試験，臨床第I相試験，臨床第II相試験では，Effect Sizeやサンプルサイズが事前に統計的に設定される場合は少なく，あくまで 次の分析ステップに進む値するエビデンス収集や仮説立案という目的で実施されるリサーチです．このような分析を探索的リサーチと呼びます．\n\n検証的リサーチにおける仮説検定手順\nとあるPopulationを対象に実施するTreatmentの効果をRCTで仮説検定検証する場合，基本的には次のような一連の手順で実施します．\n\nTable: 検証的リサーチ手順\n\n\n\n\n\n\n手順\n説明\n\n\n\n\n手順(1)\n主要評価項目 \\(\\delta\\) を定義し，期待される水準 \\(\\delta_0\\) を見積もる\n\n\n手順(2)\n\\(H_0: \\delta = 0, H_1: \\delta \\neq 0\\) のようにHypothesesを言語化する\n\n\n手順(3)\n有意水準 \\(\\alpha\\), 検出力 \\(1 - \\beta\\) を定める\n\n\n手順(4)\n有意水準 \\(\\alpha\\), 検出力 \\(1 - \\beta\\) のもとで \\(\\delta_0\\) を検出するための必要サンプルサイズを計算する\n\n\n手順(5)\nPopulationからランダムにEntityをサンプリングして，手順(4)のサンプルサイズを満たすようにEntityをランダム or 層化ランダムでtreated/controlに割り当てる\n\n\n手順(6)\ntreated, controlのバランスチェック\n\n\n手順(7)\ntreated, controlがともに実験から逸脱しない形でそれぞれ処置を受けることを観察(= プロトコル遵守の確保)\n\n\n手順(8)\ntreated, controlのデータを収集し，Attritionなどの対応を実施した上で，主要評価項目, 検定統計量を計算\n\n\n手順(9)\n手順(8)で計算された検定統計量を元に，統計的検定を実施し，P値が有意水準 \\(\\alpha\\) 以下ならば効果があると統計的判断を下し，それ以外の場合では \\(H_0\\) が棄却できなかったとする\n\n\n\n上記の手順に則って，\\(H_0\\) が棄却された場合，少なくとも \\(\\delta \\geq \\delta_0\\) なのだろうという統計的判断がなされます．\n\n\n探索的リサーチと仮説検定\n探索的リサーチでは，多くの場合，サンプルサイズや特徴量バランスがコントロールできない観察データを対象に分析し， また次のリサーチに進むための仮説構築や検討に値する特徴量スクリーニングを目的とすることが多いです．このとき検定を実施するとしても，有意水準，検出力，Effect Sizeを想定した Neyman-Pearson流の検定の実施は難しく，偶然のバラツキにしては差が大きそうというインサイトを得ることを目的としたFisher流仮説検定の用い方となります．\nただ，P値に基づいて推論を行うのではなく，平均の差やハザード比などの指標や信頼区間，またその分野のドメイン知識を考慮した上で， 総合的に結果を解釈→仮説の構築をすることが重要です．",
    "crumbs": [
      "統計的仮説検定の実践",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Fisher流検定 vs Neyman-Pearson流検定</span>"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#appendix-新薬誕生までのプロセス",
    "href": "posts/statistical_hypothesis_test_201/fisher_vs_neyman_pearson.html#appendix-新薬誕生までのプロセス",
    "title": "7  Fisher流検定 vs Neyman-Pearson流検定",
    "section": "Appendix: 新薬誕生までのプロセス",
    "text": "Appendix: 新薬誕生までのプロセス\n\n\n\n出典: 治験の３つのステップ，群馬大学医学部附属病院 先端医療開発センター臨床研究推進部\n\n\n\nTable: 各工程における分析目的\n\n\n\n\n\n\n工程\n説明\n\n\n\n\n新規物質の探索・創製\n薬になりそうな新しい物質を探したり，作り出したりすること\n\n\n物理的化学的研究\n新規物質の構造や物理的・化学的な性状などを調べること\n\n\n薬効薬理研究\nどのような効果があるか，どのようなメカニズムで効果を現すのかなどを調べること\n\n\n薬物動態研究\nどのように，体内に吸収され，臓器などに分布し，代謝されて排泄されるかなどを調べること\n\n\n一般薬理研究\nどのような部位にどんな作用を及ぼすかなど，薬効薬理作用以外の安全性に関する作用を調べること\n\n\n一般毒性研究\n投与期間を短・中・長期などに分けて，毒性（安全性）を広く調べること\n\n\n特殊毒性研究\n発がん性や胎児への影響がないかなど，特別な毒性（安全性）を調べること\n\n\n臨床第I相試験（臨床薬理試験）\n少数の健康成人などについて，主に安全性や薬物動態などを調べる試験\n\n\n臨床第II相試験（探索的試験）\n比較的少数の患者さんについて，有効性と安全性などを調べる試験\n\n\n臨床第III相試験（検証的試験）\n多数の患者さんについて，標準的な「くすり」などと比較して有効性と安全性を確認する試験\n\n\n製造販売後調査\n製造販売後に多くの患者さんに使用されたときの安全性や有効性などの情報を集め，それを分析・ 評価して医療関係者などに伝えること",
    "crumbs": [
      "統計的仮説検定の実践",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Fisher流検定 vs Neyman-Pearson流検定</span>"
    ]
  },
  {
    "objectID": "posts/ExplanatoryDataAnalysis/gini_coefficient.html",
    "href": "posts/ExplanatoryDataAnalysis/gini_coefficient.html",
    "title": "8  ジニ係数",
    "section": "",
    "text": "ジニ係数とローレンツ曲線\nPythonで形状パラメター 2.5 のパレート分布の乱数と \\(\\operatorname{Unif}(0, 1)\\) を20個ずつ発生させ作画したのが以下\nCode\nimport numpy as np\nfrom scipy.stats import pareto\nimport polars as pl\nimport plotly.express as px\n\nnp.random.seed(42)\n\nSAMPLESIZE = 20\nshape_parameter = 1\nx = pareto.rvs(shape_parameter, size=SAMPLESIZE)\nx2 = np.random.uniform(0, 1, SAMPLESIZE)\n\n# Compute ratio\nrelative_freq = np.arange(0, SAMPLESIZE + 1) / SAMPLESIZE\nrelative_cumulative_pareto = np.insert(np.cumsum(sorted(x)) / np.sum(x), 0, 0)\nrelative_cumulative_uniform = np.insert(np.cumsum(sorted(x2)) / np.sum(x2), 0, 0)\n\n# create dataframe\ndf = pl.DataFrame(\n    {\n        \"relative_freq\": relative_freq,\n        \"pareto\": relative_cumulative_pareto,\n        \"uniform\": relative_cumulative_uniform,\n    }\n)\n\n\n# compute gini\ndef compute_gini(relative_freq, relative_cumulative):\n    a = relative_freq[1:-1] - relative_cumulative[1:-1]\n    b = relative_freq[2:] - relative_freq[:-2]\n    return np.sum(a * b)\n\n\n# plot\npareto_gini = compute_gini(relative_freq, relative_cumulative_pareto)\nuniform_gini = compute_gini(relative_freq, relative_cumulative_uniform)\nfig = px.line(\n    df,\n    x=\"relative_freq\",\n    y=[\"pareto\", \"uniform\"],\n    color_discrete_sequence=[\"blue\", \"red\"],\n    markers=\"x\",\n    title=\"\"\"pareto gini coefficient: {:.2f}, uniform gini coeffient:  {:.2f}\"\"\".format(\n        pareto_gini, uniform_gini\n    ),\n)\n\nfig.update_yaxes(\n    scaleanchor=\"x\",\n    scaleratio=1,\n)\nBASE_SIZE = 600\nfig.update_layout(\n    autosize=True,\n    width=BASE_SIZE,\n    height=BASE_SIZE,\n    shapes=[\n        dict(\n            type=\"line\",\n            line_dash=\"dot\",\n            yref=\"y\",\n            y0=0,\n            y1=1,\n            xref=\"x\",\n            x0=0,\n            x1=1,\n            line=dict(color=\"gray\"),\n            label=dict(text=\"完全平等線\", textposition=\"middle center\"),\n        )\n    ],\n)\n\nfig.show()\n上記のfigureにおける45度線は完全平等線と呼ばれる線です．この赤線とローレンツ曲線で囲まれたエリアの面積の２倍がジニ係数に相当します．ジニ係数は赤線と青線のエリアを三角形と台形に分けてそれぞれを計算し，その合計の２倍で計算することができます．\n上記のようにsampleジニ係数は台形の面積の２倍で計算しますが，母集団ジニ係数と比較して小さめに計算されます． サンプルサイズが十分大きい場合は無視できる程度ですが，度数分布表に基づく計算の場合やsmall sampleの場合は 過小方向バイアスの修正が必要になる場合があります．\nまた，ジニ係数の導出式より，MAD(Mean absolute difference)と sample meanの相対比にジニ係数が比例することがわかります．\n\\[\n\\begin{align*}\n\\operatorname{Gini} &= \\frac{1}{2n^2\\overline{x}}\\sum_{i=1}^n\\sum_{j=1}^n \\vert x_i - x_j\\vert\\\\\n                    &= \\frac{1}{2}\\frac{\\sum_{i=1}^n\\sum_{j=1}^n \\vert x_i - x_j\\vert}{n^2}\\frac{1}{\\overline x}\\\\\n                    &\\propto \\frac{\\operatorname{MAD}}{\\operatorname{sample mean}}\n\\end{align*}\n\\]\n▶  ジニ係数の特徴",
    "crumbs": [
      "Explanatory Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ジニ係数</span>"
    ]
  },
  {
    "objectID": "posts/ExplanatoryDataAnalysis/gini_coefficient.html#ジニ係数とローレンツ曲線",
    "href": "posts/ExplanatoryDataAnalysis/gini_coefficient.html#ジニ係数とローレンツ曲線",
    "title": "8  ジニ係数",
    "section": "",
    "text": "Def: ローレンツ曲線 \nデータ \\(X = \\{x_1, \\cdots, x_n\\}\\) について，以下のような順序統計量をとる\n\\[\nx_{[1]} \\leq \\cdots \\leq x_{[i]} \\leq \\cdots \\leq x_{[n]}\n\\]\nこのとき，相対度数 \\(r_i\\) と累積比率 \\(I_i\\) をそれぞれ以下のように定義する：\n\\[\n\\begin{align*}\nr_i & = \\frac{i}{n}\\\\\nI_i &= \\frac{\\sum_{j=1}^i x_{[j]}}{\\sum_{j=1}^n x_{[j]}}\n\\end{align*}\n\\]\n点 \\((0,0), (r_1, I_1), \\cdots , (r_n, I_n)\\) を区分的に直線で結んで得られる曲線がローレンツ曲線である．\n\n\n\n\n\nDef: ジニ係数 \n\nジニ係数はデータの偏りを示す指標\n\n ▶  相対度数に基づくジニ係数\n\\(a_i\\) を度数表に基づく累積相対頻度， \\(b_i\\) を累積相対階級値としたとき\n\\[\n\\begin{align*}\n\\operatorname{Gini} = \\sum_{i=1}^{k-1} (a_i - b_i)(a_{i+1} - a_{i-1}) \\  \\ \\text{where } a_0 = 0, b_0 = 0\n\\end{align*}\n\\]\n ▶  データに基づくジニ係数\n\\[\n\\begin{align*}\n\\operatorname{Gini}\n    &= \\frac{2}{n}\\sum_{n-1}^{i=1}\\left(\\frac{i}{n} - \\frac{\\sum_{j=1}^i x_{[j]}}{n\\overline{x}}\\right) \\\\\n    &= \\frac{1}{2n^2\\overline{x}}\\sum_{i=1}^n\\sum_{j=1}^n \\vert x_i - x_j\\vert\n\\end{align*}\n\\]\n\n\n\n\n\n\nローレンツ曲線，ジニ係数ともに分布の尺度パラメーターに依存しない\n1点に集中する分布の場合，ローレンツ曲線は完全平等線と一致し，ジニ係数は0となる\nエントロピーと異なり，一様分布の場合にジニ係数が最大をとるとかではない\n\n\n📘 REMARKS \n\nデータの偏りや集中性を見る指標としてジニ係数は使用されますが，他にもエントロピーという指標がある\n\nカテゴリー別に分類されたデータにおいて，各カテゴリーの総体頻度を \\(\\hat p_i = f_i/n\\) としたとき\n\\[\n\\begin{align*}\nH(\\mathbf p) = -\\sum \\hat p_i \\log(\\hat p_i)\n\\end{align*}\n\\]\nHが大きいほどデータは一様になり，集中性があるほど指標は小さくなる．\n\n\n無限母集団におけるローレンツ曲線\n定義域 \\((0, \\infty)\\), 期待値 \\(\\mu\\) を持つ連続確率変数 \\(X\\) について，累積分布関数を \\(F(x)\\), 確率密度関数 \\(f(x)\\) とおきます．このとき，\\(z = F(x)\\) としたときのローレンツ曲線は\n\\[\n\\begin{align*}\n&F^{-1}(z) = x \\  \\ \\text{ (inverse function of cdf)}\\\\\n&L(z) =\\frac{\\int_0^{F^{-1}(z)} t f(t) \\mathrm{d}t}{\\mathbb E[X]}\n\\end{align*}\n\\]\nとして, \\((z, L(z))\\) で作られる曲線となります．ジニ係数は\n\\[\n\\begin{align*}\n\\operatorname{gini} &= 2\\int_0^1 (u - L(u))\\mathrm{d}u\\\\\n                    &= 1 - 2\\int_0^1 L(u)\\mathrm{d}u\n\\end{align*}\n\\]",
    "crumbs": [
      "Explanatory Data Analysis",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>ジニ係数</span>"
    ]
  },
  {
    "objectID": "posts/mathematical_appendix/beta_function.html",
    "href": "posts/mathematical_appendix/beta_function.html",
    "title": "9  ベータ関数",
    "section": "",
    "text": "ベータ関数の性質",
    "crumbs": [
      "Mathematical Appendix",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>ベータ関数</span>"
    ]
  },
  {
    "objectID": "posts/mathematical_appendix/beta_function.html#ベータ関数の性質",
    "href": "posts/mathematical_appendix/beta_function.html#ベータ関数の性質",
    "title": "9  ベータ関数",
    "section": "",
    "text": "Def: ベータ関数 \n実数 \\(a, b\\) について，ベータ関数 \\(\\operatorname{B}(a, b)\\) は以下のように定義される．\n\\[\n\\operatorname{B}(a, b) = \\int^1_0 x^{a-1}(1-x)^{b-1}\\mathrm{d}x\n\\]\nまた，ガンマ関数を用いて以下のように表せる\n\\[\n\\operatorname{B}(a, b) = \\frac{\\Gamma(a+b)}{\\Gamma(a)\\Gamma(b)}\n\\]\n\n\n\n\n\n\n\nProof: ベータ関数とガンマ関数の関係\n\n\n\n\n\nガンマ関数の定義を用いて，\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &= \\int^\\infty_0 x^{a-1}\\exp(-x)\\mathrm{d}x \\int^\\infty_0 y^{b-1}\\exp(-y)\\mathrm{d}y \\\\\n                   &= \\int^\\infty_0 \\int^\\infty_0 x^{a-1}y^{b-1}\\exp(-x-y)\\mathrm{d}x \\mathrm{d}y \\\\\n\\end{align*}\n\\]\nここで, \\(x + y = u, x/(x + y) = v\\) という変数変換を考える．つまり，\n\\[\n\\begin{align*}\nx = uv, y = u(1-v)\n\\end{align*}\n\\]\nこのときのヤコビアンは\n\\[\n\\begin{align*}\n\\vert\\operatorname{det} J \\vert= u\n\\end{align*}\n\\]\n従って，\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &=\\int^\\infty_0 \\int^\\infty_0 (uv)^{a-1}[u(1-v)]^{b-1}\\exp(-u) u\\mathrm{d}x \\mathrm{d}y \\\\\n                   &= \\int^\\infty_0 \\int^\\infty_0 u^{a+b-1}\\exp(-u) v^{a-1}(1-v)^{b-1}\\mathrm{d}x \\mathrm{d}y \\\\\n                   &= \\int^\\infty_0 \\int^1_0 u^{a+b-1}\\exp(-u) v^{a-1}(1-v)^{b-1}\\mathrm{d}v \\mathrm{d}u \\\\\n                   &= \\int^\\infty_0 u^{a+b-1}\\exp(-u) \\mathrm{d}u \\int^1_0 v^{a-1}(1-v)^{b-1}\\mathrm{d}v \\\\\n                   &= \\operatorname{\\Gamma}(a+b)\\operatorname{B}(a, b)\n\\end{align*}\n\\]\nつまり，\n\\[\n\\operatorname{B}(a, b) = \\frac{\\operatorname{\\Gamma}(a+b)}{\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b)}\n\\]\n\n\n\n\n\n\n\n\n\nProof: 座標変換\n\n\n\n\n\nガンマ関数は \\(z^2 = x\\) という変数変換を用いると以下のように変換できる\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a) &= \\int^\\infty_0 x^{a-1}\\exp(-x)\\mathrm{d}x \\\\\n          &= \\int^\\infty_0 z^{2a-2}\\exp(-z^2)\\frac{\\mathrm{d}x}{\\mathrm{d}z}\\mathrm{d}z \\\\\n          &= 2\\int^\\infty_0 z^{2a-1}\\exp(-z^2)\\mathrm{d}z\n\\end{align*}\n\\]\nこれを用いて\n\\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &= 4\\int^\\infty_0 x^{2a-1}\\exp(-x^2)\\mathrm{d}x \\int^\\infty_0 y^{2b-1}\\exp(-y^2)\\mathrm{d}y \\\\\n                   &= 4\\int^\\infty_0 \\int^\\infty_0 x^{2a-1}y^{2b-1}\\exp(-(x^2+y^2))\\mathrm{d}x \\mathrm{d}y\n\\end{align*}\n\\]\nここで, \\(x = r\\cos\\theta, y=r\\sin\\theta\\) という変数変換を行う．このときのヤコビアンは\n\\[\n\\vert \\operatorname{det} J \\vert = r\n\\]\nよって， \\[\n\\begin{align*}\n\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b) &= 4\\int^\\infty_0 \\int^\\infty_0 x^{2a-1}y^{2b-1}\\exp(-(x^2+y^2))\\mathrm{d}x \\mathrm{d}y\\\\\n                   &= 4\\int^{\\pi/2}_0 \\int^\\infty_0 r^{2a+2b-2} \\cos^{2a-1}\\theta \\sin^{2b-1}\\theta \\exp(-r^2) r \\mathrm{d}r \\mathrm{d}\\theta\\\\\n                   &= \\left(2\\int^{\\pi/2}_0 \\cos^{2a-1}\\theta \\sin^{2b-1}\\theta \\mathrm{d}\\theta\\right) \\times \\left(\\int^\\infty_0r^{2(a+b)-1}\\exp(-r^2)\\mathrm{d}r \\right)\\\\\n                   &= \\operatorname{B}(a, b) \\times \\operatorname{\\Gamma}(a+b)\n\\end{align*}\n\\]\n従って，\n\\[\n\\operatorname{B}(a, b) = \\frac{\\operatorname{\\Gamma}(a+b)}{\\operatorname{\\Gamma}(a)\\operatorname{\\Gamma}(b)}\n\\]\n\n\n\n\n\nTheorem 9.1 三角関数とベータ関数の関係 \n正の実数 \\(a, b\\) について，以下が成立する\n\\[\n\\operatorname{B}(a, b) = 2\\int^{\\pi/2}_0\\cos^{2a-1}\\theta\\sin^{2b-1}\\theta \\mathrm{d}\\theta\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\nベータ関数について \\(x = \\cos^2\\theta\\) を用いた置換積分で以下のように示すことができます．\n\\[\n\\begin{align*}\n\\operatorname{B}(a, b) &= \\int^1_0 x^{a-1}(1-x)^{b-1} \\mathrm{d}x\\\\\n                       &= \\int^0_{\\pi/2} (\\cos^2\\theta)^{a-1}(1 - \\cos^2\\theta)^{b-1} \\cdot (-2\\cos\\theta\\sin\\theta) \\mathrm{d}\\theta\\\\\n                       &= 2\\int^{\\pi/2}_0 \\cos^{2a-1}\\theta \\sin^{2b-1}\\theta\\mathrm{d}\\theta\n\\end{align*}\n\\]\nなお, \\(\\sin^2\\theta = 1 - \\cos^2\\theta\\) 及び \\(\\displaystyle\\frac{\\mathrm{d}\\cos^2\\theta}{\\mathrm{d}\\theta} = -2\\cos\\theta\\sin\\theta\\) を用いている．\n\n\n\n\n\nTheorem 9.2 引数の交換性 \n正の実数 \\(a, b\\) について，以下が成立する\n\\[\n\\operatorname{B}(a, b) = \\operatorname{B}(b, a)\n\\]\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\[\n\\begin{align*}\n\\operatorname{B}(a, b) &= \\int^1_0 x^{a-1}(1-x)^{b-1} \\mathrm{d}x\\\\\n                       &= \\int^0_1 (1-z)^{a-1}z^{b-1} \\frac{\\mathrm{d}x}{\\mathrm{d}z}\\mathrm{d}z\\\\\n                       &= \\int^1_0 (1-z)^{a-1}z^{b-1} \\mathrm{d}z\\\\\n                       &= \\operatorname{B}(b, a)\n\\end{align*}\n\\]",
    "crumbs": [
      "Mathematical Appendix",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>ベータ関数</span>"
    ]
  },
  {
    "objectID": "posts/mathematical_appendix/jensen_inequality.html",
    "href": "posts/mathematical_appendix/jensen_inequality.html",
    "title": "10  Jensen’s Inequality",
    "section": "",
    "text": "Def: convex function \n区間 \\(I\\) で定義された関数 \\(f:I \\to \\mathbb R\\) がconvex(凸関数)であるとは, 任意の \\(0 &lt; t &lt; 1\\) について\n\\[\nf((1-t)x + ty) \\leq (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\nstrictly convexであるとは\n\\[\nf((1-t)x + ty) &lt; (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\n\n\n\nDef: concave function \n区間 \\(I\\) で定義された関数 \\(f:I \\to \\mathbb R\\) がconcave(凹関数)であるとは, 任意の \\(0 &lt; t &lt; 1\\) について\n\\[\nf((1-t)x + ty) \\geq (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\nstrictly concaveであるとは\n\\[\nf((1-t)x + ty) &gt; (1 - t)f(x) + t f(y)\\quad \\forall x, y \\in I, x \\neq y\n\\]\n\n\n以下のような \\(\\exp(x), x^2, \\vert x\\vert\\) などが凸関数の例です.\n\n\nCode\nimport numpy as np\nimport plotly.express as px\nimport polars as pl\n\nx = np.linspace(-1, 1, 100)\nexp_x = np.exp(x)\nsquared_x = x**2\nabs_x = abs(x)\n\ndf = pl.DataFrame({\"x\": x, \"exp_x\": exp_x, \"squared_x\": squared_x, \"abs_x\": abs_x})\n\nfig = px.line(df, x=\"x\", y=[\"exp_x\", \"squared_x\", \"abs_x\"], title='example: convex fucntions')\nnewnames = {\"exp_x\": \"exp(x)\", \"squared_x\": \"x^2\", \"abs_x\": \"abs(x)\"}\nfig.for_each_trace(\n    lambda t: t.update(\n        name=newnames[t.name],\n        hovertemplate=t.hovertemplate.replace(t.name, newnames[t.name]),\n    )\n)\n\nfig.show()\n\n\n                                                \n\n\nまた, \\(\\ln(x), \\sqrt{x}\\) やconvext関数に \\(-1\\) を掛けたものは凹関数の例となります．\n\n\nCode\nx = np.linspace(0.05, 1.5, 100)\n\nln_x = np.log(x)\nsqrt_x = np.sqrt(x)\nsquared_x = -(x**2)\n\ndf = pl.DataFrame({\"x\": x, \"ln_x\": ln_x, \"sqrt_x\": sqrt_x, \"squared_x\": squared_x})\n\nfig = px.line(\n    df, x=\"x\", y=[\"ln_x\", \"sqrt_x\", \"squared_x\"], title=\"example: concave fucntions\"\n)\nnewnames = {\"ln_x\": \"log(x)\", \"sqrt_x\": \"sqrt(x)\", \"squared_x\": \"-x^2\"}\nfig.for_each_trace(\n    lambda t: t.update(\n        name=newnames[t.name],\n        hovertemplate=t.hovertemplate.replace(t.name, newnames[t.name]),\n    )\n)\n\nfig.show()\n\n\n                                                \n\n\n\n\nTheorem 10.1 \n関数 \\(f\\) が区間 \\([a, b]\\) で連続で \\((a, b)\\) で２回微分可能とする．このとき， 関数 \\(f\\) が凸関数であることの必要十分条件は\n\\[\nf^{\\prime\\prime}(x) \\geq 0 \\quad \\forall x\\in (a, b)\n\\]\n\n\n\n\n\nTheorem 10.2 : Subgradient Inequality \n関数 \\(f\\) が区間 \\([a, b]\\) で凸関数であり，微分可能とする．このとき以下が成立する\n\\[\nf(y) \\geq f(x) + f^{\\prime}(x)(y-x) \\quad \\forall x, y\\in (a, b)\n\\]\n\n\n\n\n\nTheorem 10.3 Jensen’s Inequality \n\\(\\mathbb E[X] = \\mu &lt; \\infty\\) 及び \\(I \\subset \\mathbb R\\) をサポートとする確率変数 \\(X\\) について，\\(g:I\\to \\mathbb R\\) というconvex functionを考える．\\(g\\) が 区間 \\(I\\) で微分可能としたとき，\n\\[\n\\mathbb E[g(X)] \\geq g(\\mathbb E[X])\n\\]\n\\(g\\) がstrictly convexの場合，\\(X\\) がdegenerateであることの必要十分条件は \\(\\mathbb E[g(X)] = g(\\mathbb E[X])\\)．\n\\(g(\\cdot)\\) がconcaveの場合は，\\(\\mathbb E[g(X)] \\leq g(\\mathbb E[X])\\) が成立する．\n\n\n\n\n\n\n\n\nProof\n\n\n\n\n\n\\(g(\\cdot)\\) はconvex functionなので,\n\\[\ng(X) \\geq g(\\mu) + g^\\prime(\\mu)(X - \\mu)\n\\]\n両辺について期待値をとると，\n\\[\n\\begin{align*}\n\\mathbb E[g(X)] &\\geq g(\\mathbb E[X]) + g^\\prime(\\mu)(\\mathbb E[X] - \\mu)\\\\\n                &= g(\\mathbb E[X])\n\\end{align*}\n\\]\n\n\n\n\nExample 10.1 \n確率変数 \\(X &gt;0\\) がnon-degenerateであるとき，Jensen’s inequalityより \\(g(x) = 1/x\\) はstrictly convexなので\n\\[\n\\mathbb E\\left[\\frac{1}{X}\\right] &gt; \\frac{1}{\\mathbb E[X]}\n\\]",
    "crumbs": [
      "Mathematical Appendix",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Jensen's Inequality</span>"
    ]
  },
  {
    "objectID": "posts/statistics101/chapter_header.html",
    "href": "posts/statistics101/chapter_header.html",
    "title": "統計学入門",
    "section": "",
    "text": "▶  統計学入門 のスコープ\n\n竹村彰通 (2020) をベースに，統計モデルとしての確率分布族と，それらに対する統計推測法について勉強する\n勉強対象は主に日々のデータサイエンス分析のベースとなるような統計基礎概念や定義になるが，これらについて数学的な定義とともにわかりやすい言語化ができるようになることを目的にしています\n\n ▶  記述統計と統計的推測\n\n 記述統計(descriptive statistics)\n\n調査や実験で得られたデータを整理して，その解釈を助けるような統計的分析のこと\n\n統計的推測(statistical inference)\n\n確率的な変動を多く含むデータに対して，そのDGP(= Data generating process)に何かしらの仮定を想定し，データから確率モデルの推定や検定を行う分析のこと\n\n\n\n「伏せられたトランプカードを透視することでスートを当てることができる！」という人がいたとします． この能力を試してみたところ５２枚のカードの内，４０枚を当てることができたというデータが得られました． この，40枚当てることができたというデータについて確率論的意味を判断をするというのが統計的推測です．\nこのように統計的推測とは確率モデルを想定してデータを解釈/判断する分析なので，確率論を中心とする数学的表現を用いたモデルの定式化 （=ランダムネスの法則を扱う数学理論）が必要となります．加えて，\n\n想定した確率モデルが正しそうか？\n与えられたデータと矛盾しないか？\n乖離がある場合，想定したモデルから導かれる結論はどの程度妥当すると言えるのだろうか？\n\nという分析上の判断も必要となります．そのため，統計的推測はデータ分析初心者にとっては敷居が高い手法となりますが， 一旦モデル化や仮定の妥当性についての説明がうまく行くと，手元に実際にあるデータの背後にあるメカニズムに基づいて推測が行えるようになります． 例えば，実際に観測できないPotential Outcomesの分布についての推定や将来の予測などがあります．\nこのように統計的推測とは，使いこなすのは大変ですが，使えるようになるととても強力なツールです．このノートを通じて，統計的推測の基礎やいくつかの応用分野の分析を見ながらマスターしたいなと思っています．\n ▶  測定の尺度\n\n\n\n\n\n\n\n\n種類\nmeasurement\n説明\n\n\n\n\nカテゴリカルデータ\n名義尺度(nominal scale)\nある対象が他と同一か，異なるかを表す測定例: 性別, 血液型\n\n\nカテゴリカルデータ\n順序尺度(ordinal scale)\n大小/優劣関係を表す測定例: ４段階評価の健康状態\n\n\n量的データ\n間隔尺度(interval scale)\n0が相対的な意味をもつ指標例: 気温，知能指数，標高\n\n\n量的データ\n比例尺度(ratio scale)\n0が絶対的な意味を持つ指標例: 身長，金額，時間の経過，絶対温度\n\n\n\n\n\n\n\n竹村彰通 (2020), 現代数理統計学, 学術図書出版社.",
    "crumbs": [
      "統計学入門"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/chapter_header.html",
    "href": "posts/statistical_hypothesis_test_201/chapter_header.html",
    "title": "統計的仮説検定の実践",
    "section": "",
    "text": "References",
    "crumbs": [
      "統計的仮説検定の実践"
    ]
  },
  {
    "objectID": "posts/statistical_hypothesis_test_201/chapter_header.html#references",
    "href": "posts/statistical_hypothesis_test_201/chapter_header.html#references",
    "title": "統計的仮説検定の実践",
    "section": "",
    "text": "柳川堯 (2018), P値: その正しい理解と適用, 近代科学社.\n\n\n永田靖 (2003), サンプルサイズの決め方, 朝倉書店.",
    "crumbs": [
      "統計的仮説検定の実践"
    ]
  },
  {
    "objectID": "posts/robust_statistics/chapter_header.html",
    "href": "posts/robust_statistics/chapter_header.html",
    "title": "Data Analysis and Outliers",
    "section": "",
    "text": "▶  Robust Statistics のスコープ\n\n藤澤洋徳 (2017) をベースに，外れ値に対する分析上の対処方法について勉強する\n\n ▶  ロバスト推定とロバスト検定\n\nDef: ロバスト推定とロバスト検定 \n\nロバスト推定: 外れ値に頑健な推定(estimation)\nロバスト検定: 外れ値の混入に頑健な検定\n\n\n\n\n\n\n藤澤洋徳 (2017), ロバスト統計 : 外れ値への対処の仕方（ISMシリーズ : 進化する統計数理 / 統計数理研究所編, 6, 近代科学社.",
    "crumbs": [
      "Data Analysis and Outliers"
    ]
  },
  {
    "objectID": "posts/econometrics101/chapter_header.html",
    "href": "posts/econometrics101/chapter_header.html",
    "title": "Econometrics Topics",
    "section": "",
    "text": "Econometrics Topics のスコープ\n\n\n\n\n\nEconometric Analysisの基本的な考え\n ▶  ceteris paribus\n\nceteris paribusとは「holding all other relevant factors fixed」を意味する概念\n\nとある確率変数 \\(X\\) の変化が別の確率変数 \\(Y\\) の変化を引き起こす（cause）とデータから主張するためには，単に同時分布（相関関係）を確認するだけでは不十分で，他の変数を固定した上(ceteris paribus)で， \\(X\\) の変化が \\(Y\\) の変化を伴うことを示す必要があります．\n ▶  Asymptotics\n\nfinite sample propertyと対になる概念で，\\(N\\to\\infty\\) に飛ばした極限分布における統計量の性質のこと\ncross section dataの場合は, unit of observations を \\(N\\to\\infty\\)\npanel data analysisの場合は，time indexを固定した上で unit of entitie sを \\(N\\to\\infty\\)\n\n ▶  説明変数(regressor)が確率的である\n\n説明変数が非確率的である例として，実験データのように説明変数 \\(\\mathbf x_i\\) の水準について分析者が事前に決定できる場合がある\n\nこの場合，error termと説明変数の相関（内生性問題）は排除できる\n\n観測データの場合は，実験データのように説明変数 \\(\\mathbf x_i\\) の水準については決定できないため，「非確率的」という仮定は通常当てはまらない\n\n説明変数が確率的である場合，非確率的のもとでは一致性を満たす推定量(例: GLS)が一致性を満たさなくなるリスクがあります．",
    "crumbs": [
      "Econometrics Topics"
    ]
  }
]